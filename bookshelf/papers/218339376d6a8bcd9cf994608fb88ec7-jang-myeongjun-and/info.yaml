abstract: ChatGPT, a question-and-answer dialogue system based on a large language
  model, has gained huge popularity since its introduction. Its positive aspects have
  been reported through many media platforms, and some analyses even showed that ChatGPT
  achieved a decent grade in professional exams, including the law, medical, and finance
  domains, adding extra support to the claim that AI now can assist and, even, replace
  humans in industrial fields. Others, however, doubt its reliability and trustworthiness.
  In this paper, we investigate ChatGPT's trustworthiness regarding logically consistent
  behaviours. Our findings suggest that, although ChatGPT seems to achieve an improved
  language understanding ability, it still fails to generate logically correct predictions
  frequently. Hence, while it is true that ChatGPT is an impressive and promising
  new technique, we conclude that its usage in real-world applications without thorough
  human inspection requires further consideration, especially for risk-sensitive areas.
archiveprefix: arXiv
author: Jang, Myeongjun and Lukasiewicz, Thomas
author_list:
- family: Jang
  given: Myeongjun
- family: Lukasiewicz
  given: Thomas
eprint: 2303.06273v1
file: 2303.06273v1.pdf
files:
- jang-myeongjun-and-lukasiewicz-thomasconsistency-analysis-of-chatgpt2023.pdf
month: Mar
primaryclass: cs.CL
ref: 2303.06273v1
time-added: 2023-03-17-09:36:46
title: Consistency Analysis of ChatGPT
type: article
url: http://arxiv.org/abs/2303.06273v1
year: '2023'
