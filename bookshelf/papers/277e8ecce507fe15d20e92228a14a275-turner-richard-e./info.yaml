abstract: The transformer is a neural network component that can be used to learn
  useful representations of sequences or sets of data-points. The transformer has
  driven recent advances in natural language processing, computer vision, and spatio-temporal
  modelling. There are many introductions to transformers, but most do not contain
  precise mathematical descriptions of the architecture and the intuitions behind
  the design choices are often also missing. Moreover, as research takes a winding
  path, the explanations for the components of the transformer can be idiosyncratic.
  In this note we aim for a mathematically precise, intuitive, and clean description
  of the transformer architecture. We will not discuss training as this is rather
  standard. We assume that the reader is familiar with fundamental topics in machine
  learning including multi-layer perceptrons, linear transformations, softmax functions
  and basic probability.
archiveprefix: arXiv
author: Turner, Richard E.
author_list:
- family: Turner
  given: Richard E.
eprint: 2304.10557v4
file: 2304.10557v4.pdf
files:
- turner-richard-e.an-introduction-to-transformers2023.pdf
month: Apr
primaryclass: cs.LG
ref: 2304.10557v4
time-added: 2023-11-07-21:20:58
title: An Introduction to Transformers
type: article
url: http://arxiv.org/abs/2304.10557v4
year: '2023'
