

<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="No">

    

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10898"/>

    <meta name="dc.title" content="Global optimization issues in deep network regression: an overview"/>

    <meta name="dc.source" content="Journal of Global Optimization 2018 73:2"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2018-09-06"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2018 Springer Science+Business Media, LLC, part of Springer Nature"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="The paper presents an overview of global issues in optimization methods for training feedforward neural networks (FNN) in a regression setting. We first recall the learning optimization paradigm for FNN and we briefly discuss global scheme for the joint choice of the network topologies and of the network parameters. The main part of the paper focuses on the core subproblem which is the continuous unconstrained (regularized) weights optimization problem with the aim of reviewing global methods specifically arising both in multi layer perceptron/deep networks and in radial basis networks. We review some recent results on the existence of non-global stationary points of the unconstrained nonlinear problem and the role of determining a global solution in a supervised learning paradigm. Local algorithms that are widespread used to solve the continuous unconstrained problems are addressed with focus on possible improvements to exploit the global properties. Hybrid global methods specifically devised for FNN training optimization problems which embed local algorithms are discussed too."/>

    <meta name="prism.issn" content="1573-2916"/>

    <meta name="prism.publicationName" content="Journal of Global Optimization"/>

    <meta name="prism.publicationDate" content="2018-09-06"/>

    <meta name="prism.volume" content="73"/>

    <meta name="prism.number" content="2"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="239"/>

    <meta name="prism.endingPage" content="277"/>

    <meta name="prism.copyright" content="2018 Springer Science+Business Media, LLC, part of Springer Nature"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10898-018-0701-7"/>

    <meta name="prism.doi" content="doi:10.1007/s10898-018-0701-7"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10898-018-0701-7.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10898-018-0701-7"/>

    <meta name="citation_journal_title" content="Journal of Global Optimization"/>

    <meta name="citation_journal_abbrev" content="J Glob Optim"/>

    <meta name="citation_publisher" content="Springer US"/>

    <meta name="citation_issn" content="1573-2916"/>

    <meta name="citation_title" content="Global optimization issues in deep network regression: an overview"/>

    <meta name="citation_volume" content="73"/>

    <meta name="citation_issue" content="2"/>

    <meta name="citation_publication_date" content="2019/02"/>

    <meta name="citation_online_date" content="2018/09/06"/>

    <meta name="citation_firstpage" content="239"/>

    <meta name="citation_lastpage" content="277"/>

    <meta name="citation_article_type" content="Article"/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10898-018-0701-7"/>

    <meta name="DOI" content="10.1007/s10898-018-0701-7"/>

    <meta name="citation_doi" content="10.1007/s10898-018-0701-7"/>

    <meta name="description" content="The paper presents an overview of global issues in optimization methods for training feedforward neural networks (FNN) in a regression setting. We first re"/>

    <meta name="dc.creator" content="Laura Palagi"/>

    <meta name="dc.subject" content="Optimization"/>

    <meta name="dc.subject" content="Operations Research/Decision Theory"/>

    <meta name="dc.subject" content="Real Functions"/>

    <meta name="dc.subject" content="Computer Science, general"/>

    <meta name="citation_reference" content="citation_journal_title=Neurocomputing; citation_title=Meta learning evolutionary artificial neural networks; citation_author=A Abraham; citation_volume=56; citation_publication_date=2004; citation_pages=1-38; citation_id=CR1"/>

    <meta name="citation_reference" content="citation_journal_title=J. Mach. Learn. Res.; citation_title=Bounding the search space for global optimization of neural networks learning error: an interval analysis approach; citation_author=S Adam, G Magoulas, D Karras, M Vrahatis; citation_volume=17; citation_publication_date=2016; citation_pages=1-40; citation_id=CR2"/>

    <meta name="citation_reference" content="Adamu, A., Maul, T., Bargiela, A.: On training neural networks with transfer function diversity. In: International Conference on Computational Intelligence and Information Technology (CIIT 2013), Elsevier (2013)"/>

    <meta name="citation_reference" content="citation_journal_title=Neurocomputing; citation_title=Simulated annealing approach in backpropagation; citation_author=S Amato, B Apolloni, G Caporali, U Madesani, A Zanaboni; citation_volume=3; citation_issue=5; citation_publication_date=1991; citation_pages=207-220; citation_id=CR4"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Comput.; citation_title=The effects of adding noise during backpropagation training on a generalization performance; citation_author=G An; citation_volume=8; citation_issue=3; citation_publication_date=1996; citation_pages=643-674; citation_id=CR5"/>

    <meta name="citation_reference" content="citation_journal_title=Top; citation_title=Unsupervised and supervised data classification via nonsmooth and global optimization; citation_author=A Bagirov, A Rubinov, N Soukhoroukova, J Yearwood; citation_volume=11; citation_issue=1; citation_publication_date=2003; citation_pages=1-75; citation_id=CR6"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Netw.; citation_title=Neural networks and principal component analysis: learning from examples without local minima; citation_author=P Baldi, K Hornik; citation_volume=2; citation_issue=1; citation_publication_date=1989; citation_pages=53-58; citation_id=CR7"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Netw.; citation_title=Complex-valued autoencoders; citation_author=P Baldi, Z Lu; citation_volume=33; citation_publication_date=2012; citation_pages=136-147; citation_id=CR8"/>

    <meta name="citation_reference" content="citation_journal_title=Artif. Intell.; citation_title=The dropout learning algorithm; citation_author=P Baldi, P Sadowski; citation_volume=210; citation_publication_date=2014; citation_pages=78-122; citation_id=CR9"/>

    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=TRUST: a deterministic algorithm for global optimization; citation_author=J Barhen, V Protopopescu, D Reister; citation_volume=276; citation_issue=5315; citation_publication_date=1997; citation_pages=1094-1097; citation_id=CR10"/>

    <meta name="citation_reference" content="citation_title=Nonlinear Regression Analysis and Its Applications. Wiley Series in Probability and Statistics; citation_publication_date=2007; citation_id=CR11; citation_author=DM Bates; citation_author=DG Watts; citation_publisher=Wiley"/>

    <meta name="citation_reference" content="Bengio, Y., Louradour, J., Collobert, R., Weston, J.: Curriculum learning. In: Proceedings of the 26th annual international conference on machine learning, pp. 41&#8211;48. ACM (2009)"/>

    <meta name="citation_reference" content="citation_journal_title=J. Mach. Learn. Res.; citation_title=Random search for hyper-parameter optimization; citation_author=J Bergstra, Y Bengio; citation_volume=13; citation_publication_date=2012; citation_pages=281-305; citation_id=CR13"/>

    <meta name="citation_reference" content="citation_title=Nonlinear Programming; citation_publication_date=1999; citation_id=CR14; citation_author=DP Bertsekas; citation_publisher=Athena Scientific"/>

    <meta name="citation_reference" content="citation_journal_title=Optim. Mach. Learn.; citation_title=Incremental gradient, subgradient, and proximal methods for convex optimization: a survey; citation_author=DP Bertsekas; citation_volume=2010; citation_issue=1&#8211;38; citation_publication_date=2011; citation_pages=3; citation_id=CR15"/>

    <meta name="citation_reference" content="citation_title=Parallel and Distributed Computation: Numerical Methods; citation_publication_date=1989; citation_id=CR16; citation_author=DP Bertsekas; citation_author=JN Tsitsiklis; citation_publisher=Prentice-Hall"/>

    <meta name="citation_reference" content="citation_journal_title=SIAM J. Optim.; citation_title=Gradient convergence in gradient methods with errors; citation_author=DP Bertsekas, JN Tsitsiklis; citation_volume=10; citation_issue=3; citation_publication_date=2000; citation_pages=627-642; citation_id=CR17"/>

    <meta name="citation_reference" content="citation_journal_title=Mach. Learn.; citation_title=Optimal classification trees; citation_author=D Bertsimas, J Dunn; citation_volume=106; citation_issue=7; citation_publication_date=2017; citation_pages=1039-1082; citation_id=CR18"/>

    <meta name="citation_reference" content="citation_journal_title=Oper. Res.; citation_title=Classification and regression via integer optimization; citation_author=D Bertsimas, R Shioda; citation_volume=55; citation_issue=2; citation_publication_date=2007; citation_pages=252-271; citation_id=CR19"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Neural Netw.; citation_title=Learning without local minima in radial basis function networks; citation_author=M Bianchini, P Frasconi, M Gori; citation_volume=6; citation_issue=3; citation_publication_date=1995; citation_pages=749-756; citation_id=CR20"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Comput.; citation_title=Improving the generalization properties of radial basis function neural networks; citation_author=C Bishop; citation_volume=3; citation_issue=4; citation_publication_date=1991; citation_pages=579-588; citation_id=CR21"/>

    <meta name="citation_reference" content="Bishop, C.: Pattern Recognition and Machine Learning (Information Science and Statistics), 1st edn. 2006. corr. 2nd printing edn (2007)"/>

    <meta name="citation_reference" content="Blum, A., Rivest, R.L.: Training a 3-node neural network is NP-complete. In: Proceedings of the 1st International Conference on Neural Information Processing Systems, pp. 494&#8211;501. MIT Press (1988)"/>

    <meta name="citation_reference" content="Blundell, C., Cornebise, J., Kavukcuoglu, K., Wierstra, D.: Weight uncertainty in neural networks (2015). arXiv preprint 
                    arXiv:1505.05424
                    
                  
                        "/>

    <meta name="citation_reference" content="Bottou, L., Bousquet, O.: The tradeoffs of large scale learning. In: Proceedings of the 20th International Conference on Neural Information Processing Systems, NIPS&#8217;07, pp. 161&#8211;168. Curran Associates Inc., USA (2007). 
                    http://dl.acm.org/citation.cfm?id=2981562.2981583
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=SIAM Rev.; citation_title=Optimization methods for large-scale machine learning; citation_author=L Bottou, FE Curtis, J Nocedal; citation_volume=60; citation_issue=2; citation_publication_date=2018; citation_pages=223-311; citation_id=CR26"/>

    <meta name="citation_reference" content="citation_journal_title=Pattern Recognit.; citation_title=Application of global optimization methods to model and feature selection; citation_author=A Boubezoul, S Paris; citation_volume=45; citation_issue=10; citation_publication_date=2012; citation_pages=3676-3686; citation_id=CR27"/>

    <meta name="citation_reference" content="Branke, J.: Evolutionary algorithms for neural network design and training. In: Proceedings of the First Nordic Workshop on Genetic Algorithms and its Applications, pp. 145&#8211;163 (1995)"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Neural Netw. Learn. Syst.; citation_title=An optimization-based method for feature ranking in nonlinear regression problems; citation_author=L Bravi, V Piccialli, M Sciandrone; citation_volume=28; citation_issue=4; citation_publication_date=2017; citation_pages=1005-1010; citation_id=CR29"/>

    <meta name="citation_reference" content="citation_journal_title=Phys. Rev. Lett.; citation_title=Statistics of critical points of Gaussian fields on large-dimensional spaces; citation_author=AJ Bray, DS Dean; citation_volume=98; citation_issue=15; citation_publication_date=2007; citation_pages=150 201; citation_id=CR30"/>

    <meta name="citation_reference" content="Breuel, T.M.: On the convergence of SGD training of neural networks (2015). arXiv preprint 
                    arXiv:1508.02790
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Syst. Man Cybern. Part B (Cybern.); citation_title=Evolutionary optimization of radial basis function classifiers for data mining applications; citation_author=O Buchtala, M Klimek, B Sick; citation_volume=35; citation_issue=5; citation_publication_date=2005; citation_pages=928-947; citation_id=CR32"/>

    <meta name="citation_reference" content="citation_journal_title=Data Min. Knowl. Discov.; citation_title=A tutorial on support vector machines for pattern recognition; citation_author=CJ Burges; citation_volume=2; citation_issue=2; citation_publication_date=1998; citation_pages=121-167; citation_id=CR33"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Comput.; citation_title=Convergent decomposition techniques for training RBF neural networks; citation_author=C Buzzi, L Grippo, M Sciandrone; citation_volume=13; citation_issue=8; citation_publication_date=2001; citation_pages=1891-1920; citation_id=CR34"/>

    <meta name="citation_reference" content="citation_journal_title=Comput. Oper. Res.; citation_title=A nested heuristic for parameter tuning in support vector machines; citation_author=E Carrizosa, B Mart&#237;n-Barrag&#225;n, DR Morales; citation_volume=43; citation_publication_date=2014; citation_pages=328-334; citation_id=CR35"/>

    <meta name="citation_reference" content="citation_journal_title=Comput. Oper. Res.; citation_title=Supervised classification and mathematical optimization; citation_author=E Carrizosa, DR Morales; citation_volume=40; citation_issue=1; citation_publication_date=2013; citation_pages=150-165; citation_id=CR36"/>

    <meta name="citation_reference" content="citation_journal_title=J. Optim. Theory Appl.; citation_title=Terminal repeller unconstrained subenergy tunneling ( trust) for fast global optimization; citation_author=B Cetin, J Barhen, J Burdick; citation_volume=77; citation_issue=1; citation_publication_date=1993; citation_pages=97-126; citation_id=CR37"/>

    <meta name="citation_reference" content="Cetin, B.C., Burdick, J.W., Barhen, J.: Global descent replaces gradient descent to avoid local minima problem in learning with artificial neural networks. In: IEEE International Conference onNeural Networks, 1993, pp. 836&#8211;842. IEEE (1993)"/>

    <meta name="citation_reference" content="citation_journal_title=Comput. Electr. Eng.; citation_title=A survey on feature selection methods; citation_author=G Chandrashekar, F Sahin; citation_volume=40; citation_issue=1; citation_publication_date=2014; citation_pages=16-28; citation_id=CR39"/>

    <meta name="citation_reference" content="Chao, J., Hoshino, M., Kitamura, T., Masuda, T.: A multilayer RBF network and its supervised learning. In: International Joint Conference on Neural Networks, 2001 (IJCNN&#8217;01), Proceedings, vol.&#160;3, pp. 1995&#8211;2000. IEEE (2001)"/>

    <meta name="citation_reference" content="citation_journal_title=J. Mach. Learn. Res.; citation_title=Optimization techniques for semi-supervised support vector machines; citation_author=O Chapelle, V Sindhwani, SS Keerthi; citation_volume=9; citation_publication_date=2008; citation_pages=203-233; citation_id=CR41"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Neural Netw.; citation_title=Combined genetic algorithm optimization and regularized orthogonal least squares learning for radial basis function networks; citation_author=S Chen, Y Wu, B Luk; citation_volume=10; citation_issue=5; citation_publication_date=1999; citation_pages=1239-1243; citation_id=CR42"/>

    <meta name="citation_reference" content="Chiang, H.D., Reddy, C.K.: TRUST-TECH based neural network training. In: International Joint Conference on Neural Networks, 2007. (IJCNN 2007), pp. 90&#8211;95. IEEE (2007)"/>

    <meta name="citation_reference" content="citation_journal_title=Neurocomputing; citation_title=Training multilayer neural networks using fast global learning algorithm&#8212;least-squares and penalized optimization methods; citation_author=Sy Cho, TW Chow; citation_volume=25; citation_issue=1; citation_publication_date=1999; citation_pages=115-131; citation_id=CR44"/>

    <meta name="citation_reference" content="Choromanska, A., Henaff, M., Mathieu, M., Arous, G.B., LeCun, Y.: The loss surfaces of multilayer networks. In: AISTATS (2015)"/>

    <meta name="citation_reference" content="Choromanska, A., LeCun, Y., Arous, G.B.: Open problem: the landscape of the loss surfaces of multilayer networks. In: COLT, pp. 1756&#8211;1760 (2015)"/>

    <meta name="citation_reference" content="Cohen, S., Intrator, N.: Global optimization of RBF networks (2000). 
                    http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.31.5955
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Pattern Anal. Appl.; citation_title=A hybrid projection-based and radial basis function architecture: initial values and global optimisation; citation_author=S Cohen, N Intrator; citation_volume=5; citation_issue=2; citation_publication_date=2002; citation_pages=113-120; citation_id=CR48"/>

    <meta name="citation_reference" content="citation_journal_title=Appl. Soft Comput.; citation_title=A two-phased and ensemble scheme integrated backpropagation algorithm; citation_author=Q Dai, Z Ma, Q Xie; citation_volume=24; citation_publication_date=2014; citation_pages=1124-1135; citation_id=CR49"/>

    <meta name="citation_reference" content="Dauphin, Y.N., Pascanu, R., Gulcehre, C., Cho, K., Ganguli, S., Bengio, Y.: Identifying and attacking the saddle point problem in high-dimensional non-convex optimization. In: Advances in neural information processing systems, pp. 2933&#8211;2941 (2014)"/>

    <meta name="citation_reference" content="David, O.E., Greental, I.: Genetic algorithms for evolving deep neural networks. In: Proceedings of the Companion Publication of the 2014 Annual Conference on Genetic and Evolutionary Computation, pp. 1451&#8211;1452. ACM (2014)"/>

    <meta name="citation_reference" content="Dietterich, T.G.: Ensemble methods in machine learning. In: International workshop on multiple classifier systems, pp. 1&#8211;15. Springer (2000)"/>

    <meta name="citation_reference" content="citation_journal_title=Eur. J. Oper. Res.; citation_title=Optimization approaches to supervised classification; citation_author=AP Duarte Silva; citation_volume=261; citation_issue=2; citation_publication_date=2017; citation_pages=772-788; citation_id=CR53"/>

    <meta name="citation_reference" content="citation_journal_title=Appl. Math. Comput. Sci.; citation_title=New neural transfer functions; citation_author=W Duch, N Jankowski; citation_volume=7; citation_publication_date=1997; citation_pages=639-658; citation_id=CR54"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Comput. Surv.; citation_title=Survey of neural transfer functions; citation_author=W Duch, N Jankowski; citation_volume=2; citation_issue=1; citation_publication_date=1999; citation_pages=163-212; citation_id=CR55"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Comput. Surv.; citation_title=Optimization and global minimization methods suitable for neural networks; citation_author=W Duch, J Korczak; citation_volume=2; citation_publication_date=1998; citation_pages=163-212; citation_id=CR56"/>

    <meta name="citation_reference" content="Feng-wen, H., Ai-ping, J.: An improved method of wavelet neural network optimization based on filled function method. In: 16th International Conference on Industrial Engineering and Engineering Management, 2009 (IE&amp;EM&#8217;09), pp. 1694&#8211;1697. IEEE (2009)"/>

    <meta name="citation_reference" content="citation_journal_title=Discrete Optim.; citation_title=Fast training of support vector machines with gaussian kernel; citation_author=M Fischetti; citation_volume=22; citation_publication_date=2016; citation_pages=183-194; citation_id=CR58"/>

    <meta name="citation_reference" content="citation_title=Deterministic Global Optimization: Theory, Methods and Applications; citation_publication_date=2013; citation_id=CR59; citation_author=CA Floudas; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Netw.; citation_title=Local minima and plateaus in hierarchical structures of multilayer perceptrons; citation_author=K Fukumizu, Si Amari; citation_volume=13; citation_issue=3; citation_publication_date=2000; citation_pages=317-327; citation_id=CR60"/>

    <meta name="citation_reference" content="citation_journal_title=Math. Program.; citation_title=A filled function method for finding a global minimizer of a function of several variables; citation_author=R Ge; citation_volume=46; citation_issue=1&#8211;3; citation_publication_date=1990; citation_pages=191-204; citation_id=CR61"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Neural Netw.; citation_title=Multiobjective evolutionary optimization of the size, shape, and position parameters of radial basis function networks for function approximation; citation_author=J Gonz&#225;lez, I Rojas, J Ortega, H Pomares, FJ Fernandez, AF D&#237;az; citation_volume=14; citation_issue=6; citation_publication_date=2003; citation_pages=1478-1495; citation_id=CR62"/>

    <meta name="citation_reference" content="citation_title=Deep Learning; citation_publication_date=2016; citation_id=CR63; citation_author=I Goodfellow; citation_author=Y Bengio; citation_author=A Courville; citation_publisher=MIT Press"/>

    <meta name="citation_reference" content="Goodfellow, I.J., Vinyals, O.: Qualitatively characterizing neural network optimization problems. CoRR (2014). 
                    http://arxiv.org/abs/1412.6544
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Pattern Anal. Mach. Intell.; citation_title=On the problem of local minima in backpropagation; citation_author=M Gori, A Tesi; citation_volume=14; citation_issue=1; citation_publication_date=1992; citation_pages=76-86; citation_id=CR65"/>

    <meta name="citation_reference" content="Gorse, D., Shepherd, A.J., Taylor, J.G.: Avoiding local minima by a classical range expansion algorithm. In: ICANN94, pp. 525&#8211;528. Springer, London (1994)"/>

    <meta name="citation_reference" content="Gorse, D., Shepherd, A.J., Taylor, J.G.: A classical algorithm for avoiding local minima. In: Proceedings of the World Congress on Neural Networks, pp. 364&#8211;369. Citeseer (1994)"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Netw.; citation_title=The new ERA in supervised learning; citation_author=D Gorse, AJ Shepherd, JG Taylor; citation_volume=10; citation_issue=2; citation_publication_date=1997; citation_pages=343-352; citation_id=CR68"/>

    <meta name="citation_reference" content="Graves, A.: Practical variational inference for neural networks. In: Advances in Neural Information Processing Systems, pp. 2348&#8211;2356 (2011)"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Neural Netw.; citation_title=Convergent on-line algorithms for supervised learning in neural networks; citation_author=L Grippo; citation_volume=11; citation_issue=6; citation_publication_date=2000; citation_pages=1284-1299; citation_id=CR70"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Neural Netw. Learn. Syst.; citation_title=Decomposition techniques for multilayer perceptron training; citation_author=L Grippo, A Manno, M Sciandrone; citation_volume=27; citation_issue=11; citation_publication_date=2016; citation_pages=2146-2159; citation_id=CR71"/>

    <meta name="citation_reference" content="citation_journal_title=Optim. Methods Softw.; citation_title=Globally convergent block-coordinate techniques for unconstrained optimization; citation_author=L Grippo, M Sciandrone; citation_volume=10; citation_issue=4; citation_publication_date=1999; citation_pages=587-637; citation_id=CR72"/>

    <meta name="citation_reference" content="citation_journal_title=Comput. Optim. Appl.; citation_title=Nonmonotone globalization techniques for the Barzilai&#8211;Borwein gradient method; citation_author=L Grippo, M Sciandrone; citation_volume=23; citation_issue=2; citation_publication_date=2002; citation_pages=143-169; citation_id=CR73"/>

    <meta name="citation_reference" content="citation_title=A Distribution-free Theory of Nonparametric Regression; citation_publication_date=2006; citation_id=CR74; citation_author=L Gy&#246;rfi; citation_author=M Kohler; citation_author=A Krzyzak; citation_author=H Walk; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Netw.; citation_title=XOR has no local minima: a case study in neural network error surface analysis; citation_author=LG Hamey; citation_volume=11; citation_issue=4; citation_publication_date=1998; citation_pages=669-681; citation_id=CR75"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Process. Lett.; citation_title=Comparison of stochastic global optimization methods to estimate neural network weights; citation_author=L Hamm, BW Brorsen, MT Hagan; citation_volume=26; citation_issue=3; citation_publication_date=2007; citation_pages=145-158; citation_id=CR76"/>

    <meta name="citation_reference" content="citation_title=Neural Networks and Learning Machines; citation_publication_date=2009; citation_id=CR77; citation_author=S Haykin; citation_publisher=Pearson"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Comput.; citation_title=Flat minima; citation_author=S Hochreiter, J Schmidhuber; citation_volume=9; citation_issue=1; citation_publication_date=1997; citation_pages=1-42; citation_id=CR78"/>

    <meta name="citation_reference" content="citation_title=Global Optimization: Deterministic Approaches; citation_publication_date=2013; citation_id=CR79; citation_author=R Horst; citation_author=H Tuy; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Netw.; citation_title=Trends in extreme learning machines: a review; citation_author=G Huang, GB Huang, S Song, K You; citation_volume=61; citation_publication_date=2015; citation_pages=32-48; citation_id=CR80"/>

    <meta name="citation_reference" content="Huang, G.B., Zhu, Q.Y., Siew, C.K.: Extreme learning machine: a new learning scheme of feedforward neural networks. In: 2004 IEEE International Joint Conference on Neural Networks, 2004. Proceedings, vol.&#160;2, pp. 985&#8211;990. IEEE (2004)"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Comput. Appl.; citation_title=Global optimisation in neural network training; citation_author=LCK Hui, KY Lam, CW Chea; citation_volume=5; citation_issue=1; citation_publication_date=1997; citation_pages=58-64; citation_id=CR82"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Syst. Man Cybern. Part C (Appl. Rev.); citation_title=Pareto-based multiobjective machine learning: an overview and case studies; citation_author=Y Jin, B Sendhoff; citation_volume=38; citation_issue=3; citation_publication_date=2008; citation_pages=397-415; citation_id=CR83"/>

    <meta name="citation_reference" content="Kawaguchi, K.: Deep learning without poor local minima. In: Advances In Neural Information Processing Systems, pp. 586&#8211;594 (2016)"/>

    <meta name="citation_reference" content="Keskar, N.S., Mudigere, D., Nocedal, J., Smelyanskiy, M., Tang, P.T.P.: On large-batch training for deep learning: generalization gap and sharp minima. In: ICLR 2017 (2016)"/>

    <meta name="citation_reference" content="Lang, K.: Learning to tell two spiral apart. In: Proceedings of the 1988 Connectionist Models Summer School, pp. 52&#8211;59 (1989)"/>

    <meta name="citation_reference" content="Laurent, T., von Brecht, J.: The multilinear structure of ReLU networks (2017). arXiv preprint 
                    arXiv:1712.10132
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Deep learning; citation_author=Y LeCun, Y Bengio, G Hinton; citation_volume=521; citation_issue=7553; citation_publication_date=2015; citation_pages=436-444; citation_id=CR88"/>

    <meta name="citation_reference" content="LeCun, Y.A., Bottou, L., Orr, G.B., M&#252;ller, K.R.: Efficient backprop. In: Neural networks: Tricks of the trade, pp. 9&#8211;48. Springer (2012)"/>

    <meta name="citation_reference" content="Lee, J.D., Simchowitz, M., Jordan, M.I., Recht, B.: Gradient descent only converges to minimizers. In: Conference on Learning Theory, pp. 1246&#8211;1257 (2016)"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Netw. World; citation_title=Global optimization of radial basis function networks by hybrid simulated annealing; citation_author=JS Lee, CH Park; citation_volume=20; citation_issue=4; citation_publication_date=2010; citation_pages=519; citation_id=CR91"/>

    <meta name="citation_reference" content="citation_journal_title=J. Northeast. Univ. Nat. Sci.; citation_title=A global optimization algorithm based on filled-function for neural networks; citation_author=HR Li, HL Li; citation_volume=28; citation_issue=9; citation_publication_date=2007; citation_pages=1247; citation_id=CR92"/>

    <meta name="citation_reference" content="citation_journal_title=Expert Syst. Appl.; citation_title=A simulated-annealing-based approach for simultaneous parameter optimization and feature selection of back-propagation networks; citation_author=SW Lin, TY Tseng, SY Chou, SC Chen; citation_volume=34; citation_issue=2; citation_publication_date=2008; citation_pages=1491-1499; citation_id=CR93"/>

    <meta name="citation_reference" content="citation_journal_title=Network: Comput. Neural Syst.; citation_title=Complete solution of the local minima in the XOR problem; citation_author=P Lisboa, S Perantonis; citation_volume=2; citation_issue=1; citation_publication_date=1991; citation_pages=119-124; citation_id=CR94"/>

    <meta name="citation_reference" content="citation_journal_title=Int. J. Comput. Math.; citation_title=A new filled function method for unconstrained global optimization; citation_author=H Liu, Y Wang, S Guan, X Liu; citation_volume=94; citation_issue=12; citation_publication_date=2017; citation_pages=2283-2296; citation_id=CR95"/>

    <meta name="citation_reference" content="Locatelli, M., Schoen, F.: Global optimization: theory, algorithms, and applications. Society for Industrial and Applied Mathematics, Philadelphia, PA (2013). 
                    https://doi.org/10.1137/1.9781611972672
                    
                  
                        "/>

    <meta name="citation_reference" content="Magoulas, G., Plagianakos, V., Vrahatis, M.: Hybrid methods using evolutionary algorithms for on-line training. In: International Joint Conference on Neural Networks, 2001 (IJCNN&#8217;01) Proceedings, vol.&#160;3, pp. 2218&#8211;2223. IEEE (2001)"/>

    <meta name="citation_reference" content="Martin-Guerreo, J., G&#243;mez-Chova, L., Calpe-Maravilla, J., Camps-Valls, G., Soria-Olivas, E., Moreno, J.: A soft approach to ERA algorithm for hyperspectral image classification. In: Proceedings of the 3rd International Symposium on Image and Signal Processing and Analysis, 2003 (ISPA 2003), vol.&#160;2, pp. 761&#8211;765. IEEE (2003)"/>

    <meta name="citation_reference" content="Neelakantan, A., Vilnis, L., Le, Q.V., Sutskever, I., Kaiser, L., Kurach, K., Martens, J.: Adding gradient noise improves learning for very deep networks (2015). arXiv preprint 
                    arXiv:1511.06807
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Sov. Math. Doklady; citation_title=A method of solving a convex programming problem with convergence rate 
                      
                      
                      
                    ; citation_author=Y Nesterov; citation_volume=27; citation_issue=2; citation_publication_date=1983; citation_pages=372-376; citation_id=CR100"/>

    <meta name="citation_reference" content="Nguyen, Q., Hein, M.: The loss surface and expressivity of deep convolutional neural networks (2017). arXiv preprint 
                    arXiv:1710.10928
                    
                  
                        "/>

    <meta name="citation_reference" content="Nguyen, Q., Hein, M.: The loss surface of deep and wide neural networks (2017). arXiv preprint 
                    arXiv:1704.08045
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Eng. Appl. Artif. Intell.; citation_title=Metaheuristic design of feedforward neural networks: a review of two decades of research; citation_author=VK Ojha, A Abraham, V Sn&#225;&#353;el; citation_volume=60; citation_publication_date=2017; citation_pages=97-116; citation_id=CR103"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Neural Netw.; citation_title=Mutation-based genetic neural network; citation_author=PP Palmes, T Hayasaka, S Usui; citation_volume=16; citation_issue=3; citation_publication_date=2005; citation_pages=587-600; citation_id=CR104"/>

    <meta name="citation_reference" content="Peng, C.C., Magoulas, G.D.: Adaptive nonmonotone conjugate gradient training algorithm for recurrent neural networks. In: 19th IEEE International Conference on Tools with Artificial Intelligence, 2007 (ICTAI 2007), vol.&#160;2, pp. 374&#8211;381. IEEE (2007)"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Comput. Appl.; citation_title=Nonmonotone Levenberg&#8211;Marquardt training of recurrent neural architectures for processing symbolic sequences; citation_author=CC Peng, GD Magoulas; citation_volume=20; citation_issue=6; citation_publication_date=2011; citation_pages=897-908; citation_id=CR106"/>

    <meta name="citation_reference" content="citation_journal_title=4OR; citation_title=Nonlinear optimization and support vector machines; citation_author=V Piccialli, M Sciandrone; citation_volume=16; citation_issue=2; citation_publication_date=2018; citation_pages=111-149; citation_id=CR107"/>

    <meta name="citation_reference" content="citation_journal_title=Expert Syst. Appl.; citation_title=Calibrating artificial neural networks by global optimization; citation_author=JD Pint&#233;r; citation_volume=39; citation_issue=1; citation_publication_date=2012; citation_pages=25-32; citation_id=CR108"/>

    <meta name="citation_reference" content="citation_journal_title=Nonlinear Anal. Theory Methods Appl.; citation_title=Learning in multilayer perceptrons using global optimization strategies; citation_author=V Plagianakos, G Magoulas, M Vrahatis; citation_volume=47; citation_issue=5; citation_publication_date=2001; citation_pages=3431-3436; citation_id=CR109"/>

    <meta name="citation_reference" content="Plagianakos, V., Magoulas, G., Vrahatis, M.: Improved learning of neural nets through global search. In: Global Optimization, pp. 361&#8211;388. Springer (2006)"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions on Neural Networks; citation_title=Deterministic nonmonotone strategies for effective training of multilayer perceptrons; citation_author=VP Plagianakos, GD Magoulas, MN Vrahatis; citation_volume=13; citation_issue=6; citation_publication_date=2002; citation_pages=1268-1284; citation_id=CR111"/>

    <meta name="citation_reference" content="citation_journal_title=Proc. IEEE; citation_title=Networks for approximation and learning; citation_author=T Poggio, F Girosi; citation_volume=78; citation_issue=9; citation_publication_date=1990; citation_pages=1481-1497; citation_id=CR112"/>

    <meta name="citation_reference" content="citation_journal_title=USSR Comput. Math. Math. Phys.; citation_title=Some methods of speeding up the convergence of iteration methods; citation_author=BT Polyak; citation_volume=4; citation_issue=5; citation_publication_date=1964; citation_pages=1-17; citation_id=CR113"/>

    <meta name="citation_reference" content="citation_journal_title=Neurocomputing; citation_title=Neural networks: an overview of early research, current frameworks and new challenges; citation_author=A Prieto, B Prieto, EM Ortigosa, E Ros, F Pelayo, J Ortega, I Rojas; citation_volume=214; citation_publication_date=2016; citation_pages=242-268; citation_id=CR114"/>

    <meta name="citation_reference" content="citation_journal_title=Proc. Comput. Sci.; citation_title=Simulated annealing algorithm for deep learning; citation_author=LR Rere, MI Fanany, AM Arymurthy; citation_volume=72; citation_publication_date=2015; citation_pages=137-144; citation_id=CR115"/>

    <meta name="citation_reference" content="citation_journal_title=Ann. Math. Stat.; citation_title=A stochastic approximation method; citation_author=H Robbins, S Monro; citation_volume=22; citation_issue=3; citation_publication_date=1951; citation_pages=400-407; citation_id=CR116"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Neural Netw.; citation_title=Dynamic tunneling technique for efficient training of multilayer perceptrons; citation_author=P RoyChowdhury, YP Singh, R Chansarkar; citation_volume=10; citation_issue=1; citation_publication_date=1999; citation_pages=48-55; citation_id=CR117"/>

    <meta name="citation_reference" content="Ruppert, D., Wand, M.P., Carroll, R.J.: Semiparametric regression. In: Cambridge Series in Statistical and Probabilistic mathematics, vol. 12. Mathematical Reviews (MathSciNet): MR1998720. Cambridge Univ. Press, Cambridge (2003)"/>

    <meta name="citation_reference" content="citation_journal_title=Electron. J. Stat.; citation_title=Semiparametric regression during 2003&#8211;2007; citation_author=D Ruppert, MP Wand, RJ Carroll; citation_volume=3; citation_publication_date=2009; citation_pages=1193; citation_id=CR119"/>

    <meta name="citation_reference" content="citation_title=On-Line Learning in Neural Networks; citation_publication_date=2009; citation_id=CR120; citation_author=D Saad; citation_publisher=Cambridge University Press"/>

    <meta name="citation_reference" content="citation_journal_title=Wiley Interdiscip. Rev. Data Min. Knowl. Discov.; citation_title=Randomness in neural networks: an overview; citation_author=S Scardapane, D Wang; citation_volume=7; citation_issue=2; citation_publication_date=2017; citation_pages=1200; citation_id=CR121"/>

    <meta name="citation_reference" content="Schaffer, J.D., Whitley, D., Eshelman, L.J.: Combinations of genetic algorithms and neural networks: a survey of the state of the art. In: International Workshop on Combinations of Genetic Algorithms and Neural Networks, 1992 (COGANN-92), pp. 1&#8211;37. IEEE (1992)"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Netw.; citation_title=Deep learning in neural networks: an overview; citation_author=J Schmidhuber; citation_volume=61; citation_publication_date=2015; citation_pages=85-117; citation_id=CR123"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Netw.; citation_title=Three learning phases for radial-basis-function networks; citation_author=F Schwenker, HA Kestler, G Palm; citation_volume=14; citation_issue=4; citation_publication_date=2001; citation_pages=439-458; citation_id=CR124"/>

    <meta name="citation_reference" content="citation_journal_title=Decis. Support Syst.; citation_title=Toward global optimization of neural networks: a comparison of the genetic algorithm and backpropagation; citation_author=RS Sexton, RE Dorsey, JD Johnson; citation_volume=22; citation_issue=2; citation_publication_date=1998; citation_pages=171-185; citation_id=CR125"/>

    <meta name="citation_reference" content="citation_journal_title=Eur. J. Oper. Res.; citation_title=Optimization of neural networks: a comparative analysis of the genetic algorithm and simulated annealing; citation_author=RS Sexton, RE Dorsey, JD Johnson; citation_volume=114; citation_issue=3; citation_publication_date=1999; citation_pages=589-601; citation_id=CR126"/>

    <meta name="citation_reference" content="citation_journal_title=Computer; citation_title=Global optimization for neural network training; citation_author=Y Shang, BW Wah; citation_volume=29; citation_issue=3; citation_publication_date=1996; citation_pages=45-54; citation_id=CR127"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Comput.; citation_title=Training a single sigmoidal neuron is hard; citation_author=J &#352;&#237;ma; citation_volume=14; citation_issue=11; citation_publication_date=2002; citation_pages=2709-2728; citation_id=CR128"/>

    <meta name="citation_reference" content="Soudry, D., Carmon, Y.: No bad local minima: data independent training error guarantees for multilayer neural networks (2016). arXiv preprint 
                    arXiv:1605.08361
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Neural Netw.; citation_title=The error surface of the 2-2-1 XOR network: The finite stationary points; citation_author=IG Sprinkhuizen-Kuyper, EJ Boers; citation_volume=11; citation_issue=4; citation_publication_date=1998; citation_pages=683-690; citation_id=CR130"/>

    <meta name="citation_reference" content="citation_journal_title=J. Mach. Learn. Res.; citation_title=Dropout: a simple way to prevent neural networks from overfitting; citation_author=N Srivastava, GE Hinton, A Krizhevsky, I Sutskever, R Salakhutdinov; citation_volume=15; citation_issue=1; citation_publication_date=2014; citation_pages=1929-1958; citation_id=CR131"/>

    <meta name="citation_reference" content="Steijvers, M., Gr&#252;nwald, P.: A recurrent network that performs a context-sensitive prediction task. In: Proceedings of the 18th Annual Conference of the Cognitive Science Society, pp. 335&#8211;339 (1996)"/>

    <meta name="citation_reference" content="citation_journal_title=ICML; citation_title=On the importance of initialization and momentum in deep learning; citation_author=I Sutskever, J Martens, GE Dahl, GE Hinton; citation_volume=3; citation_issue=28; citation_publication_date=2013; citation_pages=1139-1147; citation_id=CR133"/>

    <meta name="citation_reference" content="Swirszcz, G., Czarnecki, W.M., Pascanu, R.: Local minima in training of deep networks. CoRR (2016). 
                    arXiv:1611.06310v1
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=J. Mach. Learn. Res.; citation_title=A unified continuous optimization framework for center-based clustering methods; citation_author=M Teboulle; citation_volume=8; citation_publication_date=2007; citation_pages=65-102; citation_id=CR135"/>

    <meta name="citation_reference" content="Teo, C.H., Smola, A., Vishwanathan, S., Le, Q.V.: A scalable modular convex solver for regularized risk minimization. In: Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 727&#8211;736. ACM (2007)"/>

    <meta name="citation_reference" content="Tirumala, S.S., Ali, S., Ramesh, C.P.: Evolving deep neural networks: A new prospect. In: 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD), 2016, pp. 69&#8211;74. IEEE (2016)"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Syst. Man Cybern. Part B (Cybern.); citation_title=Deterministic global optimization for FNN training; citation_author=KA Toh; citation_volume=33; citation_issue=6; citation_publication_date=2003; citation_pages=977-983; citation_id=CR138"/>

    <meta name="citation_reference" content="citation_title=The Nature of Statistical Learning Theory; citation_publication_date=2013; citation_id=CR139; citation_author=V Vapnik; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=Neural Parallel Sci. Comput.; citation_title=A global optimization approach to neural network training; citation_author=C Voglis, I Lagaris; citation_volume=14; citation_issue=2; citation_publication_date=2006; citation_pages=231; citation_id=CR140"/>

    <meta name="citation_reference" content="citation_journal_title=Appl. Math. Comput.; citation_title=Towards ideal multistart: a stochastic approach for locating the minima of a continuous function inside a bounded domain; citation_author=C Voglis, IE Lagaris; citation_volume=213; citation_issue=1; citation_publication_date=2009; citation_pages=216-229; citation_id=CR141"/>

    <meta name="citation_reference" content="citation_journal_title=Inf. Sci.; citation_title=Editorial: Randomized algorithms for training neural networks; citation_author=D Wang; citation_volume=364&#8211;365; citation_publication_date=2016; citation_pages=126-128; citation_id=CR142"/>

    <meta name="citation_reference" content="Werbos, P.J.: Supervised learning: Can it escape its local minimum? In: Theoretical Advances in Neural Computation and Learning, pp. 449&#8211;461. Springer (1994)"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Neural Netw. Learn. Syst.; citation_title=Mlpnn training via a multiobjective optimization of training error and stochastic sensitivity; citation_author=DS Yeung, JC Li, WWY Ng, PPK Chan; citation_volume=27; citation_issue=5; citation_publication_date=2016; citation_pages=978-992; citation_id=CR144"/>

    <meta name="citation_reference" content="citation_journal_title=Neurocomputing; citation_title=Learning deep representations via extreme learning machines; citation_author=W Yu, F Zhuang, Q He, Z Shi; citation_volume=149; citation_publication_date=2015; citation_pages=308-315; citation_id=CR145"/>

    <meta name="citation_reference" content="citation_journal_title=Appl. Math. Comput.; citation_title=A hybrid particle swarm optimization-back-propagation algorithm for feedforward neural network training; citation_author=JR Zhang, J Zhang, TM Lok, MR Lyu; citation_volume=185; citation_issue=2; citation_publication_date=2007; citation_pages=1026-1037; citation_id=CR146"/>

    <meta name="citation_author" content="Laura Palagi"/>

    <meta name="citation_author_email" content="laura.palagi@uniroma1.it"/>

    <meta name="citation_author_institution" content="Dip. di Ingegneria informatica automatica e gestionale A. Ruberti, Sapienza - University of Rome, Rome, Italy"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10898-018-0701-7&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2019/02/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10898-018-0701-7"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Journal of Global Optimization"/>
        <meta property="og:title" content="Global optimization issues in deep network regression: an overview"/>
        <meta property="og:description" content="The paper presents an overview of global issues in optimization methods for training feedforward neural networks (FNN) in a regression setting. We first recall the learning optimization paradigm for FNN and we briefly discuss global scheme for the joint choice of the network topologies and of the network parameters. The main part of the paper focuses on the core subproblem which is the continuous unconstrained (regularized) weights optimization problem with the aim of reviewing global methods specifically arising both in multi layer perceptron/deep networks and in radial basis networks. We review some recent results on the existence of non-global stationary points of the unconstrained nonlinear problem and the role of determining a global solution in a supervised learning paradigm. Local algorithms that are widespread used to solve the continuous unconstrained problems are addressed with focus on possible improvements to exploit the global properties. Hybrid global methods specifically devised for FNN training optimization problems which embed local algorithms are discussed too."/>
        <meta property="og:image" content="https://media.springernature.com/w200/springer-static/cover/journal/10898.jpg"/>
    

    <title>Global optimization issues in deep network regression: an overview | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>
    
    <style>button{line-height:inherit}html,label{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}html{height:100%;overflow-y:scroll;box-sizing:border-box;color:#333;line-height:1.61803;-webkit-font-smoothing:subpixel-antialiased;font-size:62.5%}*{box-sizing:inherit}body{max-width:100%;min-height:100%;background-color:#fcfcfc;background-position:initial initial;background-repeat:initial initial;margin:0}button,div,form,input{margin:0;padding:0}body,p{padding:0}a{color:#004b83;text-decoration:underline}h1,h2{margin-top:0}h1{font-size:3.2rem}h2{font-size:2.8rem}h1,h2{font-style:normal;margin-bottom:1em;line-height:1.4;font-family:Georgia,Palatino,serif;font-weight:400}p{margin:0}ul{margin-top:0}p{margin-bottom:1.5em}.c-ad{display:none;padding:8px;text-align:center}@media only screen and (min-width:768px){.js .c-ad{display:block}}.c-ad--728x90{background-color:#ccc}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}.c-ad--300x250{background-color:#f2f2f2}.c-ad--300x250 .c-ad__inner{min-height:calc(1.5em + 254px)}.c-ad__label,.c-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-ad__label{font-size:1.4rem;font-weight:400;margin-bottom:4px;color:#333;line-height:1.5}.c-header{font-size:1.6rem}.c-header{background-color:#fff;padding:16px 0;border-bottom:4px solid #00285a}.c-header__container{margin:0 auto;max-width:1280px;padding:0 16px;display:-webkit-flex;-webkit-box-align:center;-webkit-align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between}.c-header__brand{margin-right:32px}.c-header__brand a{text-decoration:none}.c-header__menu,.c-header__navigation{display:-webkit-flex}.c-header__navigation{-webkit-box-align:center;-webkit-align-items:center}.c-header__menu{list-style:none;margin:0;padding:0}.c-header__item{color:inherit;margin-right:24px}.c-header__item:last-child{margin-right:0}.c-header__link{text-decoration:none;color:inherit}.js .c-popup{position:absolute;font-family:Georgia,Palatino,serif;z-index:100;padding:16px;border:1px solid rgba(151,191,216,.298039);-webkit-box-shadow:hsla(0,0%,50.2%,.0980392) 0 0 5px 0;box-shadow:0 0 5px 0 hsla(0,0%,50.2%,.0980392);width:auto;border-top-left-radius:2px;border-top-right-radius:2px;border-bottom-right-radius:2px;border-bottom-left-radius:2px;background-color:#fff}.js .c-popup__close{position:absolute;display:block;top:16px;right:16px;height:16px;background-image:url("data:image/svg+xml,%0A%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z' fill='%23666' fill-rule='evenodd'/%3E%3C/svg%3E");border:0;padding-right:16px;background-position:initial initial;background-repeat:no-repeat}.js .c-popup__close-text{border:0;clip:rect(0 0 0 0);height:1px;margin:-100%;overflow:hidden;padding:0;width:1px;position:absolute!important}.js .c-popup__arrow{content:"";position:absolute;width:20px;height:20px;background-color:#fff;border-top:1px solid rgba(151,191,216,.298039);border-left:1px solid rgba(151,191,216,.298039)}body{font-size:1.8em}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{list-style:none;font-size:1.6rem;line-height:1.3;display:-webkit-flex;-webkit-flex-wrap:wrap;color:#6f6f6f;padding:0;margin:0 0 8px}.c-article-identifiers__item{border-right:1px solid #6f6f6f;margin-right:8px;padding-right:8px;list-style:none}.c-article-identifiers__item a{color:#069;text-decoration:none}.c-article-identifiers__item:last-child{margin-right:0;padding-right:0;border-right-width:0}@media only screen and (min-width:768px){.c-author-popup .c-article-identifiers{-webkit-box-pack:end;-webkit-justify-content:flex-end}}.c-article-title{font-size:2.4rem;line-height:1.25;margin-bottom:16px}@media only screen and (min-width:768px){.c-article-title{font-size:3rem;line-height:1.2}}.c-author-list{font-size:1.6rem;list-style:none;margin-bottom:0;padding:0;width:100%}.c-author-list__item{margin-left:0}.c-author-list__item,.c-author-list li{display:inline;padding-right:0}.c-author-list__item svg{margin-left:4px}.c-article-info-details{font-size:1.6rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:-webkit-flex;-webkit-flex-wrap:wrap;line-height:1.3;font-size:1.6rem}.c-article-metrics-bar__wrapper{margin:0 0 16px}.c-article-metrics-bar__item{-webkit-box-align:baseline;-webkit-align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right-width:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-weight:400;font-style:normal;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-author-popup__subheading{font-weight:700;float:left;padding-right:8px;margin-bottom:8px;margin-top:4px}.c-author-popup .c-article-button{font-size:1.6rem;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-author-popup__author-list{list-style:none;font-size:1.6rem;padding:0;margin-top:0;clear:both;margin-bottom:16px}.c-author-popup__author-list>li{margin-bottom:8px}.c-author-popup__link{font-weight:700;vertical-align:baseline;color:#069;text-decoration:none}.c-author-popup .c-article-button{color:#fff;background-image:linear-gradient(#4d78af,#3365a0);border:1px solid transparent;border-top-left-radius:2px;border-top-right-radius:2px;border-bottom-right-radius:2px;border-bottom-left-radius:2px;text-decoration:none;display:block;width:100%;padding-top:8px;padding-bottom:8px;text-align:center;background-position:initial initial;background-repeat:initial initial}.c-article-section{clear:both}.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:2rem;line-height:1.3;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-section__title{font-size:2.4rem;line-height:1.24}}.c-article-section__content{margin-bottom:40px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-top:0;margin-bottom:24px}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-weight:700;margin:0;padding:0;font-size:1.7rem}.c-article-authors-search__item{font-size:1.6rem}.c-article-authors-search__text{margin:0}@media only screen and (min-width:768px){.c-author-popup .c-article-authors-search__list{display:-webkit-flex;-webkit-flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-webkit-box-align:center;-webkit-align-items:center}.c-author-popup .c-article-authors-search__list-item--left{-webkit-flex-basis:40%}}.c-author-popup .c-article-authors-search__list-item--right{margin-top:16px}@media only screen and (min-width:768px){.c-author-popup .c-article-authors-search__list-item--right{text-align:right;-webkit-box-flex:1;-webkit-flex:1 1 0px;margin-top:0}}.c-article-share-box__no-sharelink-info{font-size:1.3rem;font-weight:700;padding-top:4px;margin-bottom:24px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;display:inline-block;margin-bottom:8px;font-size:1.4rem;font-weight:700;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:1.4rem;margin-bottom:8px;margin-left:10px}.c-article-body{clear:both}.c-article-body p{word-wrap:break-word}.c-pdf-download{display:-webkit-flex;margin-bottom:24px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}@media only screen and (min-width:1024px){.c-pdf-button__container{display:none}}.c-context-bar{position:relative;width:100%;-webkit-box-shadow:rgba(51,51,51,.2) 0 0 10px 0;box-shadow:0 0 10px 0 rgba(51,51,51,.2)}.c-context-bar__title{display:none}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-pdf-download__link{display:-webkit-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;-webkit-box-pack:justify;-webkit-justify-content:space-between;color:#fff;background-image:linear-gradient(#4d78af,#3365a0);border:1px solid transparent;border-top-left-radius:2px;border-top-right-radius:2px;border-bottom-right-radius:2px;border-bottom-left-radius:2px;text-decoration:none;font-size:1.6rem;line-height:1.3;-webkit-box-flex:1;-webkit-flex:1 1 0px;padding:13px 24px;background-position:initial initial;background-repeat:initial initial}.c-reading-companion{clear:both}.c-reading-companion__sticky{max-width:582px}.c-reading-companion__scroll-pane{overflow-x:hidden;overflow-y:auto;margin:0 0 16px}.c-reading-companion__tabs{font-size:1.6rem;list-style:none;display:-webkit-flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-webkit-flex-flow:row nowrap;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{-webkit-box-flex:1;-webkit-flex-grow:1}.c-reading-companion__tab{color:#069;border:1px solid #d5d5d5;border-left-width:0;background-color:#eee;padding:8px 8px 8px 15px;text-align:left;font-size:1.6rem;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{color:#222;background-color:#fcfcfc;border-bottom:1px solid #fcfcfc;font-weight:700}.c-reading-companion__references-list,.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1.6rem;padding:0}.c-reading-companion__section-item a{display:block;padding:8px 0 8px 16px;line-height:1em;overflow:hidden;white-space:nowrap;text-overflow:ellipsis}.c-reading-companion__reference-item{padding:8px 8px 8px 0;border-top:1px solid #d5d5d5;font-size:1.6rem}.c-reading-companion__reference-item:first-child{border-top-style:none}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{list-style:none;text-align:right;margin:8px 0 0;padding:0;font-weight:700;font-size:1.3rem}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__panel{display:none;border-top:1px solid #d5d5d5;margin-top:-9px;padding-top:9px}.c-reading-companion__panel--active{display:block}.c-popup-search{position:relative;z-index:10;background-color:#eee;padding:16px 0;-webkit-box-shadow:rgba(0,0,0,.207843) 0 3px 3px -3px;box-shadow:0 3px 3px -3px rgba(0,0,0,.207843)}@media only screen and (min-width:1024px){.js .c-popup-search{position:absolute;width:100%;top:100%}.c-popup-search__container{margin:auto;max-width:70%}}.app-search__content{display:-webkit-flex}.app-search__label{font-size:1.4rem;display:inline-block;color:#666;margin-bottom:8px}.app-search__input{font-size:1.4rem;border:1px solid #b3b3b3;border-top-left-radius:3px;border-bottom-left-radius:3px;vertical-align:middle;line-height:1.2;-webkit-box-shadow:rgba(0,0,0,.207843) 0 1px 3px 0 inset;box-shadow:inset 0 1px 3px 0 rgba(0,0,0,.207843);padding:.75em 1em;width:100%;-webkit-box-flex:0;-webkit-flex:0 1 auto}.app-search__button{-webkit-box-align:center;-webkit-align-items:center;cursor:pointer;display:-webkit-inline-flex;margin:0;position:relative;text-decoration:none;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:16px;line-height:1.3;-webkit-box-pack:center;-webkit-justify-content:center;padding:8px;transition:.25s ease,color .25s ease,border-color .25s ease;-webkit-transition:.25s ease,color .25s ease,border-color .25s ease;color:#fff;background-color:#33629d;background-image:linear-gradient(#4d76a9,#33629d);border:1px solid rgba(0,59,132,.498039);width:50px;text-align:center;border-top-left-radius:0;border-bottom-left-radius:0}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-display-block{display:block}.u-display-flex{display:-webkit-flex;width:100%}.u-align-items-center{-webkit-box-align:center;-webkit-align-items:center}.u-flex-static{-webkit-box-flex:0;-webkit-flex:0 1 auto;-webkit-flex:0 0 auto}.u-display-none{display:none}.js .u-js-hide{display:none;visibility:hidden}@media print{.u-hide-print{display:none}}.u-icon{fill:currentColor;-webkit-transform:translate(0);display:inline-block;vertical-align:text-top}.u-list-reset{list-style:none;margin:0;padding:0}.u-button-reset{background-color:transparent;border:0;padding:0}.u-h3{font-size:1.8rem}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-position-relative{position:relative}.u-mt-32{margin-top:32px}.u-mr-24{margin-right:24px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.u-ml-8{margin-left:8px}.u-hide{display:none;visibility:hidden}.u-visually-hidden{border:0;clip:rect(0 0 0 0);height:1px;margin:-100%;overflow:hidden;padding:0;width:1px;position:absolute!important}.hide,.js .js-hide{display:none;visibility:hidden}.c-article-section__content p{line-height:1.8}.c-reading-companion__section-item a{text-decoration:none}.c-reading-companion__sections-list{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-main-column .c-pdf-button__container .c-pdf-download{display:none}@media only screen and (max-width:1023px){.c-article-main-column .c-pdf-button__container .c-pdf-download{display:block}}</style>



    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-f182b8db52.css media="screen">
    <link rel="stylesheet" data-inline-css-source="critical-css" id="js-mustard" href="/oscar-static/app-springerlink/css/enhanced-article-3d55bb12b0.css" media="print" onload="this.media='only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)';this.onload=null">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"IT","doi":"10.1007-s10898-018-0701-7","Journal Title":"Journal of Global Optimization","Journal Id":10898,"Keywords":"Supervised learning, Deep networks, Feedforward neural networks, Global optimization, Weights optimization, Hybrid algorithms","kwrd":["Supervised_learning","Deep_networks","Feedforward_neural_networks","Global_optimization","Weights_optimization","Hybrid_algorithms"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":[],"Open Access":"N","hasAccess":"N","bypassPaywall":"N","user":{"license":{"businessPartnerID":[],"businessPartnerIDString":""}},"Access Type":"no-access","Bpids":"","Bpnames":"","BPID":["1"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10898-018-0701-7","Full HTML":"N","Subject Codes":["SCM","SCM26008","SC521000","SCM12171","SCI00001"],"pmc":["M","M26008","521000","M12171","I00001"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1573-2916","pissn":"0925-5001"},"type":"Article","category":{"pmc":{"primarySubject":"Mathematics","primarySubjectCode":"M","secondarySubjects":{"1":"Optimization","2":"Operations Research/Decision Theory","3":"Real Functions","4":"Computer Science, general"},"secondarySubjectCodes":{"1":"M26008","2":"521000","3":"M12171","4":"I00001"}},"sucode":"SC10"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10898-018-0701-7","Page":"article","page":{"attributes":{"environment":"live"}}}];
    </script>


    
    
        
            <script src=/oscar-static/js/jquery-220afd743d.js></script>
        
    

    <script data-test="onetrust-control">
        
            (function(w,d,t) {
                var assetPath = '/oscar-static/js/cookie-consent-es5-bundle-0ea0aa3601.js';
                function cc() {
                    var h = w.location.hostname,
                        e = d.createElement(t),
                        s = d.getElementsByTagName(t)[0];

                    if (h === "link.springer.com") {
                        e.src = "https://cdn.cookielaw.org/scripttemplates/otSDKStub.js";
                        e.setAttribute("data-domain-script", "4f53bc14-4ee3-45bd-9935-e3d2b6b2a543");
                    } else {
                        e.src = assetPath;
                        e.setAttribute("data-consent", h);
                    }
                    s.parentNode.insertBefore(e, s);
                }
                w.google_tag_manager ? cc() : window.addEventListener("gtm_loaded", cc);
            })(window,document,"script");
        
    </script>
    <script>
        function OptanonWrapper() {
            var elementInside = function(candidate, element) {
                if (candidate === element) {
                    return true;
                } else if (candidate.nodeName.toLowerCase() === 'body') {
                    return false;
                } else {
                    return elementInside(candidate.parentNode, element);
                }
            };

            var disclaimer = document.querySelector('.c-disclaimer[aria-hidden="false"]');
            window.dataLayer.push({event:'OneTrustGroupsUpdated'});
            if (disclaimer) {
                if (!elementInside(document.activeElement, disclaimer)) {
                    disclaimer.querySelector('button').focus();
                }
            } else {
                document.activeElement.blur();
            }
        }
    </script>

    <script>
    window.config = window.config || {};
    window.config.mustardcut = false;

    
    if (window.matchMedia && window.matchMedia('only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)').matches) {
        window.config.mustardcut = true;
    }
</script>

    <!--Polyfills CustomEvent constructor in IE. Allows us to use events to manage race conditions in client side js-->
<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>

    
    
        
            <!-- Google Tag Manager -->
            <script data-test="gtm-head">
                if (window.config.mustardcut) {
                    (function (w, d, s, l, i) {
                        w[l] = w[l] || [];
                        w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                        var f = d.getElementsByTagName(s)[0],
                                j = d.createElement(s),
                                dl = l != 'dataLayer' ? '&l=' + l : '';
                        j.async = true;
                        j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                        
                        j.addEventListener('load', function() {
                            var _ge = new CustomEvent('gtm_loaded', { bubbles: true });
                            d.dispatchEvent(_ge);
                        });
                        f.parentNode.insertBefore(j, f);
                    })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
                }
            </script>
            <!-- End Google Tag Manager -->
        
    


    <script class="js-entry">
    if (window.config.mustardcut) {
        (function(w, d) {
            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                {'src': '/oscar-static/js/polyfill-es5-bundle-974eb189f7.js', 'async': false},
                {'src': '/oscar-static/js/airbrake-es5-bundle-3beea8373b.js', 'async': false},
            ];

            var bodyScripts = [
                {'src': '/oscar-static/js/app-es5-bundle-05e3d0b21b.js', 'async': false, 'module': false},
                {'src': '/oscar-static/js/app-es6-bundle-8d5be091e0.js', 'async': false, 'module': true}
                
                
                    , {'src': '/oscar-static/js/global-article-es5-bundle-20559bc353.js', 'async': false, 'module': false},
                    {'src': '/oscar-static/js/global-article-es6-bundle-644b2aa152.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i = 0; i < headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i = 0; i < bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        })(window, document);
    }
</script>

    
    
    <link rel="canonical" href="https://link.springer.com/article/10.1007/s10898-018-0701-7"/>
    

</head>
<body class="shared-article-renderer">
    
    
    
        
            <!-- Google Tag Manager (noscript) -->
            <noscript data-test="gtm-body">
                <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
                height="0" width="0" style="display:none;visibility:hidden"></iframe>
            </noscript>
            <!-- End Google Tag Manager (noscript) -->
        
    


    <div class="u-vh-full">
        
    <div class="u-hide u-show-following-ad"></div>
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
                <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10898/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=701;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="u-icon u-flex-static u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a
                        data-test="login-link"
                        class="c-header__link"
                        href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10898-018-0701-7"
                        data-track="click"
                        data-track-category="header"
                        data-track-action="login header"
                        data-track-label="link">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="u-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            

            <div class="c-pdf-button__container">
                
            </div>

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2018-09-06" itemprop="datePublished">06 September 2018</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Global optimization issues in deep network regression: an overview</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Laura-Palagi" data-author-popup="auth-Laura-Palagi" data-corresp-id="c1">Laura Palagi<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><span class="u-js-hide"> 
            <a class="js-orcid" itemprop="url" href="http://orcid.org/0000-0002-9496-6097"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-9496-6097</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Sapienza - University of Rome" /><meta itemprop="address" content="grid.7841.a, Dip. di Ingegneria informatica automatica e gestionale A. Ruberti, Sapienza - University of Rome, Via Ariosto 25, 00185, Rome, Italy" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10898"><i data-test="journal-title">Journal of Global Optimization</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 73</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">239</span>–<span itemprop="pageEnd">277</span>(<span data-test="article-publication-year">2019</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    <div class="c-article-metrics-bar__wrapper u-clear-both">
        <ul class="c-article-metrics-bar u-list-reset">
            
                <li class=" c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__count">777 <span class="c-article-metrics-bar__label">Accesses</span></p>
                </li>
            
            
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__count">1 <span class="c-article-metrics-bar__label">Citations</span></p>
                </li>
            
            
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">1 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                    </li>
                
            
            <li class="c-article-metrics-bar__item">
                <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10898-018-0701-7/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
            </li>
        </ul>
    </div>
</div>

                        </div>
                            
    

    

                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>The paper presents an overview of global issues in optimization methods for training feedforward neural networks (FNN) in a regression setting. We first recall the learning optimization paradigm for FNN and we briefly discuss global scheme for the joint choice of the network topologies and of the network parameters. The main part of the paper focuses on the core subproblem which is the continuous unconstrained (regularized) weights optimization problem with the aim of reviewing global methods specifically arising both in multi layer perceptron/deep networks and in radial basis networks. We review some recent results on the existence of non-global stationary points of the unconstrained nonlinear problem and the role of determining a global solution in a supervised learning paradigm. Local algorithms that are widespread used to solve the continuous unconstrained problems are addressed with focus on possible improvements to exploit the global properties. Hybrid global methods specifically devised for FNN training optimization problems which embed local algorithms are discussed too.</p></div></div></section>
                    
    


                    
                        
                            <div class="c-notes">
                                <p class="c-notes__text">This is a preview of subscription content, <a id="test-login-banner-link" href="//wayf.springernature.com?redirect_uri&#x3D;https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10898-018-0701-7" data-track="click" data-track-action="login" data-track-label="link">log in</a> to check access.</p>
                            </div>
                        
                        
                            <div class="c-article-buy-box c-article-buy-box--article">
                                <div class="sprcom-buybox-articleSidebar" id="sprcom-buybox-articleSidebar">
 <h2 class="c-box__heading">Access options</h2>
 <article class="c-box" data-test-id="buy-article">
  <h3 class="c-box__heading">Buy single article</h3>
  <div class="c-box__body">
   <div class="buybox__info">
    <p>Instant access to the full article PDF.</p>
   </div>
   <div class="buybox__buy">
    <p class="buybox__price">42,64 €</p>
    <p class="buybox__price-info">Tax calculation will be finalised during checkout.</p>
    <form action="https://order.springer.com/public/checkout?utm_source=springerlink&amp;utm_medium=referral&amp;utm_campaign=sl-buybox_articlePage_article&amp;abtest=v2" method="post">
     <input type="hidden" name="type" value="article">
     <input type="hidden" name="doi" value="10.1007/s10898-018-0701-7">
     <input type="hidden" name="isxn" value="1573-2916">
     <input type="hidden" name="contenttitle" value="Global optimization issues in deep network regression: an overview">
     <input type="hidden" name="copyrightyear" value="2018">
     <input type="hidden" name="year" value="2018">
     <input type="hidden" name="authors" value="Laura Palagi">
     <input type="hidden" name="title" value="Journal of Global Optimization">
     <input type="hidden" name="mac" value="DC28390165FECC34B77A6B81654A97F0">
     <input type="submit" class="c-box__button" data-track="click" data-track-action="buy pdf" data-track-category="ppv" data-track-label="buy article action" value="Buy article PDF">
    </form>
   </div>
  </div>
 </article>
 <article class="c-box buybox__subscribe-subscription" data-test-id="journal-subscription">
  <h3 class="c-box__heading">Subscribe to journal</h3>
  <div class="c-box__body">
   <div class="buybox__info">
    <p>Immediate online access to all issues from 2019. Subscription will auto renew annually.</p>
   </div>
   <div class="buybox__buy">
    <p class="buybox__price">135,68 €</p>
    <p class="buybox__price-info">Tax calculation will be finalised during checkout.</p>
    <form action="https://order.springer.com/public/checkout?utm_source=springerlink&amp;utm_medium=referral&amp;utm_campaign=sl-buybox_articlePage_journal&amp;abtest=v2" method="post">
     <input type="hidden" name="type" value="journal">
     <input type="hidden" name="contenttitle" value="Journal of Global Optimization">
     <input type="hidden" name="journalnumber" value="10898">
     <input type="hidden" name="pricetype" value="PSE">
     <input type="hidden" name="countrycode" value="IT">
     <input type="submit" class="c-box__button" data-track="click" data-track-action="subscribe to journal" data-track-category="journal" data-track-label="subscribe action, new buybox" value="Buy journal subscription">
    </form>
   </div>
  </div>
 </article>
 <article class="c-box buybox__rent-article" id="deepdyve" style="display: none" data-test-id="journal-subscription">
  <div class="c-box__body">
   <div class="buybox__info">
    <p><a class="deepdyve-link" target="deepdyve" rel="nofollow" data-track="click" data-track-action="rent article" data-track-label="rent action, new buybox">Rent this article via DeepDyve.</a></p>
   </div>
  </div>
  <script>
            function deepDyveResponse(data) {
                if (data.status === 'ok') {
                    [].slice.call(document.querySelectorAll('.c-box.buybox__rent-article')).forEach(function (article) {
                        article.style.display = 'flex'
                        var link = article.querySelector('.deepdyve-link')
                        if (link) {
                          link.setAttribute('href', data.url)
                        }
                    })
                }
            }

            var script = document.createElement('script')
            script.src = '//www.deepdyve.com/rental-link?docId=10.1007/s10898-018-0701-7&journal=1573-2916&fieldName=journal_doi&affiliateId=springer&format=jsonp&callback=deepDyveResponse'
            document.body.appendChild(script)
          </script>
 </article>
 <aside class="buybox__institutional-sub">
  <div class="c-box__body">
   <div class="buybox__info">
    <p><a href="https://www.springernature.com/gp/librarians/licensing/license-options?utm_source=springerlink&amp;utm_medium=referral&amp;utm_campaign=sl-buybox_articlePage_institutionalCustomer&amp;abtest=v2" data-track="click" data-track-action="institutional link" data-track-label="institutional subscriptions, new buybox">Learn more about Institutional subscriptions</a></p>
   </div>
  </div>
 </aside>
 <style>.sprcom-buybox-articleSidebar{
  box-shadow: 0px 0px 5px rgba(51,51,51,0.101);
  display: flex;
  flex-wrap: wrap;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
  text-align: center;
}
.sprcom-buybox-articleSidebar *{
  box-sizing: border-box;
  line-height: calc(100% + 4px);
  margin: 0px;
}
.sprcom-buybox-articleSidebar > *{
  display: flex;
  flex-basis: 240px;
  flex-direction: column;
  flex-grow: 1;
  flex-shrink: 1;
  margin: 0.5px;
}
.sprcom-buybox-articleSidebar > *{
  box-shadow: 0 0 0 1px rgba(204,204,204,0.494);
}
.sprcom-buybox-articleSidebar .c-box__body{
  display: flex;
  flex-direction: column-reverse;
  flex-grow: 1;
  justify-content: space-between;
  padding: 6%;
}
.sprcom-buybox-articleSidebar .c-box__body .buybox__buy{
  display: flex;
  flex-direction: column-reverse;
}
.sprcom-buybox-articleSidebar p{
  color: #333;
  font-size: 15px;
}
.sprcom-buybox-articleSidebar .buybox__price{
  font-size: 24px;
  font-weight: 500;
  line-height: calc(100% + 8px);
  margin: 20px 0;
  order: 1;
}
.sprcom-buybox-articleSidebar form{
  order: 1;
}
.sprcom-buybox-articleSidebar .buybox__price-info{
  margin-bottom: 20px;
}
.sprcom-buybox-articleSidebar .c-box__heading{
  background-color: #f0f0f0;
  color: #333;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
  font-size: 16px;
  margin: 0px;
  padding: 10px 12px;
  text-align: center;
}
.sprcom-buybox-articleSidebar .c-box__button{
  background-color: #3365A4;
  border: 1px solid transparent;
  border-radius: 2px;
  color: #fff;
  cursor: pointer;
  display: inline-block;
  font-family: inherit;
  font-size: 16px;
  max-width: 222px;
  padding: 10px 12px;
  text-decoration: none;
  width: 100%;
}
.sprcom-buybox-articleSidebar h3{
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  overflow: hidden;
  position: absolute;
  width: 1px;
}
.sprcom-buybox-articleSidebar h2{
  flex-basis: 100%;
  margin-bottom: 16px;
  text-align: left;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub, .buybox__rent-article .c-box__body{
  flex-direction: row;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub, .buybox__rent-article .buybox__info{
  text-align: left;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub{
  background-color: #f0f0f0;
}
.sprcom-buybox-articleSidebar .visually-hidden{
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  overflow: hidden;
  position: absolute;
  width: 1px;
}
.sprcom-buybox-articleSidebar style{
  display: none;
}
</style>
</div>
                            </div>
                        
                        <div class="u-display-none">
                            <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><picture><source type="image/webp" srcset="//media.springernature.com/m312/springer-static/image/art%3A10.1007%2Fs10898-018-0701-7/MediaObjects/10898_2018_701_Fig1_HTML.png?as=webp"></source><img src="//media.springernature.com/m312/springer-static/image/art%3A10.1007%2Fs10898-018-0701-7/MediaObjects/10898_2018_701_Fig1_HTML.png" alt="" loading="lazy" width="312" height="139" /></picture></div></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><picture><source type="image/webp" srcset="//media.springernature.com/m312/springer-static/image/art%3A10.1007%2Fs10898-018-0701-7/MediaObjects/10898_2018_701_Fig2_HTML.png?as=webp"></source><img src="//media.springernature.com/m312/springer-static/image/art%3A10.1007%2Fs10898-018-0701-7/MediaObjects/10898_2018_701_Fig2_HTML.png" alt="" loading="lazy" width="312" height="171" /></picture></div></div></figure></div>
                        </div>
                    

                    

                    

                    <section aria-labelledby="notes" data-title="Notes"><div class="c-article-section" id="notes-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="notes">Notes</h2><div class="c-article-section__content" id="notes-content"><ol class="c-article-footnote c-article-footnote--listed"><li class="c-article-footnote--listed__item" id="Fn1"><span class="c-article-footnote--listed__index">1.</span><div class="c-article-footnote--listed__content"><p>Usually the data set is divided into <i>K</i> subsets and the average validation error across all <i>K</i> trials is computed (<i>K</i>-fold cross validation).</p></div></li><li class="c-article-footnote--listed__item" id="Fn2"><span class="c-article-footnote--listed__index">2.</span><div class="c-article-footnote--listed__content"><p>The picture has been obtained using a shallow network with <span class="mathjax-tex">\(N=100\)</span> and fixing all the weights to a given random value but the two in input-to-hidden layer</p></div></li></ol></div></div></section><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Abraham, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Abraham, A.: Meta learning evolutionary artificial neural networks. Neurocomputing 56, 1–38 (2004)" /><span class="c-article-references__counter">1.</span><p class="c-article-references__text" id="ref-CR1">Abraham, A.: Meta learning evolutionary artificial neural networks. Neurocomputing <b>56</b>, 1–38 (2004)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Meta%20learning%20evolutionary%20artificial%20neural%20networks&amp;journal=Neurocomputing&amp;volume=56&amp;pages=1-38&amp;publication_year=2004&amp;author=Abraham%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Adam, G. Magoulas, D. Karras, M. Vrahatis, " /><meta itemprop="datePublished" content="2016" /><meta itemprop="headline" content="Adam, S., Magoulas, G., Karras, D., Vrahatis, M.: Bounding the search space for global optimization of neural " /><span class="c-article-references__counter">2.</span><p class="c-article-references__text" id="ref-CR2">Adam, S., Magoulas, G., Karras, D., Vrahatis, M.: Bounding the search space for global optimization of neural networks learning error: an interval analysis approach. J. Mach. Learn. Res. <b>17</b>, 1–40 (2016)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3567437" aria-label="View reference 2 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1392.68335" aria-label="View reference 2 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Bounding%20the%20search%20space%20for%20global%20optimization%20of%20neural%20networks%20learning%20error%3A%20an%20interval%20analysis%20approach&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=17&amp;pages=1-40&amp;publication_year=2016&amp;author=Adam%2CS&amp;author=Magoulas%2CG&amp;author=Karras%2CD&amp;author=Vrahatis%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Adamu, A., Maul, T., Bargiela, A.: On training neural networks with transfer function diversity. In: Internati" /><span class="c-article-references__counter">3.</span><p class="c-article-references__text" id="ref-CR3">Adamu, A., Maul, T., Bargiela, A.: On training neural networks with transfer function diversity. In: International Conference on Computational Intelligence and Information Technology (CIIT 2013), Elsevier (2013)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Amato, B. Apolloni, G. Caporali, U. Madesani, A. Zanaboni, " /><meta itemprop="datePublished" content="1991" /><meta itemprop="headline" content="Amato, S., Apolloni, B., Caporali, G., Madesani, U., Zanaboni, A.: Simulated annealing approach in backpropaga" /><span class="c-article-references__counter">4.</span><p class="c-article-references__text" id="ref-CR4">Amato, S., Apolloni, B., Caporali, G., Madesani, U., Zanaboni, A.: Simulated annealing approach in backpropagation. Neurocomputing <b>3</b>(5), 207–220 (1991)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Simulated%20annealing%20approach%20in%20backpropagation&amp;journal=Neurocomputing&amp;volume=3&amp;issue=5&amp;pages=207-220&amp;publication_year=1991&amp;author=Amato%2CS&amp;author=Apolloni%2CB&amp;author=Caporali%2CG&amp;author=Madesani%2CU&amp;author=Zanaboni%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. An, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="An, G.: The effects of adding noise during backpropagation training on a generalization performance. Neural Co" /><span class="c-article-references__counter">5.</span><p class="c-article-references__text" id="ref-CR5">An, G.: The effects of adding noise during backpropagation training on a generalization performance. Neural Comput. <b>8</b>(3), 643–674 (1996)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20effects%20of%20adding%20noise%20during%20backpropagation%20training%20on%20a%20generalization%20performance&amp;journal=Neural%20Comput.&amp;volume=8&amp;issue=3&amp;pages=643-674&amp;publication_year=1996&amp;author=An%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Bagirov, A. Rubinov, N. Soukhoroukova, J. Yearwood, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Bagirov, A., Rubinov, A., Soukhoroukova, N., Yearwood, J.: Unsupervised and supervised data classification via" /><span class="c-article-references__counter">6.</span><p class="c-article-references__text" id="ref-CR6">Bagirov, A., Rubinov, A., Soukhoroukova, N., Yearwood, J.: Unsupervised and supervised data classification via nonsmooth and global optimization. Top <b>11</b>(1), 1–75 (2003)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1991209" aria-label="View reference 6 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1048.65059" aria-label="View reference 6 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Unsupervised%20and%20supervised%20data%20classification%20via%20nonsmooth%20and%20global%20optimization&amp;journal=Top&amp;volume=11&amp;issue=1&amp;pages=1-75&amp;publication_year=2003&amp;author=Bagirov%2CA&amp;author=Rubinov%2CA&amp;author=Soukhoroukova%2CN&amp;author=Yearwood%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Baldi, K. Hornik, " /><meta itemprop="datePublished" content="1989" /><meta itemprop="headline" content="Baldi, P., Hornik, K.: Neural networks and principal component analysis: learning from examples without local " /><span class="c-article-references__counter">7.</span><p class="c-article-references__text" id="ref-CR7">Baldi, P., Hornik, K.: Neural networks and principal component analysis: learning from examples without local minima. Neural Netw. <b>2</b>(1), 53–58 (1989)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20networks%20and%20principal%20component%20analysis%3A%20learning%20from%20examples%20without%20local%20minima&amp;journal=Neural%20Netw.&amp;volume=2&amp;issue=1&amp;pages=53-58&amp;publication_year=1989&amp;author=Baldi%2CP&amp;author=Hornik%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Baldi, Z. Lu, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Baldi, P., Lu, Z.: Complex-valued autoencoders. Neural Netw. 33, 136–147 (2012)" /><span class="c-article-references__counter">8.</span><p class="c-article-references__text" id="ref-CR8">Baldi, P., Lu, Z.: Complex-valued autoencoders. Neural Netw. <b>33</b>, 136–147 (2012)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1258.68111" aria-label="View reference 8 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Complex-valued%20autoencoders&amp;journal=Neural%20Netw.&amp;volume=33&amp;pages=136-147&amp;publication_year=2012&amp;author=Baldi%2CP&amp;author=Lu%2CZ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Baldi, P. Sadowski, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Baldi, P., Sadowski, P.: The dropout learning algorithm. Artif. Intell. 210, 78–122 (2014)" /><span class="c-article-references__counter">9.</span><p class="c-article-references__text" id="ref-CR9">Baldi, P., Sadowski, P.: The dropout learning algorithm. Artif. Intell. <b>210</b>, 78–122 (2014)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3180465" aria-label="View reference 9 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1333.68225" aria-label="View reference 9 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20dropout%20learning%20algorithm&amp;journal=Artif.%20Intell.&amp;volume=210&amp;pages=78-122&amp;publication_year=2014&amp;author=Baldi%2CP&amp;author=Sadowski%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Barhen, V. Protopopescu, D. Reister, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Barhen, J., Protopopescu, V., Reister, D.: TRUST: a deterministic algorithm for global optimization. Science 2" /><span class="c-article-references__counter">10.</span><p class="c-article-references__text" id="ref-CR10">Barhen, J., Protopopescu, V., Reister, D.: <span class="u-monospace">TRUST</span>: a deterministic algorithm for global optimization. Science <b>276</b>(5315), 1094–1097 (1997)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1446654" aria-label="View reference 10 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1226.90073" aria-label="View reference 10 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=TRUST%3A%20a%20deterministic%20algorithm%20for%20global%20optimization&amp;journal=Science&amp;volume=276&amp;issue=5315&amp;pages=1094-1097&amp;publication_year=1997&amp;author=Barhen%2CJ&amp;author=Protopopescu%2CV&amp;author=Reister%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="DM. Bates, DG. Watts, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Bates, D.M., Watts, D.G.: Nonlinear Regression Analysis and Its Applications. Wiley Series in Probability and " /><span class="c-article-references__counter">11.</span><p class="c-article-references__text" id="ref-CR11">Bates, D.M., Watts, D.G.: Nonlinear Regression Analysis and Its Applications. Wiley Series in Probability and Statistics. Wiley, Hoboken (2007)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Nonlinear%20Regression%20Analysis%20and%20Its%20Applications.%20Wiley%20Series%20in%20Probability%20and%20Statistics&amp;publication_year=2007&amp;author=Bates%2CDM&amp;author=Watts%2CDG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bengio, Y., Louradour, J., Collobert, R., Weston, J.: Curriculum learning. In: Proceedings of the 26th annual " /><span class="c-article-references__counter">12.</span><p class="c-article-references__text" id="ref-CR12">Bengio, Y., Louradour, J., Collobert, R., Weston, J.: Curriculum learning. In: Proceedings of the 26th annual international conference on machine learning, pp. 41–48. ACM (2009)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Bergstra, Y. Bengio, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Bergstra, J., Bengio, Y.: Random search for hyper-parameter optimization. J. Mach. Learn. Res. 13, 281–305 (20" /><span class="c-article-references__counter">13.</span><p class="c-article-references__text" id="ref-CR13">Bergstra, J., Bengio, Y.: Random search for hyper-parameter optimization. J. Mach. Learn. Res. <b>13</b>, 281–305 (2012)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2913701" aria-label="View reference 13 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1283.68282" aria-label="View reference 13 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Random%20search%20for%20hyper-parameter%20optimization&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=13&amp;pages=281-305&amp;publication_year=2012&amp;author=Bergstra%2CJ&amp;author=Bengio%2CY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="DP. Bertsekas, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Bertsekas, D.P.: Nonlinear Programming. Athena Scientific, Belmont (1999)" /><span class="c-article-references__counter">14.</span><p class="c-article-references__text" id="ref-CR14">Bertsekas, D.P.: Nonlinear Programming. Athena Scientific, Belmont (1999)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Nonlinear%20Programming&amp;publication_year=1999&amp;author=Bertsekas%2CDP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DP. Bertsekas, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Bertsekas, D.P.: Incremental gradient, subgradient, and proximal methods for convex optimization: a survey. Op" /><span class="c-article-references__counter">15.</span><p class="c-article-references__text" id="ref-CR15">Bertsekas, D.P.: Incremental gradient, subgradient, and proximal methods for convex optimization: a survey. Optim. Mach. Learn. <b>2010</b>(1–38), 3 (2011)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Incremental%20gradient%2C%20subgradient%2C%20and%20proximal%20methods%20for%20convex%20optimization%3A%20a%20survey&amp;journal=Optim.%20Mach.%20Learn.&amp;volume=2010&amp;issue=1%E2%80%9338&amp;publication_year=2011&amp;author=Bertsekas%2CDP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="DP. Bertsekas, JN. Tsitsiklis, " /><meta itemprop="datePublished" content="1989" /><meta itemprop="headline" content="Bertsekas, D.P., Tsitsiklis, J.N.: Parallel and Distributed Computation: Numerical Methods. Prentice-Hall, Eng" /><span class="c-article-references__counter">16.</span><p class="c-article-references__text" id="ref-CR16">Bertsekas, D.P., Tsitsiklis, J.N.: Parallel and Distributed Computation: Numerical Methods. Prentice-Hall, Englewood Cliffs (1989)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Parallel%20and%20Distributed%20Computation%3A%20Numerical%20Methods&amp;publication_year=1989&amp;author=Bertsekas%2CDP&amp;author=Tsitsiklis%2CJN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DP. Bertsekas, JN. Tsitsiklis, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Bertsekas, D.P., Tsitsiklis, J.N.: Gradient convergence in gradient methods with errors. SIAM J. Optim. 10(3)," /><span class="c-article-references__counter">17.</span><p class="c-article-references__text" id="ref-CR17">Bertsekas, D.P., Tsitsiklis, J.N.: Gradient convergence in gradient methods with errors. SIAM J. Optim. <b>10</b>(3), 627–642 (2000)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1741189" aria-label="View reference 17 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1049.90130" aria-label="View reference 17 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Gradient%20convergence%20in%20gradient%20methods%20with%20errors&amp;journal=SIAM%20J.%20Optim.&amp;volume=10&amp;issue=3&amp;pages=627-642&amp;publication_year=2000&amp;author=Bertsekas%2CDP&amp;author=Tsitsiklis%2CJN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Bertsimas, J. Dunn, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Bertsimas, D., Dunn, J.: Optimal classification trees. Mach. Learn. 106(7), 1039–1082 (2017). https://doi.org/" /><span class="c-article-references__counter">18.</span><p class="c-article-references__text" id="ref-CR18">Bertsimas, D., Dunn, J.: Optimal classification trees. Mach. Learn. <b>106</b>(7), 1039–1082 (2017). <a href="https://doi.org/10.1007/s10994-017-5633-9">https://doi.org/10.1007/s10994-017-5633-9</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3665788" aria-label="View reference 18 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?06841416" aria-label="View reference 18 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Optimal%20classification%20trees&amp;journal=Mach.%20Learn.&amp;doi=10.1007%2Fs10994-017-5633-9&amp;volume=106&amp;issue=7&amp;pages=1039-1082&amp;publication_year=2017&amp;author=Bertsimas%2CD&amp;author=Dunn%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Bertsimas, R. Shioda, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Bertsimas, D., Shioda, R.: Classification and regression via integer optimization. Oper. Res. 55(2), 252–271 (" /><span class="c-article-references__counter">19.</span><p class="c-article-references__text" id="ref-CR19">Bertsimas, D., Shioda, R.: Classification and regression via integer optimization. Oper. Res. <b>55</b>(2), 252–271 (2007)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2316258" aria-label="View reference 19 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1167.90593" aria-label="View reference 19 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Classification%20and%20regression%20via%20integer%20optimization&amp;journal=Oper.%20Res.&amp;volume=55&amp;issue=2&amp;pages=252-271&amp;publication_year=2007&amp;author=Bertsimas%2CD&amp;author=Shioda%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Bianchini, P. Frasconi, M. Gori, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Bianchini, M., Frasconi, P., Gori, M.: Learning without local minima in radial basis function networks. IEEE T" /><span class="c-article-references__counter">20.</span><p class="c-article-references__text" id="ref-CR20">Bianchini, M., Frasconi, P., Gori, M.: Learning without local minima in radial basis function networks. IEEE Trans. Neural Netw. <b>6</b>(3), 749–756 (1995)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20without%20local%20minima%20in%20radial%20basis%20function%20networks&amp;journal=IEEE%20Trans.%20Neural%20Netw.&amp;volume=6&amp;issue=3&amp;pages=749-756&amp;publication_year=1995&amp;author=Bianchini%2CM&amp;author=Frasconi%2CP&amp;author=Gori%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Bishop, " /><meta itemprop="datePublished" content="1991" /><meta itemprop="headline" content="Bishop, C.: Improving the generalization properties of radial basis function neural networks. Neural Comput. 3" /><span class="c-article-references__counter">21.</span><p class="c-article-references__text" id="ref-CR21">Bishop, C.: Improving the generalization properties of radial basis function neural networks. Neural Comput. <b>3</b>(4), 579–588 (1991)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Improving%20the%20generalization%20properties%20of%20radial%20basis%20function%20neural%20networks&amp;journal=Neural%20Comput.&amp;volume=3&amp;issue=4&amp;pages=579-588&amp;publication_year=1991&amp;author=Bishop%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bishop, C.: Pattern Recognition and Machine Learning (Information Science and Statistics), 1st edn. 2006. corr" /><span class="c-article-references__counter">22.</span><p class="c-article-references__text" id="ref-CR22">Bishop, C.: Pattern Recognition and Machine Learning (Information Science and Statistics), 1st edn. 2006. corr. 2nd printing edn (2007)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Blum, A., Rivest, R.L.: Training a 3-node neural network is NP-complete. In: Proceedings of the 1st Internatio" /><span class="c-article-references__counter">23.</span><p class="c-article-references__text" id="ref-CR23">Blum, A., Rivest, R.L.: Training a 3-node neural network is NP-complete. In: Proceedings of the 1st International Conference on Neural Information Processing Systems, pp. 494–501. MIT Press (1988)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Blundell, C., Cornebise, J., Kavukcuoglu, K., Wierstra, D.: Weight uncertainty in neural networks (2015). arXi" /><span class="c-article-references__counter">24.</span><p class="c-article-references__text" id="ref-CR24">Blundell, C., Cornebise, J., Kavukcuoglu, K., Wierstra, D.: Weight uncertainty in neural networks (2015). arXiv preprint <a href="http://arxiv.org/abs/1505.05424">arXiv:1505.05424</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bottou, L., Bousquet, O.: The tradeoffs of large scale learning. In: Proceedings of the 20th International Con" /><span class="c-article-references__counter">25.</span><p class="c-article-references__text" id="ref-CR25">Bottou, L., Bousquet, O.: The tradeoffs of large scale learning. In: Proceedings of the 20th International Conference on Neural Information Processing Systems, NIPS’07, pp. 161–168. Curran Associates Inc., USA (2007). <a href="http://dl.acm.org/citation.cfm?id=2981562.2981583">http://dl.acm.org/citation.cfm?id=2981562.2981583</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Bottou, FE. Curtis, J. Nocedal, " /><meta itemprop="datePublished" content="2018" /><meta itemprop="headline" content="Bottou, L., Curtis, F.E., Nocedal, J.: Optimization methods for large-scale machine learning. SIAM Rev. 60(2)," /><span class="c-article-references__counter">26.</span><p class="c-article-references__text" id="ref-CR26">Bottou, L., Curtis, F.E., Nocedal, J.: Optimization methods for large-scale machine learning. SIAM Rev. <b>60</b>(2), 223–311 (2018)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3797719" aria-label="View reference 26 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1397.65085" aria-label="View reference 26 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Optimization%20methods%20for%20large-scale%20machine%20learning&amp;journal=SIAM%20Rev.&amp;volume=60&amp;issue=2&amp;pages=223-311&amp;publication_year=2018&amp;author=Bottou%2CL&amp;author=Curtis%2CFE&amp;author=Nocedal%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Boubezoul, S. Paris, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Boubezoul, A., Paris, S.: Application of global optimization methods to model and feature selection. Pattern R" /><span class="c-article-references__counter">27.</span><p class="c-article-references__text" id="ref-CR27">Boubezoul, A., Paris, S.: Application of global optimization methods to model and feature selection. Pattern Recognit. <b>45</b>(10), 3676–3686 (2012)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1242.68207" aria-label="View reference 27 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 27 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Application%20of%20global%20optimization%20methods%20to%20model%20and%20feature%20selection&amp;journal=Pattern%20Recognit.&amp;volume=45&amp;issue=10&amp;pages=3676-3686&amp;publication_year=2012&amp;author=Boubezoul%2CA&amp;author=Paris%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Branke, J.: Evolutionary algorithms for neural network design and training. In: Proceedings of the First Nordi" /><span class="c-article-references__counter">28.</span><p class="c-article-references__text" id="ref-CR28">Branke, J.: Evolutionary algorithms for neural network design and training. In: Proceedings of the First Nordic Workshop on Genetic Algorithms and its Applications, pp. 145–163 (1995)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Bravi, V. Piccialli, M. Sciandrone, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Bravi, L., Piccialli, V., Sciandrone, M.: An optimization-based method for feature ranking in nonlinear regres" /><span class="c-article-references__counter">29.</span><p class="c-article-references__text" id="ref-CR29">Bravi, L., Piccialli, V., Sciandrone, M.: An optimization-based method for feature ranking in nonlinear regression problems. IEEE Trans. Neural Netw. Learn. Syst. <b>28</b>(4), 1005–1010 (2017)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 29 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20optimization-based%20method%20for%20feature%20ranking%20in%20nonlinear%20regression%20problems&amp;journal=IEEE%20Trans.%20Neural%20Netw.%20Learn.%20Syst.&amp;volume=28&amp;issue=4&amp;pages=1005-1010&amp;publication_year=2017&amp;author=Bravi%2CL&amp;author=Piccialli%2CV&amp;author=Sciandrone%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="AJ. Bray, DS. Dean, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Bray, A.J., Dean, D.S.: Statistics of critical points of Gaussian fields on large-dimensional spaces. Phys. Re" /><span class="c-article-references__counter">30.</span><p class="c-article-references__text" id="ref-CR30">Bray, A.J., Dean, D.S.: Statistics of critical points of Gaussian fields on large-dimensional spaces. Phys. Rev. Lett. <b>98</b>(15), 150 201 (2007)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Statistics%20of%20critical%20points%20of%20Gaussian%20fields%20on%20large-dimensional%20spaces&amp;journal=Phys.%20Rev.%20Lett.&amp;volume=98&amp;issue=15&amp;publication_year=2007&amp;author=Bray%2CAJ&amp;author=Dean%2CDS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Breuel, T.M.: On the convergence of SGD training of neural networks (2015). arXiv preprint arXiv:1508.02790&#xA;  " /><span class="c-article-references__counter">31.</span><p class="c-article-references__text" id="ref-CR31">Breuel, T.M.: On the convergence of SGD training of neural networks (2015). arXiv preprint <a href="http://arxiv.org/abs/1508.02790">arXiv:1508.02790</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="O. Buchtala, M. Klimek, B. Sick, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Buchtala, O., Klimek, M., Sick, B.: Evolutionary optimization of radial basis function classifiers for data mi" /><span class="c-article-references__counter">32.</span><p class="c-article-references__text" id="ref-CR32">Buchtala, O., Klimek, M., Sick, B.: Evolutionary optimization of radial basis function classifiers for data mining applications. IEEE Trans. Syst. Man Cybern. Part B (Cybern.) <b>35</b>(5), 928–947 (2005)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Evolutionary%20optimization%20of%20radial%20basis%20function%20classifiers%20for%20data%20mining%20applications&amp;journal=IEEE%20Trans.%20Syst.%20Man%20Cybern.%20Part%20B%20%28Cybern.%29&amp;volume=35&amp;issue=5&amp;pages=928-947&amp;publication_year=2005&amp;author=Buchtala%2CO&amp;author=Klimek%2CM&amp;author=Sick%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="CJ. Burges, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Burges, C.J.: A tutorial on support vector machines for pattern recognition. Data Min. Knowl. Discov. 2(2), 12" /><span class="c-article-references__counter">33.</span><p class="c-article-references__text" id="ref-CR33">Burges, C.J.: A tutorial on support vector machines for pattern recognition. Data Min. Knowl. Discov. <b>2</b>(2), 121–167 (1998)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 33 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20tutorial%20on%20support%20vector%20machines%20for%20pattern%20recognition&amp;journal=Data%20Min.%20Knowl.%20Discov.&amp;volume=2&amp;issue=2&amp;pages=121-167&amp;publication_year=1998&amp;author=Burges%2CCJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Buzzi, L. Grippo, M. Sciandrone, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Buzzi, C., Grippo, L., Sciandrone, M.: Convergent decomposition techniques for training RBF neural networks. N" /><span class="c-article-references__counter">34.</span><p class="c-article-references__text" id="ref-CR34">Buzzi, C., Grippo, L., Sciandrone, M.: Convergent decomposition techniques for training RBF neural networks. Neural Comput. <b>13</b>(8), 1891–1920 (2001)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0986.68109" aria-label="View reference 34 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 34 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Convergent%20decomposition%20techniques%20for%20training%20RBF%20neural%20networks&amp;journal=Neural%20Comput.&amp;volume=13&amp;issue=8&amp;pages=1891-1920&amp;publication_year=2001&amp;author=Buzzi%2CC&amp;author=Grippo%2CL&amp;author=Sciandrone%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="E. Carrizosa, B. Martín-Barragán, DR. Morales, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Carrizosa, E., Martín-Barragán, B., Morales, D.R.: A nested heuristic for parameter tuning in support vector m" /><span class="c-article-references__counter">35.</span><p class="c-article-references__text" id="ref-CR35">Carrizosa, E., Martín-Barragán, B., Morales, D.R.: A nested heuristic for parameter tuning in support vector machines. Comput. Oper. Res. <b>43</b>, 328–334 (2014)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3134409" aria-label="View reference 35 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1349.62260" aria-label="View reference 35 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 35 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20nested%20heuristic%20for%20parameter%20tuning%20in%20support%20vector%20machines&amp;journal=Comput.%20Oper.%20Res.&amp;volume=43&amp;pages=328-334&amp;publication_year=2014&amp;author=Carrizosa%2CE&amp;author=Mart%C3%ADn-Barrag%C3%A1n%2CB&amp;author=Morales%2CDR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="E. Carrizosa, DR. Morales, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Carrizosa, E., Morales, D.R.: Supervised classification and mathematical optimization. Comput. Oper. Res. 40(1" /><span class="c-article-references__counter">36.</span><p class="c-article-references__text" id="ref-CR36">Carrizosa, E., Morales, D.R.: Supervised classification and mathematical optimization. Comput. Oper. Res. <b>40</b>(1), 150–165 (2013)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2979101" aria-label="View reference 36 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1349.68135" aria-label="View reference 36 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 36 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Supervised%20classification%20and%20mathematical%20optimization&amp;journal=Comput.%20Oper.%20Res.&amp;volume=40&amp;issue=1&amp;pages=150-165&amp;publication_year=2013&amp;author=Carrizosa%2CE&amp;author=Morales%2CDR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="B. Cetin, J. Barhen, J. Burdick, " /><meta itemprop="datePublished" content="1993" /><meta itemprop="headline" content="Cetin, B., Barhen, J., Burdick, J.: Terminal repeller unconstrained subenergy tunneling ( trust) for fast glob" /><span class="c-article-references__counter">37.</span><p class="c-article-references__text" id="ref-CR37">Cetin, B., Barhen, J., Burdick, J.: Terminal repeller unconstrained subenergy tunneling ( trust) for fast global optimization. J. Optim. Theory Appl. <b>77</b>(1), 97–126 (1993)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1222786" aria-label="View reference 37 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0801.49001" aria-label="View reference 37 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 37 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Terminal%20repeller%20unconstrained%20subenergy%20tunneling%20%28%20trust%29%20for%20fast%20global%20optimization&amp;journal=J.%20Optim.%20Theory%20Appl.&amp;volume=77&amp;issue=1&amp;pages=97-126&amp;publication_year=1993&amp;author=Cetin%2CB&amp;author=Barhen%2CJ&amp;author=Burdick%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cetin, B.C., Burdick, J.W., Barhen, J.: Global descent replaces gradient descent to avoid local minima problem" /><span class="c-article-references__counter">38.</span><p class="c-article-references__text" id="ref-CR38">Cetin, B.C., Burdick, J.W., Barhen, J.: Global descent replaces gradient descent to avoid local minima problem in learning with artificial neural networks. In: IEEE International Conference onNeural Networks, 1993, pp. 836–842. IEEE (1993)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Chandrashekar, F. Sahin, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Chandrashekar, G., Sahin, F.: A survey on feature selection methods. Comput. Electr. Eng. 40(1), 16–28 (2014)" /><span class="c-article-references__counter">39.</span><p class="c-article-references__text" id="ref-CR39">Chandrashekar, G., Sahin, F.: A survey on feature selection methods. Comput. Electr. Eng. <b>40</b>(1), 16–28 (2014)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 39 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20survey%20on%20feature%20selection%20methods&amp;journal=Comput.%20Electr.%20Eng.&amp;volume=40&amp;issue=1&amp;pages=16-28&amp;publication_year=2014&amp;author=Chandrashekar%2CG&amp;author=Sahin%2CF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Chao, J., Hoshino, M., Kitamura, T., Masuda, T.: A multilayer RBF network and its supervised learning. In: Int" /><span class="c-article-references__counter">40.</span><p class="c-article-references__text" id="ref-CR40">Chao, J., Hoshino, M., Kitamura, T., Masuda, T.: A multilayer RBF network and its supervised learning. In: International Joint Conference on Neural Networks, 2001 (IJCNN’01), Proceedings, vol. 3, pp. 1995–2000. IEEE (2001)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="O. Chapelle, V. Sindhwani, SS. Keerthi, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Chapelle, O., Sindhwani, V., Keerthi, S.S.: Optimization techniques for semi-supervised support vector machine" /><span class="c-article-references__counter">41.</span><p class="c-article-references__text" id="ref-CR41">Chapelle, O., Sindhwani, V., Keerthi, S.S.: Optimization techniques for semi-supervised support vector machines. J. Mach. Learn. Res. <b>9</b>, 203–233 (2008)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1225.68158" aria-label="View reference 41 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 41 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Optimization%20techniques%20for%20semi-supervised%20support%20vector%20machines&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=9&amp;pages=203-233&amp;publication_year=2008&amp;author=Chapelle%2CO&amp;author=Sindhwani%2CV&amp;author=Keerthi%2CSS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Chen, Y. Wu, B. Luk, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Chen, S., Wu, Y., Luk, B.: Combined genetic algorithm optimization and regularized orthogonal least squares le" /><span class="c-article-references__counter">42.</span><p class="c-article-references__text" id="ref-CR42">Chen, S., Wu, Y., Luk, B.: Combined genetic algorithm optimization and regularized orthogonal least squares learning for radial basis function networks. IEEE Trans. Neural Netw. <b>10</b>(5), 1239–1243 (1999)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 42 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Combined%20genetic%20algorithm%20optimization%20and%20regularized%20orthogonal%20least%20squares%20learning%20for%20radial%20basis%20function%20networks&amp;journal=IEEE%20Trans.%20Neural%20Netw.&amp;volume=10&amp;issue=5&amp;pages=1239-1243&amp;publication_year=1999&amp;author=Chen%2CS&amp;author=Wu%2CY&amp;author=Luk%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Chiang, H.D., Reddy, C.K.: TRUST-TECH based neural network training. In: International Joint Conference on Neu" /><span class="c-article-references__counter">43.</span><p class="c-article-references__text" id="ref-CR43">Chiang, H.D., Reddy, C.K.: <span class="u-monospace">TRUST-TECH</span> based neural network training. In: International Joint Conference on Neural Networks, 2007. (IJCNN 2007), pp. 90–95. IEEE (2007)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Sy. Cho, TW. Chow, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Cho, Sy, Chow, T.W.: Training multilayer neural networks using fast global learning algorithm—least-squares an" /><span class="c-article-references__counter">44.</span><p class="c-article-references__text" id="ref-CR44">Cho, Sy, Chow, T.W.: Training multilayer neural networks using fast global learning algorithm—least-squares and penalized optimization methods. Neurocomputing <b>25</b>(1), 115–131 (1999)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0941.68110" aria-label="View reference 44 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 44 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Training%20multilayer%20neural%20networks%20using%20fast%20global%20learning%20algorithm%E2%80%94least-squares%20and%20penalized%20optimization%20methods&amp;journal=Neurocomputing&amp;volume=25&amp;issue=1&amp;pages=115-131&amp;publication_year=1999&amp;author=Cho%2CSy&amp;author=Chow%2CTW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Choromanska, A., Henaff, M., Mathieu, M., Arous, G.B., LeCun, Y.: The loss surfaces of multilayer networks. In" /><span class="c-article-references__counter">45.</span><p class="c-article-references__text" id="ref-CR45">Choromanska, A., Henaff, M., Mathieu, M., Arous, G.B., LeCun, Y.: The loss surfaces of multilayer networks. In: AISTATS (2015)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Choromanska, A., LeCun, Y., Arous, G.B.: Open problem: the landscape of the loss surfaces of multilayer networ" /><span class="c-article-references__counter">46.</span><p class="c-article-references__text" id="ref-CR46">Choromanska, A., LeCun, Y., Arous, G.B.: Open problem: the landscape of the loss surfaces of multilayer networks. In: COLT, pp. 1756–1760 (2015)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cohen, S., Intrator, N.: Global optimization of RBF networks (2000). http://citeseerx.ist.psu.edu/viewdoc/summ" /><span class="c-article-references__counter">47.</span><p class="c-article-references__text" id="ref-CR47">Cohen, S., Intrator, N.: Global optimization of RBF networks (2000). <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.31.5955">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.31.5955</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Cohen, N. Intrator, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Cohen, S., Intrator, N.: A hybrid projection-based and radial basis function architecture: initial values and " /><span class="c-article-references__counter">48.</span><p class="c-article-references__text" id="ref-CR48">Cohen, S., Intrator, N.: A hybrid projection-based and radial basis function architecture: initial values and global optimisation. Pattern Anal. Appl. <b>5</b>(2), 113–120 (2002)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1930442" aria-label="View reference 48 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1024.68091" aria-label="View reference 48 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 48 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20hybrid%20projection-based%20and%20radial%20basis%20function%20architecture%3A%20initial%20values%20and%20global%20optimisation&amp;journal=Pattern%20Anal.%20Appl.&amp;volume=5&amp;issue=2&amp;pages=113-120&amp;publication_year=2002&amp;author=Cohen%2CS&amp;author=Intrator%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Q. Dai, Z. Ma, Q. Xie, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Dai, Q., Ma, Z., Xie, Q.: A two-phased and ensemble scheme integrated backpropagation algorithm. Appl. Soft Co" /><span class="c-article-references__counter">49.</span><p class="c-article-references__text" id="ref-CR49">Dai, Q., Ma, Z., Xie, Q.: A two-phased and ensemble scheme integrated backpropagation algorithm. Appl. Soft Comput. <b>24</b>, 1124–1135 (2014)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 49 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20two-phased%20and%20ensemble%20scheme%20integrated%20backpropagation%20algorithm&amp;journal=Appl.%20Soft%20Comput.&amp;volume=24&amp;pages=1124-1135&amp;publication_year=2014&amp;author=Dai%2CQ&amp;author=Ma%2CZ&amp;author=Xie%2CQ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dauphin, Y.N., Pascanu, R., Gulcehre, C., Cho, K., Ganguli, S., Bengio, Y.: Identifying and attacking the sadd" /><span class="c-article-references__counter">50.</span><p class="c-article-references__text" id="ref-CR50">Dauphin, Y.N., Pascanu, R., Gulcehre, C., Cho, K., Ganguli, S., Bengio, Y.: Identifying and attacking the saddle point problem in high-dimensional non-convex optimization. In: Advances in neural information processing systems, pp. 2933–2941 (2014)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="David, O.E., Greental, I.: Genetic algorithms for evolving deep neural networks. In: Proceedings of the Compan" /><span class="c-article-references__counter">51.</span><p class="c-article-references__text" id="ref-CR51">David, O.E., Greental, I.: Genetic algorithms for evolving deep neural networks. In: Proceedings of the Companion Publication of the 2014 Annual Conference on Genetic and Evolutionary Computation, pp. 1451–1452. ACM (2014)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Dietterich, T.G.: Ensemble methods in machine learning. In: International workshop on multiple classifier syst" /><span class="c-article-references__counter">52.</span><p class="c-article-references__text" id="ref-CR52">Dietterich, T.G.: Ensemble methods in machine learning. In: International workshop on multiple classifier systems, pp. 1–15. Springer (2000)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="AP. Duarte Silva, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Duarte Silva, A.P.: Optimization approaches to supervised classification. Eur. J. Oper. Res. 261(2), 772–788 (" /><span class="c-article-references__counter">53.</span><p class="c-article-references__text" id="ref-CR53">Duarte Silva, A.P.: Optimization approaches to supervised classification. Eur. J. Oper. Res. <b>261</b>(2), 772–788 (2017)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3634663" aria-label="View reference 53 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?06875900" aria-label="View reference 53 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 53 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Optimization%20approaches%20to%20supervised%20classification&amp;journal=Eur.%20J.%20Oper.%20Res.&amp;volume=261&amp;issue=2&amp;pages=772-788&amp;publication_year=2017&amp;author=Duarte%20Silva%2CAP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="W. Duch, N. Jankowski, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Duch, W., Jankowski, N.: New neural transfer functions. Appl. Math. Comput. Sci. 7, 639–658 (1997)" /><span class="c-article-references__counter">54.</span><p class="c-article-references__text" id="ref-CR54">Duch, W., Jankowski, N.: New neural transfer functions. Appl. Math. Comput. Sci. <b>7</b>, 639–658 (1997)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1631627" aria-label="View reference 54 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0902.68168" aria-label="View reference 54 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 54 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=New%20neural%20transfer%20functions&amp;journal=Appl.%20Math.%20Comput.%20Sci.&amp;volume=7&amp;pages=639-658&amp;publication_year=1997&amp;author=Duch%2CW&amp;author=Jankowski%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="W. Duch, N. Jankowski, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Duch, W., Jankowski, N.: Survey of neural transfer functions. Neural Comput. Surv. 2(1), 163–212 (1999)" /><span class="c-article-references__counter">55.</span><p class="c-article-references__text" id="ref-CR55">Duch, W., Jankowski, N.: Survey of neural transfer functions. Neural Comput. Surv. <b>2</b>(1), 163–212 (1999)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 55 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Survey%20of%20neural%20transfer%20functions&amp;journal=Neural%20Comput.%20Surv.&amp;volume=2&amp;issue=1&amp;pages=163-212&amp;publication_year=1999&amp;author=Duch%2CW&amp;author=Jankowski%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="W. Duch, J. Korczak, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Duch, W., Korczak, J.: Optimization and global minimization methods suitable for neural networks. Neural Compu" /><span class="c-article-references__counter">56.</span><p class="c-article-references__text" id="ref-CR56">Duch, W., Korczak, J.: Optimization and global minimization methods suitable for neural networks. Neural Comput. Surv. <b>2</b>, 163–212 (1998)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 56 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Optimization%20and%20global%20minimization%20methods%20suitable%20for%20neural%20networks&amp;journal=Neural%20Comput.%20Surv.&amp;volume=2&amp;pages=163-212&amp;publication_year=1998&amp;author=Duch%2CW&amp;author=Korczak%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Feng-wen, H., Ai-ping, J.: An improved method of wavelet neural network optimization based on filled function " /><span class="c-article-references__counter">57.</span><p class="c-article-references__text" id="ref-CR57">Feng-wen, H., Ai-ping, J.: An improved method of wavelet neural network optimization based on filled function method. In: 16th International Conference on Industrial Engineering and Engineering Management, 2009 (IE&amp;EM’09), pp. 1694–1697. IEEE (2009)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Fischetti, " /><meta itemprop="datePublished" content="2016" /><meta itemprop="headline" content="Fischetti, M.: Fast training of support vector machines with gaussian kernel. Discrete Optim. 22, 183–194 (201" /><span class="c-article-references__counter">58.</span><p class="c-article-references__text" id="ref-CR58">Fischetti, M.: Fast training of support vector machines with gaussian kernel. Discrete Optim. <b>22</b>, 183–194 (2016)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3556046" aria-label="View reference 58 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1387.68197" aria-label="View reference 58 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 58 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Fast%20training%20of%20support%20vector%20machines%20with%20gaussian%20kernel&amp;journal=Discrete%20Optim.&amp;volume=22&amp;pages=183-194&amp;publication_year=2016&amp;author=Fischetti%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="CA. Floudas, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Floudas, C.A.: Deterministic Global Optimization: Theory, Methods and Applications, vol. 37. Springer, Berlin " /><span class="c-article-references__counter">59.</span><p class="c-article-references__text" id="ref-CR59">Floudas, C.A.: Deterministic Global Optimization: Theory, Methods and Applications, vol. 37. Springer, Berlin (2013)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 59 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Deterministic%20Global%20Optimization%3A%20Theory%2C%20Methods%20and%20Applications&amp;publication_year=2013&amp;author=Floudas%2CCA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="K. Fukumizu, Si. Amari, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Fukumizu, K., Amari, Si: Local minima and plateaus in hierarchical structures of multilayer perceptrons. Neura" /><span class="c-article-references__counter">60.</span><p class="c-article-references__text" id="ref-CR60">Fukumizu, K., Amari, Si: Local minima and plateaus in hierarchical structures of multilayer perceptrons. Neural Netw. <b>13</b>(3), 317–327 (2000)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 60 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Local%20minima%20and%20plateaus%20in%20hierarchical%20structures%20of%20multilayer%20perceptrons&amp;journal=Neural%20Netw.&amp;volume=13&amp;issue=3&amp;pages=317-327&amp;publication_year=2000&amp;author=Fukumizu%2CK&amp;author=Amari%2CSi">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Ge, " /><meta itemprop="datePublished" content="1990" /><meta itemprop="headline" content="Ge, R.: A filled function method for finding a global minimizer of a function of several variables. Math. Prog" /><span class="c-article-references__counter">61.</span><p class="c-article-references__text" id="ref-CR61">Ge, R.: A filled function method for finding a global minimizer of a function of several variables. Math. Program. <b>46</b>(1–3), 191–204 (1990)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1047374" aria-label="View reference 61 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0694.90083" aria-label="View reference 61 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 61 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20filled%20function%20method%20for%20finding%20a%20global%20minimizer%20of%20a%20function%20of%20several%20variables&amp;journal=Math.%20Program.&amp;volume=46&amp;issue=1%E2%80%933&amp;pages=191-204&amp;publication_year=1990&amp;author=Ge%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. González, I. Rojas, J. Ortega, H. Pomares, FJ. Fernandez, AF. Díaz, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="González, J., Rojas, I., Ortega, J., Pomares, H., Fernandez, F.J., Díaz, A.F.: Multiobjective evolutionary opt" /><span class="c-article-references__counter">62.</span><p class="c-article-references__text" id="ref-CR62">González, J., Rojas, I., Ortega, J., Pomares, H., Fernandez, F.J., Díaz, A.F.: Multiobjective evolutionary optimization of the size, shape, and position parameters of radial basis function networks for function approximation. IEEE Trans. Neural Netw. <b>14</b>(6), 1478–1495 (2003)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 62 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Multiobjective%20evolutionary%20optimization%20of%20the%20size%2C%20shape%2C%20and%20position%20parameters%20of%20radial%20basis%20function%20networks%20for%20function%20approximation&amp;journal=IEEE%20Trans.%20Neural%20Netw.&amp;volume=14&amp;issue=6&amp;pages=1478-1495&amp;publication_year=2003&amp;author=Gonz%C3%A1lez%2CJ&amp;author=Rojas%2CI&amp;author=Ortega%2CJ&amp;author=Pomares%2CH&amp;author=Fernandez%2CFJ&amp;author=D%C3%ADaz%2CAF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="I. Goodfellow, Y. Bengio, A. Courville, " /><meta itemprop="datePublished" content="2016" /><meta itemprop="headline" content="Goodfellow, I., Bengio, Y., Courville, A.: Deep Learning. MIT Press, Cambridge (2016)" /><span class="c-article-references__counter">63.</span><p class="c-article-references__text" id="ref-CR63">Goodfellow, I., Bengio, Y., Courville, A.: Deep Learning. MIT Press, Cambridge (2016)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 63 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20Learning&amp;publication_year=2016&amp;author=Goodfellow%2CI&amp;author=Bengio%2CY&amp;author=Courville%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Goodfellow, I.J., Vinyals, O.: Qualitatively characterizing neural network optimization problems. CoRR (2014)." /><span class="c-article-references__counter">64.</span><p class="c-article-references__text" id="ref-CR64">Goodfellow, I.J., Vinyals, O.: Qualitatively characterizing neural network optimization problems. CoRR (2014). <a href="http://arxiv.org/abs/1412.6544">http://arxiv.org/abs/1412.6544</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Gori, A. Tesi, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Gori, M., Tesi, A.: On the problem of local minima in backpropagation. IEEE Trans. Pattern Anal. Mach. Intell." /><span class="c-article-references__counter">65.</span><p class="c-article-references__text" id="ref-CR65">Gori, M., Tesi, A.: On the problem of local minima in backpropagation. IEEE Trans. Pattern Anal. Mach. Intell. <b>14</b>(1), 76–86 (1992)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 65 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20the%20problem%20of%20local%20minima%20in%20backpropagation&amp;journal=IEEE%20Trans.%20Pattern%20Anal.%20Mach.%20Intell.&amp;volume=14&amp;issue=1&amp;pages=76-86&amp;publication_year=1992&amp;author=Gori%2CM&amp;author=Tesi%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gorse, D., Shepherd, A.J., Taylor, J.G.: Avoiding local minima by a classical range expansion algorithm. In: I" /><span class="c-article-references__counter">66.</span><p class="c-article-references__text" id="ref-CR66">Gorse, D., Shepherd, A.J., Taylor, J.G.: Avoiding local minima by a classical range expansion algorithm. In: ICANN94, pp. 525–528. Springer, London (1994)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Gorse, D., Shepherd, A.J., Taylor, J.G.: A classical algorithm for avoiding local minima. In: Proceedings of t" /><span class="c-article-references__counter">67.</span><p class="c-article-references__text" id="ref-CR67">Gorse, D., Shepherd, A.J., Taylor, J.G.: A classical algorithm for avoiding local minima. In: Proceedings of the World Congress on Neural Networks, pp. 364–369. Citeseer (1994)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Gorse, AJ. Shepherd, JG. Taylor, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Gorse, D., Shepherd, A.J., Taylor, J.G.: The new ERA in supervised learning. Neural Netw. 10(2), 343–352 (1997" /><span class="c-article-references__counter">68.</span><p class="c-article-references__text" id="ref-CR68">Gorse, D., Shepherd, A.J., Taylor, J.G.: The new ERA in supervised learning. Neural Netw. <b>10</b>(2), 343–352 (1997)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 68 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20new%20ERA%20in%20supervised%20learning&amp;journal=Neural%20Netw.&amp;volume=10&amp;issue=2&amp;pages=343-352&amp;publication_year=1997&amp;author=Gorse%2CD&amp;author=Shepherd%2CAJ&amp;author=Taylor%2CJG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Graves, A.: Practical variational inference for neural networks. In: Advances in Neural Information Processing" /><span class="c-article-references__counter">69.</span><p class="c-article-references__text" id="ref-CR69">Graves, A.: Practical variational inference for neural networks. In: Advances in Neural Information Processing Systems, pp. 2348–2356 (2011)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Grippo, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Grippo, L.: Convergent on-line algorithms for supervised learning in neural networks. IEEE Trans. Neural Netw." /><span class="c-article-references__counter">70.</span><p class="c-article-references__text" id="ref-CR70">Grippo, L.: Convergent on-line algorithms for supervised learning in neural networks. IEEE Trans. Neural Netw. <b>11</b>(6), 1284–1299 (2000)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 70 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Convergent%20on-line%20algorithms%20for%20supervised%20learning%20in%20neural%20networks&amp;journal=IEEE%20Trans.%20Neural%20Netw.&amp;volume=11&amp;issue=6&amp;pages=1284-1299&amp;publication_year=2000&amp;author=Grippo%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Grippo, A. Manno, M. Sciandrone, " /><meta itemprop="datePublished" content="2016" /><meta itemprop="headline" content="Grippo, L., Manno, A., Sciandrone, M.: Decomposition techniques for multilayer perceptron training. IEEE Trans" /><span class="c-article-references__counter">71.</span><p class="c-article-references__text" id="ref-CR71">Grippo, L., Manno, A., Sciandrone, M.: Decomposition techniques for multilayer perceptron training. IEEE Trans. Neural Netw. Learn. Syst. <b>27</b>(11), 2146–2159 (2016)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3571596" aria-label="View reference 71 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 71 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Decomposition%20techniques%20for%20multilayer%20perceptron%20training&amp;journal=IEEE%20Trans.%20Neural%20Netw.%20Learn.%20Syst.&amp;volume=27&amp;issue=11&amp;pages=2146-2159&amp;publication_year=2016&amp;author=Grippo%2CL&amp;author=Manno%2CA&amp;author=Sciandrone%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Grippo, M. Sciandrone, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Grippo, L., Sciandrone, M.: Globally convergent block-coordinate techniques for unconstrained optimization. Op" /><span class="c-article-references__counter">72.</span><p class="c-article-references__text" id="ref-CR72">Grippo, L., Sciandrone, M.: Globally convergent block-coordinate techniques for unconstrained optimization. Optim. Methods Softw. <b>10</b>(4), 587–637 (1999)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1694581" aria-label="View reference 72 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0940.65070" aria-label="View reference 72 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 72 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Globally%20convergent%20block-coordinate%20techniques%20for%20unconstrained%20optimization&amp;journal=Optim.%20Methods%20Softw.&amp;volume=10&amp;issue=4&amp;pages=587-637&amp;publication_year=1999&amp;author=Grippo%2CL&amp;author=Sciandrone%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Grippo, M. Sciandrone, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Grippo, L., Sciandrone, M.: Nonmonotone globalization techniques for the Barzilai–Borwein gradient method. Com" /><span class="c-article-references__counter">73.</span><p class="c-article-references__text" id="ref-CR73">Grippo, L., Sciandrone, M.: Nonmonotone globalization techniques for the Barzilai–Borwein gradient method. Comput. Optim. Appl. <b>23</b>(2), 143–169 (2002)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1937087" aria-label="View reference 73 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1028.90061" aria-label="View reference 73 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 73 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Nonmonotone%20globalization%20techniques%20for%20the%20Barzilai%E2%80%93Borwein%20gradient%20method&amp;journal=Comput.%20Optim.%20Appl.&amp;volume=23&amp;issue=2&amp;pages=143-169&amp;publication_year=2002&amp;author=Grippo%2CL&amp;author=Sciandrone%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="L. Györfi, M. Kohler, A. Krzyzak, H. Walk, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Györfi, L., Kohler, M., Krzyzak, A., Walk, H.: A Distribution-free Theory of Nonparametric Regression. Springe" /><span class="c-article-references__counter">74.</span><p class="c-article-references__text" id="ref-CR74">Györfi, L., Kohler, M., Krzyzak, A., Walk, H.: A Distribution-free Theory of Nonparametric Regression. Springer, Berlin (2006)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 74 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20Distribution-free%20Theory%20of%20Nonparametric%20Regression&amp;publication_year=2006&amp;author=Gy%C3%B6rfi%2CL&amp;author=Kohler%2CM&amp;author=Krzyzak%2CA&amp;author=Walk%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="LG. Hamey, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Hamey, L.G.: XOR has no local minima: a case study in neural network error surface analysis. Neural Netw. 11(4" /><span class="c-article-references__counter">75.</span><p class="c-article-references__text" id="ref-CR75">Hamey, L.G.: XOR has no local minima: a case study in neural network error surface analysis. Neural Netw. <b>11</b>(4), 669–681 (1998)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 75 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=XOR%20has%20no%20local%20minima%3A%20a%20case%20study%20in%20neural%20network%20error%20surface%20analysis&amp;journal=Neural%20Netw.&amp;volume=11&amp;issue=4&amp;pages=669-681&amp;publication_year=1998&amp;author=Hamey%2CLG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Hamm, BW. Brorsen, MT. Hagan, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Hamm, L., Brorsen, B.W., Hagan, M.T.: Comparison of stochastic global optimization methods to estimate neural " /><span class="c-article-references__counter">76.</span><p class="c-article-references__text" id="ref-CR76">Hamm, L., Brorsen, B.W., Hagan, M.T.: Comparison of stochastic global optimization methods to estimate neural network weights. Neural Process. Lett. <b>26</b>(3), 145–158 (2007)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 76 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Comparison%20of%20stochastic%20global%20optimization%20methods%20to%20estimate%20neural%20network%20weights&amp;journal=Neural%20Process.%20Lett.&amp;volume=26&amp;issue=3&amp;pages=145-158&amp;publication_year=2007&amp;author=Hamm%2CL&amp;author=Brorsen%2CBW&amp;author=Hagan%2CMT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="S. Haykin, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Haykin, S.: Neural Networks and Learning Machines, vol. 3. Pearson, Upper Saddle River (2009)" /><span class="c-article-references__counter">77.</span><p class="c-article-references__text" id="ref-CR77">Haykin, S.: Neural Networks and Learning Machines, vol. 3. Pearson, Upper Saddle River (2009)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 77 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20Networks%20and%20Learning%20Machines&amp;publication_year=2009&amp;author=Haykin%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Hochreiter, J. Schmidhuber, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Hochreiter, S., Schmidhuber, J.: Flat minima. Neural Comput. 9(1), 1–42 (1997)" /><span class="c-article-references__counter">78.</span><p class="c-article-references__text" id="ref-CR78">Hochreiter, S., Schmidhuber, J.: Flat minima. Neural Comput. <b>9</b>(1), 1–42 (1997)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0872.68150" aria-label="View reference 78 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 78 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Flat%20minima&amp;journal=Neural%20Comput.&amp;volume=9&amp;issue=1&amp;pages=1-42&amp;publication_year=1997&amp;author=Hochreiter%2CS&amp;author=Schmidhuber%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="R. Horst, H. Tuy, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Horst, R., Tuy, H.: Global Optimization: Deterministic Approaches. Springer, Berlin (2013)" /><span class="c-article-references__counter">79.</span><p class="c-article-references__text" id="ref-CR79">Horst, R., Tuy, H.: Global Optimization: Deterministic Approaches. Springer, Berlin (2013)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 79 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Global%20Optimization%3A%20Deterministic%20Approaches&amp;publication_year=2013&amp;author=Horst%2CR&amp;author=Tuy%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Huang, GB. Huang, S. Song, K. You, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Huang, G., Huang, G.B., Song, S., You, K.: Trends in extreme learning machines: a review. Neural Netw. 61, 32–" /><span class="c-article-references__counter">80.</span><p class="c-article-references__text" id="ref-CR80">Huang, G., Huang, G.B., Song, S., You, K.: Trends in extreme learning machines: a review. Neural Netw. <b>61</b>, 32–48 (2015)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1325.68190" aria-label="View reference 80 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 80 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Trends%20in%20extreme%20learning%20machines%3A%20a%20review&amp;journal=Neural%20Netw.&amp;volume=61&amp;pages=32-48&amp;publication_year=2015&amp;author=Huang%2CG&amp;author=Huang%2CGB&amp;author=Song%2CS&amp;author=You%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Huang, G.B., Zhu, Q.Y., Siew, C.K.: Extreme learning machine: a new learning scheme of feedforward neural netw" /><span class="c-article-references__counter">81.</span><p class="c-article-references__text" id="ref-CR81">Huang, G.B., Zhu, Q.Y., Siew, C.K.: Extreme learning machine: a new learning scheme of feedforward neural networks. In: 2004 IEEE International Joint Conference on Neural Networks, 2004. Proceedings, vol. 2, pp. 985–990. IEEE (2004)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="LCK. Hui, KY. Lam, CW. Chea, " /><meta itemprop="datePublished" content="1997" /><meta itemprop="headline" content="Hui, L.C.K., Lam, K.Y., Chea, C.W.: Global optimisation in neural network training. Neural Comput. Appl. 5(1)," /><span class="c-article-references__counter">82.</span><p class="c-article-references__text" id="ref-CR82">Hui, L.C.K., Lam, K.Y., Chea, C.W.: Global optimisation in neural network training. Neural Comput. Appl. <b>5</b>(1), 58–64 (1997)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 82 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Global%20optimisation%20in%20neural%20network%20training&amp;journal=Neural%20Comput.%20Appl.&amp;volume=5&amp;issue=1&amp;pages=58-64&amp;publication_year=1997&amp;author=Hui%2CLCK&amp;author=Lam%2CKY&amp;author=Chea%2CCW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Y. Jin, B. Sendhoff, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Jin, Y., Sendhoff, B.: Pareto-based multiobjective machine learning: an overview and case studies. IEEE Trans." /><span class="c-article-references__counter">83.</span><p class="c-article-references__text" id="ref-CR83">Jin, Y., Sendhoff, B.: Pareto-based multiobjective machine learning: an overview and case studies. IEEE Trans. Syst. Man Cybern. Part C (Appl. Rev.) <b>38</b>(3), 397–415 (2008)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 83 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Pareto-based%20multiobjective%20machine%20learning%3A%20an%20overview%20and%20case%20studies&amp;journal=IEEE%20Trans.%20Syst.%20Man%20Cybern.%20Part%20C%20%28Appl.%20Rev.%29&amp;volume=38&amp;issue=3&amp;pages=397-415&amp;publication_year=2008&amp;author=Jin%2CY&amp;author=Sendhoff%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kawaguchi, K.: Deep learning without poor local minima. In: Advances In Neural Information Processing Systems," /><span class="c-article-references__counter">84.</span><p class="c-article-references__text" id="ref-CR84">Kawaguchi, K.: Deep learning without poor local minima. In: Advances In Neural Information Processing Systems, pp. 586–594 (2016)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Keskar, N.S., Mudigere, D., Nocedal, J., Smelyanskiy, M., Tang, P.T.P.: On large-batch training for deep learn" /><span class="c-article-references__counter">85.</span><p class="c-article-references__text" id="ref-CR85">Keskar, N.S., Mudigere, D., Nocedal, J., Smelyanskiy, M., Tang, P.T.P.: On large-batch training for deep learning: generalization gap and sharp minima. In: ICLR 2017 (2016)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lang, K.: Learning to tell two spiral apart. In: Proceedings of the 1988 Connectionist Models Summer School, p" /><span class="c-article-references__counter">86.</span><p class="c-article-references__text" id="ref-CR86">Lang, K.: Learning to tell two spiral apart. In: Proceedings of the 1988 Connectionist Models Summer School, pp. 52–59 (1989)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Laurent, T., von Brecht, J.: The multilinear structure of ReLU networks (2017). arXiv preprint arXiv:1712.1013" /><span class="c-article-references__counter">87.</span><p class="c-article-references__text" id="ref-CR87">Laurent, T., von Brecht, J.: The multilinear structure of ReLU networks (2017). arXiv preprint <a href="http://arxiv.org/abs/1712.10132">arXiv:1712.10132</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Y. LeCun, Y. Bengio, G. Hinton, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="LeCun, Y., Bengio, Y., Hinton, G.: Deep learning. Nature 521(7553), 436–444 (2015)" /><span class="c-article-references__counter">88.</span><p class="c-article-references__text" id="ref-CR88">LeCun, Y., Bengio, Y., Hinton, G.: Deep learning. Nature <b>521</b>(7553), 436–444 (2015)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 88 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20learning&amp;journal=Nature&amp;volume=521&amp;issue=7553&amp;pages=436-444&amp;publication_year=2015&amp;author=LeCun%2CY&amp;author=Bengio%2CY&amp;author=Hinton%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="LeCun, Y.A., Bottou, L., Orr, G.B., Müller, K.R.: Efficient backprop. In: Neural networks: Tricks of the trade" /><span class="c-article-references__counter">89.</span><p class="c-article-references__text" id="ref-CR89">LeCun, Y.A., Bottou, L., Orr, G.B., Müller, K.R.: Efficient backprop. In: Neural networks: Tricks of the trade, pp. 9–48. Springer (2012)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Lee, J.D., Simchowitz, M., Jordan, M.I., Recht, B.: Gradient descent only converges to minimizers. In: Confere" /><span class="c-article-references__counter">90.</span><p class="c-article-references__text" id="ref-CR90">Lee, J.D., Simchowitz, M., Jordan, M.I., Recht, B.: Gradient descent only converges to minimizers. In: Conference on Learning Theory, pp. 1246–1257 (2016)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JS. Lee, CH. Park, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Lee, J.S., Park, C.H.: Global optimization of radial basis function networks by hybrid simulated annealing. Ne" /><span class="c-article-references__counter">91.</span><p class="c-article-references__text" id="ref-CR91">Lee, J.S., Park, C.H.: Global optimization of radial basis function networks by hybrid simulated annealing. Neural Netw. World <b>20</b>(4), 519 (2010)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 91 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Global%20optimization%20of%20radial%20basis%20function%20networks%20by%20hybrid%20simulated%20annealing&amp;journal=Neural%20Netw.%20World&amp;volume=20&amp;issue=4&amp;publication_year=2010&amp;author=Lee%2CJS&amp;author=Park%2CCH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="HR. Li, HL. Li, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Li, H.R., Li, H.L.: A global optimization algorithm based on filled-function for neural networks. J. Northeast" /><span class="c-article-references__counter">92.</span><p class="c-article-references__text" id="ref-CR92">Li, H.R., Li, H.L.: A global optimization algorithm based on filled-function for neural networks. J. Northeast. Univ. Nat. Sci. <b>28</b>(9), 1247 (2007)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2380219" aria-label="View reference 92 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1150.68413" aria-label="View reference 92 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 92 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20global%20optimization%20algorithm%20based%20on%20filled-function%20for%20neural%20networks&amp;journal=J.%20Northeast.%20Univ.%20Nat.%20Sci.&amp;volume=28&amp;issue=9&amp;publication_year=2007&amp;author=Li%2CHR&amp;author=Li%2CHL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="SW. Lin, TY. Tseng, SY. Chou, SC. Chen, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Lin, S.W., Tseng, T.Y., Chou, S.Y., Chen, S.C.: A simulated-annealing-based approach for simultaneous paramete" /><span class="c-article-references__counter">93.</span><p class="c-article-references__text" id="ref-CR93">Lin, S.W., Tseng, T.Y., Chou, S.Y., Chen, S.C.: A simulated-annealing-based approach for simultaneous parameter optimization and feature selection of back-propagation networks. Expert Syst. Appl. <b>34</b>(2), 1491–1499 (2008)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 93 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20simulated-annealing-based%20approach%20for%20simultaneous%20parameter%20optimization%20and%20feature%20selection%20of%20back-propagation%20networks&amp;journal=Expert%20Syst.%20Appl.&amp;volume=34&amp;issue=2&amp;pages=1491-1499&amp;publication_year=2008&amp;author=Lin%2CSW&amp;author=Tseng%2CTY&amp;author=Chou%2CSY&amp;author=Chen%2CSC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Lisboa, S. Perantonis, " /><meta itemprop="datePublished" content="1991" /><meta itemprop="headline" content="Lisboa, P., Perantonis, S.: Complete solution of the local minima in the XOR problem. Network: Comput. Neural " /><span class="c-article-references__counter">94.</span><p class="c-article-references__text" id="ref-CR94">Lisboa, P., Perantonis, S.: Complete solution of the local minima in the XOR problem. Network: Comput. Neural Syst. <b>2</b>(1), 119–124 (1991)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1105295" aria-label="View reference 94 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0719.94512" aria-label="View reference 94 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 94 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Complete%20solution%20of%20the%20local%20minima%20in%20the%20XOR%20problem&amp;journal=Network%3A%20Comput.%20Neural%20Syst.&amp;volume=2&amp;issue=1&amp;pages=119-124&amp;publication_year=1991&amp;author=Lisboa%2CP&amp;author=Perantonis%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Liu, Y. Wang, S. Guan, X. Liu, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Liu, H., Wang, Y., Guan, S., Liu, X.: A new filled function method for unconstrained global optimization. Int." /><span class="c-article-references__counter">95.</span><p class="c-article-references__text" id="ref-CR95">Liu, H., Wang, Y., Guan, S., Liu, X.: A new filled function method for unconstrained global optimization. Int. J. Comput. Math. <b>94</b>(12), 2283–2296 (2017)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3740649" aria-label="View reference 95 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1398.65125" aria-label="View reference 95 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 95 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20new%20filled%20function%20method%20for%20unconstrained%20global%20optimization&amp;journal=Int.%20J.%20Comput.%20Math.&amp;volume=94&amp;issue=12&amp;pages=2283-2296&amp;publication_year=2017&amp;author=Liu%2CH&amp;author=Wang%2CY&amp;author=Guan%2CS&amp;author=Liu%2CX">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Locatelli, M., Schoen, F.: Global optimization: theory, algorithms, and applications. Society for Industrial a" /><span class="c-article-references__counter">96.</span><p class="c-article-references__text" id="ref-CR96">Locatelli, M., Schoen, F.: Global optimization: theory, algorithms, and applications. Society for Industrial and Applied Mathematics, Philadelphia, PA (2013). <a href="https://doi.org/10.1137/1.9781611972672">https://doi.org/10.1137/1.9781611972672</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Magoulas, G., Plagianakos, V., Vrahatis, M.: Hybrid methods using evolutionary algorithms for on-line training" /><span class="c-article-references__counter">97.</span><p class="c-article-references__text" id="ref-CR97">Magoulas, G., Plagianakos, V., Vrahatis, M.: Hybrid methods using evolutionary algorithms for on-line training. In: International Joint Conference on Neural Networks, 2001 (IJCNN’01) Proceedings, vol. 3, pp. 2218–2223. IEEE (2001)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Martin-Guerreo, J., Gómez-Chova, L., Calpe-Maravilla, J., Camps-Valls, G., Soria-Olivas, E., Moreno, J.: A sof" /><span class="c-article-references__counter">98.</span><p class="c-article-references__text" id="ref-CR98">Martin-Guerreo, J., Gómez-Chova, L., Calpe-Maravilla, J., Camps-Valls, G., Soria-Olivas, E., Moreno, J.: A soft approach to ERA algorithm for hyperspectral image classification. In: Proceedings of the 3rd International Symposium on Image and Signal Processing and Analysis, 2003 (ISPA 2003), vol. 2, pp. 761–765. IEEE (2003)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Neelakantan, A., Vilnis, L., Le, Q.V., Sutskever, I., Kaiser, L., Kurach, K., Martens, J.: Adding gradient noi" /><span class="c-article-references__counter">99.</span><p class="c-article-references__text" id="ref-CR99">Neelakantan, A., Vilnis, L., Le, Q.V., Sutskever, I., Kaiser, L., Kurach, K., Martens, J.: Adding gradient noise improves learning for very deep networks (2015). arXiv preprint <a href="http://arxiv.org/abs/1511.06807">arXiv:1511.06807</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Y. Nesterov, " /><meta itemprop="datePublished" content="1983" /><meta itemprop="headline" content="Nesterov, Y.: A method of solving a convex programming problem with convergence rate \(o(1/k^2)\). Sov. Math. " /><span class="c-article-references__counter">100.</span><p class="c-article-references__text" id="ref-CR100">Nesterov, Y.: A method of solving a convex programming problem with convergence rate <span class="mathjax-tex">\(o(1/k^2)\)</span>. Sov. Math. Doklady <b>27</b>(2), 372–376 (1983)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0535.90071" aria-label="View reference 100 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 100 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20method%20of%20solving%20a%20convex%20programming%20problem%20with%20convergence%20rate%20%24%24o%281%2Fk%5E2%29%24%24%20o%20%28%201%20%2F%20k%202%20%29&amp;journal=Sov.%20Math.%20Doklady&amp;volume=27&amp;issue=2&amp;pages=372-376&amp;publication_year=1983&amp;author=Nesterov%2CY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Nguyen, Q., Hein, M.: The loss surface and expressivity of deep convolutional neural networks (2017). arXiv pr" /><span class="c-article-references__counter">101.</span><p class="c-article-references__text" id="ref-CR101">Nguyen, Q., Hein, M.: The loss surface and expressivity of deep convolutional neural networks (2017). arXiv preprint <a href="http://arxiv.org/abs/1710.10928">arXiv:1710.10928</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Nguyen, Q., Hein, M.: The loss surface of deep and wide neural networks (2017). arXiv preprint arXiv:1704.0804" /><span class="c-article-references__counter">102.</span><p class="c-article-references__text" id="ref-CR102">Nguyen, Q., Hein, M.: The loss surface of deep and wide neural networks (2017). arXiv preprint <a href="http://arxiv.org/abs/1704.08045">arXiv:1704.08045</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="VK. Ojha, A. Abraham, V. Snášel, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Ojha, V.K., Abraham, A., Snášel, V.: Metaheuristic design of feedforward neural networks: a review of two deca" /><span class="c-article-references__counter">103.</span><p class="c-article-references__text" id="ref-CR103">Ojha, V.K., Abraham, A., Snášel, V.: Metaheuristic design of feedforward neural networks: a review of two decades of research. Eng. Appl. Artif. Intell. <b>60</b>, 97–116 (2017)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 103 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Metaheuristic%20design%20of%20feedforward%20neural%20networks%3A%20a%20review%20of%20two%20decades%20of%20research&amp;journal=Eng.%20Appl.%20Artif.%20Intell.&amp;volume=60&amp;pages=97-116&amp;publication_year=2017&amp;author=Ojha%2CVK&amp;author=Abraham%2CA&amp;author=Sn%C3%A1%C5%A1el%2CV">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="PP. Palmes, T. Hayasaka, S. Usui, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Palmes, P.P., Hayasaka, T., Usui, S.: Mutation-based genetic neural network. IEEE Trans. Neural Netw. 16(3), 5" /><span class="c-article-references__counter">104.</span><p class="c-article-references__text" id="ref-CR104">Palmes, P.P., Hayasaka, T., Usui, S.: Mutation-based genetic neural network. IEEE Trans. Neural Netw. <b>16</b>(3), 587–600 (2005)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 104 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Mutation-based%20genetic%20neural%20network&amp;journal=IEEE%20Trans.%20Neural%20Netw.&amp;volume=16&amp;issue=3&amp;pages=587-600&amp;publication_year=2005&amp;author=Palmes%2CPP&amp;author=Hayasaka%2CT&amp;author=Usui%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Peng, C.C., Magoulas, G.D.: Adaptive nonmonotone conjugate gradient training algorithm for recurrent neural ne" /><span class="c-article-references__counter">105.</span><p class="c-article-references__text" id="ref-CR105">Peng, C.C., Magoulas, G.D.: Adaptive nonmonotone conjugate gradient training algorithm for recurrent neural networks. In: 19th IEEE International Conference on Tools with Artificial Intelligence, 2007 (ICTAI 2007), vol. 2, pp. 374–381. IEEE (2007)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="CC. Peng, GD. Magoulas, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Peng, C.C., Magoulas, G.D.: Nonmonotone Levenberg–Marquardt training of recurrent neural architectures for pro" /><span class="c-article-references__counter">106.</span><p class="c-article-references__text" id="ref-CR106">Peng, C.C., Magoulas, G.D.: Nonmonotone Levenberg–Marquardt training of recurrent neural architectures for processing symbolic sequences. Neural Comput. Appl. <b>20</b>(6), 897–908 (2011)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 106 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Nonmonotone%20Levenberg%E2%80%93Marquardt%20training%20of%20recurrent%20neural%20architectures%20for%20processing%20symbolic%20sequences&amp;journal=Neural%20Comput.%20Appl.&amp;volume=20&amp;issue=6&amp;pages=897-908&amp;publication_year=2011&amp;author=Peng%2CCC&amp;author=Magoulas%2CGD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="V. Piccialli, M. Sciandrone, " /><meta itemprop="datePublished" content="2018" /><meta itemprop="headline" content="Piccialli, V., Sciandrone, M.: Nonlinear optimization and support vector machines. 4OR 16(2), 111–149 (2018)" /><span class="c-article-references__counter">107.</span><p class="c-article-references__text" id="ref-CR107">Piccialli, V., Sciandrone, M.: Nonlinear optimization and support vector machines. 4OR <b>16</b>(2), 111–149 (2018)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3806088" aria-label="View reference 107 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1398.65126" aria-label="View reference 107 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 107 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Nonlinear%20optimization%20and%20support%20vector%20machines&amp;journal=4OR&amp;volume=16&amp;issue=2&amp;pages=111-149&amp;publication_year=2018&amp;author=Piccialli%2CV&amp;author=Sciandrone%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JD. Pintér, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Pintér, J.D.: Calibrating artificial neural networks by global optimization. Expert Syst. Appl. 39(1), 25–32 (" /><span class="c-article-references__counter">108.</span><p class="c-article-references__text" id="ref-CR108">Pintér, J.D.: Calibrating artificial neural networks by global optimization. Expert Syst. Appl. <b>39</b>(1), 25–32 (2012)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 108 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Calibrating%20artificial%20neural%20networks%20by%20global%20optimization&amp;journal=Expert%20Syst.%20Appl.&amp;volume=39&amp;issue=1&amp;pages=25-32&amp;publication_year=2012&amp;author=Pint%C3%A9r%2CJD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="V. Plagianakos, G. Magoulas, M. Vrahatis, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Plagianakos, V., Magoulas, G., Vrahatis, M.: Learning in multilayer perceptrons using global optimization stra" /><span class="c-article-references__counter">109.</span><p class="c-article-references__text" id="ref-CR109">Plagianakos, V., Magoulas, G., Vrahatis, M.: Learning in multilayer perceptrons using global optimization strategies. Nonlinear Anal. Theory Methods Appl. <b>47</b>(5), 3431–3436 (2001)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1979238" aria-label="View reference 109 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1042.90653" aria-label="View reference 109 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 109 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20in%20multilayer%20perceptrons%20using%20global%20optimization%20strategies&amp;journal=Nonlinear%20Anal.%20Theory%20Methods%20Appl.&amp;volume=47&amp;issue=5&amp;pages=3431-3436&amp;publication_year=2001&amp;author=Plagianakos%2CV&amp;author=Magoulas%2CG&amp;author=Vrahatis%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Plagianakos, V., Magoulas, G., Vrahatis, M.: Improved learning of neural nets through global search. In: Globa" /><span class="c-article-references__counter">110.</span><p class="c-article-references__text" id="ref-CR110">Plagianakos, V., Magoulas, G., Vrahatis, M.: Improved learning of neural nets through global search. In: Global Optimization, pp. 361–388. Springer (2006)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="VP. Plagianakos, GD. Magoulas, MN. Vrahatis, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Plagianakos, V.P., Magoulas, G.D., Vrahatis, M.N.: Deterministic nonmonotone strategies for effective training" /><span class="c-article-references__counter">111.</span><p class="c-article-references__text" id="ref-CR111">Plagianakos, V.P., Magoulas, G.D., Vrahatis, M.N.: Deterministic nonmonotone strategies for effective training of multilayer perceptrons. IEEE Transactions on Neural Networks <b>13</b>(6), 1268–1284 (2002)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 111 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Deterministic%20nonmonotone%20strategies%20for%20effective%20training%20of%20multilayer%20perceptrons&amp;journal=IEEE%20Transactions%20on%20Neural%20Networks&amp;volume=13&amp;issue=6&amp;pages=1268-1284&amp;publication_year=2002&amp;author=Plagianakos%2CVP&amp;author=Magoulas%2CGD&amp;author=Vrahatis%2CMN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Poggio, F. Girosi, " /><meta itemprop="datePublished" content="1990" /><meta itemprop="headline" content="Poggio, T., Girosi, F.: Networks for approximation and learning. Proc. IEEE 78(9), 1481–1497 (1990)" /><span class="c-article-references__counter">112.</span><p class="c-article-references__text" id="ref-CR112">Poggio, T., Girosi, F.: Networks for approximation and learning. Proc. IEEE <b>78</b>(9), 1481–1497 (1990)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1226.92005" aria-label="View reference 112 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 112 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Networks%20for%20approximation%20and%20learning&amp;journal=Proc.%20IEEE&amp;volume=78&amp;issue=9&amp;pages=1481-1497&amp;publication_year=1990&amp;author=Poggio%2CT&amp;author=Girosi%2CF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="BT. Polyak, " /><meta itemprop="datePublished" content="1964" /><meta itemprop="headline" content="Polyak, B.T.: Some methods of speeding up the convergence of iteration methods. USSR Comput. Math. Math. Phys." /><span class="c-article-references__counter">113.</span><p class="c-article-references__text" id="ref-CR113">Polyak, B.T.: Some methods of speeding up the convergence of iteration methods. USSR Comput. Math. Math. Phys. <b>4</b>(5), 1–17 (1964)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 113 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Some%20methods%20of%20speeding%20up%20the%20convergence%20of%20iteration%20methods&amp;journal=USSR%20Comput.%20Math.%20Math.%20Phys.&amp;volume=4&amp;issue=5&amp;pages=1-17&amp;publication_year=1964&amp;author=Polyak%2CBT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Prieto, B. Prieto, EM. Ortigosa, E. Ros, F. Pelayo, J. Ortega, I. Rojas, " /><meta itemprop="datePublished" content="2016" /><meta itemprop="headline" content="Prieto, A., Prieto, B., Ortigosa, E.M., Ros, E., Pelayo, F., Ortega, J., Rojas, I.: Neural networks: an overvi" /><span class="c-article-references__counter">114.</span><p class="c-article-references__text" id="ref-CR114">Prieto, A., Prieto, B., Ortigosa, E.M., Ros, E., Pelayo, F., Ortega, J., Rojas, I.: Neural networks: an overview of early research, current frameworks and new challenges. Neurocomputing <b>214</b>, 242–268 (2016)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 114 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20networks%3A%20an%20overview%20of%20early%20research%2C%20current%20frameworks%20and%20new%20challenges&amp;journal=Neurocomputing&amp;volume=214&amp;pages=242-268&amp;publication_year=2016&amp;author=Prieto%2CA&amp;author=Prieto%2CB&amp;author=Ortigosa%2CEM&amp;author=Ros%2CE&amp;author=Pelayo%2CF&amp;author=Ortega%2CJ&amp;author=Rojas%2CI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="LR. Rere, MI. Fanany, AM. Arymurthy, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Rere, L.R., Fanany, M.I., Arymurthy, A.M.: Simulated annealing algorithm for deep learning. Proc. Comput. Sci." /><span class="c-article-references__counter">115.</span><p class="c-article-references__text" id="ref-CR115">Rere, L.R., Fanany, M.I., Arymurthy, A.M.: Simulated annealing algorithm for deep learning. Proc. Comput. Sci. <b>72</b>, 137–144 (2015)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 115 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Simulated%20annealing%20algorithm%20for%20deep%20learning&amp;journal=Proc.%20Comput.%20Sci.&amp;volume=72&amp;pages=137-144&amp;publication_year=2015&amp;author=Rere%2CLR&amp;author=Fanany%2CMI&amp;author=Arymurthy%2CAM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Robbins, S. Monro, " /><meta itemprop="datePublished" content="1951" /><meta itemprop="headline" content="Robbins, H., Monro, S.: A stochastic approximation method. Ann. Math. Stat. 22(3), 400–407 (1951)" /><span class="c-article-references__counter">116.</span><p class="c-article-references__text" id="ref-CR116">Robbins, H., Monro, S.: A stochastic approximation method. Ann. Math. Stat. <b>22</b>(3), 400–407 (1951)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=42668" aria-label="View reference 116 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0054.05901" aria-label="View reference 116 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 116 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20stochastic%20approximation%20method&amp;journal=Ann.%20Math.%20Stat.&amp;volume=22&amp;issue=3&amp;pages=400-407&amp;publication_year=1951&amp;author=Robbins%2CH&amp;author=Monro%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. RoyChowdhury, YP. Singh, R. Chansarkar, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="RoyChowdhury, P., Singh, Y.P., Chansarkar, R.: Dynamic tunneling technique for efficient training of multilaye" /><span class="c-article-references__counter">117.</span><p class="c-article-references__text" id="ref-CR117">RoyChowdhury, P., Singh, Y.P., Chansarkar, R.: Dynamic tunneling technique for efficient training of multilayer perceptrons. IEEE Trans. Neural Netw. <b>10</b>(1), 48–55 (1999)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 117 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Dynamic%20tunneling%20technique%20for%20efficient%20training%20of%20multilayer%20perceptrons&amp;journal=IEEE%20Trans.%20Neural%20Netw.&amp;volume=10&amp;issue=1&amp;pages=48-55&amp;publication_year=1999&amp;author=RoyChowdhury%2CP&amp;author=Singh%2CYP&amp;author=Chansarkar%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ruppert, D., Wand, M.P., Carroll, R.J.: Semiparametric regression. In: Cambridge Series in Statistical and Pro" /><span class="c-article-references__counter">118.</span><p class="c-article-references__text" id="ref-CR118">Ruppert, D., Wand, M.P., Carroll, R.J.: Semiparametric regression. In: Cambridge Series in Statistical and Probabilistic mathematics, vol. 12. Mathematical Reviews (MathSciNet): MR1998720. Cambridge Univ. Press, Cambridge (2003)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Ruppert, MP. Wand, RJ. Carroll, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Ruppert, D., Wand, M.P., Carroll, R.J.: Semiparametric regression during 2003–2007. Electron. J. Stat. 3, 1193" /><span class="c-article-references__counter">119.</span><p class="c-article-references__text" id="ref-CR119">Ruppert, D., Wand, M.P., Carroll, R.J.: Semiparametric regression during 2003–2007. Electron. J. Stat. <b>3</b>, 1193 (2009)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2566186" aria-label="View reference 119 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1326.62094" aria-label="View reference 119 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 119 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Semiparametric%20regression%20during%202003%E2%80%932007&amp;journal=Electron.%20J.%20Stat.&amp;volume=3&amp;publication_year=2009&amp;author=Ruppert%2CD&amp;author=Wand%2CMP&amp;author=Carroll%2CRJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="D. Saad, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Saad, D.: On-Line Learning in Neural Networks, vol. 17. Cambridge University Press, Cambridge (2009)" /><span class="c-article-references__counter">120.</span><p class="c-article-references__text" id="ref-CR120">Saad, D.: On-Line Learning in Neural Networks, vol. 17. Cambridge University Press, Cambridge (2009)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 120 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On-Line%20Learning%20in%20Neural%20Networks&amp;publication_year=2009&amp;author=Saad%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="S. Scardapane, D. Wang, " /><meta itemprop="datePublished" content="2017" /><meta itemprop="headline" content="Scardapane, S., Wang, D.: Randomness in neural networks: an overview. Wiley Interdiscip. Rev. Data Min. Knowl." /><span class="c-article-references__counter">121.</span><p class="c-article-references__text" id="ref-CR121">Scardapane, S., Wang, D.: Randomness in neural networks: an overview. Wiley Interdiscip. Rev. Data Min. Knowl. Discov. <b>7</b>(2), 1200 (2017)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 121 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Randomness%20in%20neural%20networks%3A%20an%20overview&amp;journal=Wiley%20Interdiscip.%20Rev.%20Data%20Min.%20Knowl.%20Discov.&amp;volume=7&amp;issue=2&amp;publication_year=2017&amp;author=Scardapane%2CS&amp;author=Wang%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Schaffer, J.D., Whitley, D., Eshelman, L.J.: Combinations of genetic algorithms and neural networks: a survey " /><span class="c-article-references__counter">122.</span><p class="c-article-references__text" id="ref-CR122">Schaffer, J.D., Whitley, D., Eshelman, L.J.: Combinations of genetic algorithms and neural networks: a survey of the state of the art. In: International Workshop on Combinations of Genetic Algorithms and Neural Networks, 1992 (COGANN-92), pp. 1–37. IEEE (1992)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Schmidhuber, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Schmidhuber, J.: Deep learning in neural networks: an overview. Neural Netw. 61, 85–117 (2015)" /><span class="c-article-references__counter">123.</span><p class="c-article-references__text" id="ref-CR123">Schmidhuber, J.: Deep learning in neural networks: an overview. Neural Netw. <b>61</b>, 85–117 (2015)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 123 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20learning%20in%20neural%20networks%3A%20an%20overview&amp;journal=Neural%20Netw.&amp;volume=61&amp;pages=85-117&amp;publication_year=2015&amp;author=Schmidhuber%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="F. Schwenker, HA. Kestler, G. Palm, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Schwenker, F., Kestler, H.A., Palm, G.: Three learning phases for radial-basis-function networks. Neural Netw." /><span class="c-article-references__counter">124.</span><p class="c-article-references__text" id="ref-CR124">Schwenker, F., Kestler, H.A., Palm, G.: Three learning phases for radial-basis-function networks. Neural Netw. <b>14</b>(4), 439–458 (2001)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0991.68061" aria-label="View reference 124 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 124 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Three%20learning%20phases%20for%20radial-basis-function%20networks&amp;journal=Neural%20Netw.&amp;volume=14&amp;issue=4&amp;pages=439-458&amp;publication_year=2001&amp;author=Schwenker%2CF&amp;author=Kestler%2CHA&amp;author=Palm%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RS. Sexton, RE. Dorsey, JD. Johnson, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Sexton, R.S., Dorsey, R.E., Johnson, J.D.: Toward global optimization of neural networks: a comparison of the " /><span class="c-article-references__counter">125.</span><p class="c-article-references__text" id="ref-CR125">Sexton, R.S., Dorsey, R.E., Johnson, J.D.: Toward global optimization of neural networks: a comparison of the genetic algorithm and backpropagation. Decis. Support Syst. <b>22</b>(2), 171–185 (1998)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 125 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Toward%20global%20optimization%20of%20neural%20networks%3A%20a%20comparison%20of%20the%20genetic%20algorithm%20and%20backpropagation&amp;journal=Decis.%20Support%20Syst.&amp;volume=22&amp;issue=2&amp;pages=171-185&amp;publication_year=1998&amp;author=Sexton%2CRS&amp;author=Dorsey%2CRE&amp;author=Johnson%2CJD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RS. Sexton, RE. Dorsey, JD. Johnson, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Sexton, R.S., Dorsey, R.E., Johnson, J.D.: Optimization of neural networks: a comparative analysis of the gene" /><span class="c-article-references__counter">126.</span><p class="c-article-references__text" id="ref-CR126">Sexton, R.S., Dorsey, R.E., Johnson, J.D.: Optimization of neural networks: a comparative analysis of the genetic algorithm and simulated annealing. Eur. J. Oper. Res. <b>114</b>(3), 589–601 (1999)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0938.90069" aria-label="View reference 126 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 126 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Optimization%20of%20neural%20networks%3A%20a%20comparative%20analysis%20of%20the%20genetic%20algorithm%20and%20simulated%20annealing&amp;journal=Eur.%20J.%20Oper.%20Res.&amp;volume=114&amp;issue=3&amp;pages=589-601&amp;publication_year=1999&amp;author=Sexton%2CRS&amp;author=Dorsey%2CRE&amp;author=Johnson%2CJD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Y. Shang, BW. Wah, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Shang, Y., Wah, B.W.: Global optimization for neural network training. Computer 29(3), 45–54 (1996)" /><span class="c-article-references__counter">127.</span><p class="c-article-references__text" id="ref-CR127">Shang, Y., Wah, B.W.: Global optimization for neural network training. Computer <b>29</b>(3), 45–54 (1996)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 127 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Global%20optimization%20for%20neural%20network%20training&amp;journal=Computer&amp;volume=29&amp;issue=3&amp;pages=45-54&amp;publication_year=1996&amp;author=Shang%2CY&amp;author=Wah%2CBW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Šíma, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Šíma, J.: Training a single sigmoidal neuron is hard. Neural Comput. 14(11), 2709–2728 (2002)" /><span class="c-article-references__counter">128.</span><p class="c-article-references__text" id="ref-CR128">Šíma, J.: Training a single sigmoidal neuron is hard. Neural Comput. <b>14</b>(11), 2709–2728 (2002)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1060.68099" aria-label="View reference 128 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 128 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Training%20a%20single%20sigmoidal%20neuron%20is%20hard&amp;journal=Neural%20Comput.&amp;volume=14&amp;issue=11&amp;pages=2709-2728&amp;publication_year=2002&amp;author=%C5%A0%C3%ADma%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Soudry, D., Carmon, Y.: No bad local minima: data independent training error guarantees for multilayer neural " /><span class="c-article-references__counter">129.</span><p class="c-article-references__text" id="ref-CR129">Soudry, D., Carmon, Y.: No bad local minima: data independent training error guarantees for multilayer neural networks (2016). arXiv preprint <a href="http://arxiv.org/abs/1605.08361">arXiv:1605.08361</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="IG. Sprinkhuizen-Kuyper, EJ. Boers, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Sprinkhuizen-Kuyper, I.G., Boers, E.J.: The error surface of the 2-2-1 XOR network: The finite stationary poin" /><span class="c-article-references__counter">130.</span><p class="c-article-references__text" id="ref-CR130">Sprinkhuizen-Kuyper, I.G., Boers, E.J.: The error surface of the 2-2-1 XOR network: The finite stationary points. Neural Netw. <b>11</b>(4), 683–690 (1998)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 130 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20error%20surface%20of%20the%202-2-1%20XOR%20network%3A%20The%20finite%20stationary%20points&amp;journal=Neural%20Netw.&amp;volume=11&amp;issue=4&amp;pages=683-690&amp;publication_year=1998&amp;author=Sprinkhuizen-Kuyper%2CIG&amp;author=Boers%2CEJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="N. Srivastava, GE. Hinton, A. Krizhevsky, I. Sutskever, R. Salakhutdinov, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.: Dropout: a simple way to preve" /><span class="c-article-references__counter">131.</span><p class="c-article-references__text" id="ref-CR131">Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.: Dropout: a simple way to prevent neural networks from overfitting. J. Mach. Learn. Res. <b>15</b>(1), 1929–1958 (2014)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3231592" aria-label="View reference 131 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1318.68153" aria-label="View reference 131 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 131 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Dropout%3A%20a%20simple%20way%20to%20prevent%20neural%20networks%20from%20overfitting&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=15&amp;issue=1&amp;pages=1929-1958&amp;publication_year=2014&amp;author=Srivastava%2CN&amp;author=Hinton%2CGE&amp;author=Krizhevsky%2CA&amp;author=Sutskever%2CI&amp;author=Salakhutdinov%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Steijvers, M., Grünwald, P.: A recurrent network that performs a context-sensitive prediction task. In: Procee" /><span class="c-article-references__counter">132.</span><p class="c-article-references__text" id="ref-CR132">Steijvers, M., Grünwald, P.: A recurrent network that performs a context-sensitive prediction task. In: Proceedings of the 18th Annual Conference of the Cognitive Science Society, pp. 335–339 (1996)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="I. Sutskever, J. Martens, GE. Dahl, GE. Hinton, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Sutskever, I., Martens, J., Dahl, G.E., Hinton, G.E.: On the importance of initialization and momentum in deep" /><span class="c-article-references__counter">133.</span><p class="c-article-references__text" id="ref-CR133">Sutskever, I., Martens, J., Dahl, G.E., Hinton, G.E.: On the importance of initialization and momentum in deep learning. ICML <b>3</b>(28), 1139–1147 (2013)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 133 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20the%20importance%20of%20initialization%20and%20momentum%20in%20deep%20learning&amp;journal=ICML&amp;volume=3&amp;issue=28&amp;pages=1139-1147&amp;publication_year=2013&amp;author=Sutskever%2CI&amp;author=Martens%2CJ&amp;author=Dahl%2CGE&amp;author=Hinton%2CGE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Swirszcz, G., Czarnecki, W.M., Pascanu, R.: Local minima in training of deep networks. CoRR (2016). arXiv:1611" /><span class="c-article-references__counter">134.</span><p class="c-article-references__text" id="ref-CR134">Swirszcz, G., Czarnecki, W.M., Pascanu, R.: Local minima in training of deep networks. CoRR (2016). <a href="http://arxiv.org/abs/1611.06310v1">arXiv:1611.06310v1</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Teboulle, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Teboulle, M.: A unified continuous optimization framework for center-based clustering methods. J. Mach. Learn." /><span class="c-article-references__counter">135.</span><p class="c-article-references__text" id="ref-CR135">Teboulle, M.: A unified continuous optimization framework for center-based clustering methods. J. Mach. Learn. Res. <b>8</b>, 65–102 (2007)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2280215" aria-label="View reference 135 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1222.68318" aria-label="View reference 135 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 135 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20unified%20continuous%20optimization%20framework%20for%20center-based%20clustering%20methods&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=8&amp;pages=65-102&amp;publication_year=2007&amp;author=Teboulle%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Teo, C.H., Smola, A., Vishwanathan, S., Le, Q.V.: A scalable modular convex solver for regularized risk minimi" /><span class="c-article-references__counter">136.</span><p class="c-article-references__text" id="ref-CR136">Teo, C.H., Smola, A., Vishwanathan, S., Le, Q.V.: A scalable modular convex solver for regularized risk minimization. In: Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 727–736. ACM (2007)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Tirumala, S.S., Ali, S., Ramesh, C.P.: Evolving deep neural networks: A new prospect. In: 12th International C" /><span class="c-article-references__counter">137.</span><p class="c-article-references__text" id="ref-CR137">Tirumala, S.S., Ali, S., Ramesh, C.P.: Evolving deep neural networks: A new prospect. In: 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD), 2016, pp. 69–74. IEEE (2016)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="KA. Toh, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Toh, K.A.: Deterministic global optimization for FNN training. IEEE Trans. Syst. Man Cybern. Part B (Cybern.) " /><span class="c-article-references__counter">138.</span><p class="c-article-references__text" id="ref-CR138">Toh, K.A.: Deterministic global optimization for FNN training. IEEE Trans. Syst. Man Cybern. Part B (Cybern.) <b>33</b>(6), 977–983 (2003)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 138 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Deterministic%20global%20optimization%20for%20FNN%20training&amp;journal=IEEE%20Trans.%20Syst.%20Man%20Cybern.%20Part%20B%20%28Cybern.%29&amp;volume=33&amp;issue=6&amp;pages=977-983&amp;publication_year=2003&amp;author=Toh%2CKA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="V. Vapnik, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Vapnik, V.: The Nature of Statistical Learning Theory. Springer, Berlin (2013)" /><span class="c-article-references__counter">139.</span><p class="c-article-references__text" id="ref-CR139">Vapnik, V.: The Nature of Statistical Learning Theory. Springer, Berlin (2013)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 139 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20Nature%20of%20Statistical%20Learning%20Theory&amp;publication_year=2013&amp;author=Vapnik%2CV">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Voglis, I. Lagaris, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Voglis, C., Lagaris, I.: A global optimization approach to neural network training. Neural Parallel Sci. Compu" /><span class="c-article-references__counter">140.</span><p class="c-article-references__text" id="ref-CR140">Voglis, C., Lagaris, I.: A global optimization approach to neural network training. Neural Parallel Sci. Comput. <b>14</b>(2), 231 (2006)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2358707" aria-label="View reference 140 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1152.90673" aria-label="View reference 140 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 140 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20global%20optimization%20approach%20to%20neural%20network%20training&amp;journal=Neural%20Parallel%20Sci.%20Comput.&amp;volume=14&amp;issue=2&amp;publication_year=2006&amp;author=Voglis%2CC&amp;author=Lagaris%2CI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Voglis, IE. Lagaris, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Voglis, C., Lagaris, I.E.: Towards ideal multistart: a stochastic approach for locating the minima of a contin" /><span class="c-article-references__counter">141.</span><p class="c-article-references__text" id="ref-CR141">Voglis, C., Lagaris, I.E.: Towards ideal multistart: a stochastic approach for locating the minima of a continuous function inside a bounded domain. Appl. Math. Comput. <b>213</b>(1), 216–229 (2009)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2533378" aria-label="View reference 141 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1167.65377" aria-label="View reference 141 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 141 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Towards%20ideal%20multistart%3A%20a%20stochastic%20approach%20for%20locating%20the%20minima%20of%20a%20continuous%20function%20inside%20a%20bounded%20domain&amp;journal=Appl.%20Math.%20Comput.&amp;volume=213&amp;issue=1&amp;pages=216-229&amp;publication_year=2009&amp;author=Voglis%2CC&amp;author=Lagaris%2CIE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Wang, " /><meta itemprop="datePublished" content="2016" /><meta itemprop="headline" content="Wang, D.: Editorial: Randomized algorithms for training neural networks. Inf. Sci. 364–365, 126–128 (2016)" /><span class="c-article-references__counter">142.</span><p class="c-article-references__text" id="ref-CR142">Wang, D.: Editorial: Randomized algorithms for training neural networks. Inf. Sci. <b>364–365</b>, 126–128 (2016)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 142 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Editorial%3A%20Randomized%20algorithms%20for%20training%20neural%20networks&amp;journal=Inf.%20Sci.&amp;volume=364%E2%80%93365&amp;pages=126-128&amp;publication_year=2016&amp;author=Wang%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Werbos, P.J.: Supervised learning: Can it escape its local minimum? In: Theoretical Advances in Neural Computa" /><span class="c-article-references__counter">143.</span><p class="c-article-references__text" id="ref-CR143">Werbos, P.J.: Supervised learning: Can it escape its local minimum? In: Theoretical Advances in Neural Computation and Learning, pp. 449–461. Springer (1994)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DS. Yeung, JC. Li, WWY. Ng, PPK. Chan, " /><meta itemprop="datePublished" content="2016" /><meta itemprop="headline" content="Yeung, D.S., Li, J.C., Ng, W.W.Y., Chan, P.P.K.: Mlpnn training via a multiobjective optimization of training " /><span class="c-article-references__counter">144.</span><p class="c-article-references__text" id="ref-CR144">Yeung, D.S., Li, J.C., Ng, W.W.Y., Chan, P.P.K.: Mlpnn training via a multiobjective optimization of training error and stochastic sensitivity. IEEE Trans. Neural Netw. Learn. Syst. <b>27</b>(5), 978–992 (2016). <a href="https://doi.org/10.1109/TNNLS.2015.2431251">https://doi.org/10.1109/TNNLS.2015.2431251</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=3497938" aria-label="View reference 144 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 144 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Mlpnn%20training%20via%20a%20multiobjective%20optimization%20of%20training%20error%20and%20stochastic%20sensitivity&amp;journal=IEEE%20Trans.%20Neural%20Netw.%20Learn.%20Syst.&amp;doi=10.1109%2FTNNLS.2015.2431251&amp;volume=27&amp;issue=5&amp;pages=978-992&amp;publication_year=2016&amp;author=Yeung%2CDS&amp;author=Li%2CJC&amp;author=Ng%2CWWY&amp;author=Chan%2CPPK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="W. Yu, F. Zhuang, Q. He, Z. Shi, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Yu, W., Zhuang, F., He, Q., Shi, Z.: Learning deep representations via extreme learning machines. Neurocomputi" /><span class="c-article-references__counter">145.</span><p class="c-article-references__text" id="ref-CR145">Yu, W., Zhuang, F., He, Q., Shi, Z.: Learning deep representations via extreme learning machines. Neurocomputing <b>149</b>, 308–315 (2015)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 145 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20deep%20representations%20via%20extreme%20learning%20machines&amp;journal=Neurocomputing&amp;volume=149&amp;pages=308-315&amp;publication_year=2015&amp;author=Yu%2CW&amp;author=Zhuang%2CF&amp;author=He%2CQ&amp;author=Shi%2CZ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JR. Zhang, J. Zhang, TM. Lok, MR. Lyu, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Zhang, J.R., Zhang, J., Lok, T.M., Lyu, M.R.: A hybrid particle swarm optimization-back-propagation algorithm " /><span class="c-article-references__counter">146.</span><p class="c-article-references__text" id="ref-CR146">Zhang, J.R., Zhang, J., Lok, T.M., Lyu, M.R.: A hybrid particle swarm optimization-back-propagation algorithm for feedforward neural network training. Appl. Math. Comput. <b>185</b>(2), 1026–1037 (2007)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1112.65059" aria-label="View reference 146 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 146 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20hybrid%20particle%20swarm%20optimization-back-propagation%20algorithm%20for%20feedforward%20neural%20network%20training&amp;journal=Appl.%20Math.%20Comput.&amp;volume=185&amp;issue=2&amp;pages=1026-1037&amp;publication_year=2007&amp;author=Zhang%2CJR&amp;author=Zhang%2CJ&amp;author=Lok%2CTM&amp;author=Lyu%2CMR">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10898-018-0701-7-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1" data-title="Acknowledgements"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>Many thanks to two anonymous referees who read carefully the paper and gave useful suggestions that allowed to improve substantially the paper. Thanks to Marianna De Santis and to the Ph.D. students at DIAG who gave their comments on a first version of the paper. Finally I wish to thank prof. Luigi Grippo for pleasant and fruitful conversations on optimization topics, not only about ML, since the time of my Ph.D.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Dip. di Ingegneria informatica automatica e gestionale A. Ruberti, Sapienza - University of Rome, Via Ariosto 25, 00185, Rome, Italy</p><p class="c-article-author-affiliation__authors-list">Laura Palagi</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Laura-Palagi"><span class="c-article-authors-search__title u-h3 js-search-name">Laura Palagi</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Laura+Palagi&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Laura+Palagi" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Laura+Palagi%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10898-018-0701-7/email/correspondent/c1/new">Laura Palagi</a>.</p></div></div></section><section aria-labelledby="additional-information" data-title="Additional information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><p>The author acknowledges support within the project “Distributed optimization algorithms for Big Data” (2017) (No RM11715C7E49E89C) which has received funding from Sapienza, University of Rome.</p></div></div></section><section aria-labelledby="rightslink" data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Global%20optimization%20issues%20in%20deep%20network%20regression%3A%20an%20overview&amp;author=Laura%20Palagi&amp;contentID=10.1007%2Fs10898-018-0701-7&amp;copyright=Springer%20Science%2BBusiness%20Media%2C%20LLC%2C%20part%20of%20Springer%20Nature&amp;publication=0925-5001&amp;publicationDate=2018-09-06&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10898-018-0701-7" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10898-018-0701-7" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Palagi, L. Global optimization issues in deep network regression: an overview.
                    <i>J Glob Optim</i> <b>73, </b>239–277 (2019). https://doi.org/10.1007/s10898-018-0701-7</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" href="/article/10.1007/s10898-018-0701-7.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2017-06-17">17 June 2017</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2018-08-27">27 August 2018</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2018-09-06">06 September 2018</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2019-02-15">15 February 2019</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10898-018-0701-7" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10898-018-0701-7</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Supervised learning</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Deep networks</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Feedforward neural networks</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Global optimization</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Weights optimization</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Hybrid algorithms</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
                </div>

                <div data-test="collections">
                    <div id="SpringerLinkArticleCollections">
    
</div>

                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        
                            <div class="c-article-buy-box">
                                <div class="sprcom-buybox-articleSidebar" id="sprcom-buybox-articleSidebar">
 <h2 class="c-box__heading">Access options</h2>
 <article class="c-box" data-test-id="buy-article">
  <h3 class="c-box__heading">Buy single article</h3>
  <div class="c-box__body">
   <div class="buybox__info">
    <p>Instant access to the full article PDF.</p>
   </div>
   <div class="buybox__buy">
    <p class="buybox__price">42,64 €</p>
    <p class="buybox__price-info">Tax calculation will be finalised during checkout.</p>
    <form action="https://order.springer.com/public/checkout?utm_source=springerlink&amp;utm_medium=referral&amp;utm_campaign=sl-buybox_articlePage_article&amp;abtest=v2" method="post">
     <input type="hidden" name="type" value="article">
     <input type="hidden" name="doi" value="10.1007/s10898-018-0701-7">
     <input type="hidden" name="isxn" value="1573-2916">
     <input type="hidden" name="contenttitle" value="Global optimization issues in deep network regression: an overview">
     <input type="hidden" name="copyrightyear" value="2018">
     <input type="hidden" name="year" value="2018">
     <input type="hidden" name="authors" value="Laura Palagi">
     <input type="hidden" name="title" value="Journal of Global Optimization">
     <input type="hidden" name="mac" value="DC28390165FECC34B77A6B81654A97F0">
     <input type="submit" class="c-box__button" data-track="click" data-track-action="buy pdf" data-track-category="ppv" data-track-label="buy article action" value="Buy article PDF">
    </form>
   </div>
  </div>
 </article>
 <article class="c-box buybox__subscribe-subscription" data-test-id="journal-subscription">
  <h3 class="c-box__heading">Subscribe to journal</h3>
  <div class="c-box__body">
   <div class="buybox__info">
    <p>Immediate online access to all issues from 2019. Subscription will auto renew annually.</p>
   </div>
   <div class="buybox__buy">
    <p class="buybox__price">135,68 €</p>
    <p class="buybox__price-info">Tax calculation will be finalised during checkout.</p>
    <form action="https://order.springer.com/public/checkout?utm_source=springerlink&amp;utm_medium=referral&amp;utm_campaign=sl-buybox_articlePage_journal&amp;abtest=v2" method="post">
     <input type="hidden" name="type" value="journal">
     <input type="hidden" name="contenttitle" value="Journal of Global Optimization">
     <input type="hidden" name="journalnumber" value="10898">
     <input type="hidden" name="pricetype" value="PSE">
     <input type="hidden" name="countrycode" value="IT">
     <input type="submit" class="c-box__button" data-track="click" data-track-action="subscribe to journal" data-track-category="journal" data-track-label="subscribe action, new buybox" value="Buy journal subscription">
    </form>
   </div>
  </div>
 </article>
 <article class="c-box buybox__rent-article" id="deepdyve" style="display: none" data-test-id="journal-subscription">
  <div class="c-box__body">
   <div class="buybox__info">
    <p><a class="deepdyve-link" target="deepdyve" rel="nofollow" data-track="click" data-track-action="rent article" data-track-label="rent action, new buybox">Rent this article via DeepDyve.</a></p>
   </div>
  </div>
  <script>
            function deepDyveResponse(data) {
                if (data.status === 'ok') {
                    [].slice.call(document.querySelectorAll('.c-box.buybox__rent-article')).forEach(function (article) {
                        article.style.display = 'flex'
                        var link = article.querySelector('.deepdyve-link')
                        if (link) {
                          link.setAttribute('href', data.url)
                        }
                    })
                }
            }

            var script = document.createElement('script')
            script.src = '//www.deepdyve.com/rental-link?docId=10.1007/s10898-018-0701-7&journal=1573-2916&fieldName=journal_doi&affiliateId=springer&format=jsonp&callback=deepDyveResponse'
            document.body.appendChild(script)
          </script>
 </article>
 <aside class="buybox__institutional-sub">
  <div class="c-box__body">
   <div class="buybox__info">
    <p><a href="https://www.springernature.com/gp/librarians/licensing/license-options?utm_source=springerlink&amp;utm_medium=referral&amp;utm_campaign=sl-buybox_articlePage_institutionalCustomer&amp;abtest=v2" data-track="click" data-track-action="institutional link" data-track-label="institutional subscriptions, new buybox">Learn more about Institutional subscriptions</a></p>
   </div>
  </div>
 </aside>
 <style>.sprcom-buybox-articleSidebar{
  box-shadow: 0px 0px 5px rgba(51,51,51,0.101);
  display: flex;
  flex-wrap: wrap;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
  text-align: center;
}
.sprcom-buybox-articleSidebar *{
  box-sizing: border-box;
  line-height: calc(100% + 4px);
  margin: 0px;
}
.sprcom-buybox-articleSidebar > *{
  display: flex;
  flex-basis: 240px;
  flex-direction: column;
  flex-grow: 1;
  flex-shrink: 1;
  margin: 0.5px;
}
.sprcom-buybox-articleSidebar > *{
  box-shadow: 0 0 0 1px rgba(204,204,204,0.494);
}
.sprcom-buybox-articleSidebar .c-box__body{
  display: flex;
  flex-direction: column-reverse;
  flex-grow: 1;
  justify-content: space-between;
  padding: 6%;
}
.sprcom-buybox-articleSidebar .c-box__body .buybox__buy{
  display: flex;
  flex-direction: column-reverse;
}
.sprcom-buybox-articleSidebar p{
  color: #333;
  font-size: 15px;
}
.sprcom-buybox-articleSidebar .buybox__price{
  font-size: 24px;
  font-weight: 500;
  line-height: calc(100% + 8px);
  margin: 20px 0;
  order: 1;
}
.sprcom-buybox-articleSidebar form{
  order: 1;
}
.sprcom-buybox-articleSidebar .buybox__price-info{
  margin-bottom: 20px;
}
.sprcom-buybox-articleSidebar .c-box__heading{
  background-color: #f0f0f0;
  color: #333;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen-Sans, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
  font-size: 16px;
  margin: 0px;
  padding: 10px 12px;
  text-align: center;
}
.sprcom-buybox-articleSidebar .c-box__button{
  background-color: #3365A4;
  border: 1px solid transparent;
  border-radius: 2px;
  color: #fff;
  cursor: pointer;
  display: inline-block;
  font-family: inherit;
  font-size: 16px;
  max-width: 222px;
  padding: 10px 12px;
  text-decoration: none;
  width: 100%;
}
.sprcom-buybox-articleSidebar h3{
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  overflow: hidden;
  position: absolute;
  width: 1px;
}
.sprcom-buybox-articleSidebar h2{
  flex-basis: 100%;
  margin-bottom: 16px;
  text-align: left;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub, .buybox__rent-article .c-box__body{
  flex-direction: row;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub, .buybox__rent-article .buybox__info{
  text-align: left;
}
.sprcom-buybox-articleSidebar .buybox__institutional-sub{
  background-color: #f0f0f0;
}
.sprcom-buybox-articleSidebar .visually-hidden{
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  overflow: hidden;
  position: absolute;
  width: 1px;
}
.sprcom-buybox-articleSidebar style{
  display: none;
}
</style>
</div>
                            </div>
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10898/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=701;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 87.4.11.85</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Not affiliated
        </p>

    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2021 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
        <symbol id="icon-info" viewBox="0 0 18 18">
            <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-chevron-down" viewBox="0 0 16 16">
            <path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>
