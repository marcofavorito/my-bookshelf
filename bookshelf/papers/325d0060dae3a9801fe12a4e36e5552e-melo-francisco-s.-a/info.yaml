author: Melo, Francisco S. and Ribeiro, M. Isabel
author_list:
- affiliation: []
  family: Melo
  given: Francisco S.
- affiliation: []
  family: Ribeiro
  given: M. Isabel
citations:
- author: R. Sutton
  first-page: '9'
  journal-title: Machine Learning
  unstructured: 'Sutton, R.: Learning to predict by the methods of temporal differences.
    Machine Learning 3, 9–44 (1988)'
  volume: '3'
  year: '1988'
- unstructured: 'Watkins, C.: Learning from delayed rewards. PhD thesis, King’s College,
    University of Cambridge (May 1989)'
- unstructured: 'Rummery, G., Niranjan, M.: On-line Q-learning using connectionist
    systems. Technical Report CUED/F-INFENG/TR 166, Cambridge University Engineering
    Department (1994)'
- author: R. Sutton
  doi: 10.1145/122344.122377
  first-page: '160'
  issue: '4'
  journal-title: ACM SIGART Bulletin
  unstructured: 'Sutton, R.: DYNA, an integrated architecture for learning, planning,
    and reacting. ACM SIGART Bulletin 2(4), 160–163 (1991)'
  volume: '2'
  year: '1991'
- unstructured: 'Barto, A., Bradtke, S., Singh, S.: Learning to act using real-time
    dynamic programming. Technical Report UM-CS-1993-002, Department of Computer Science,
    University of Massachusetts at Amherst (1993)'
- unstructured: 'Boyan, J.: Least-squares temporal difference learning. In: Proc.
    16th Int. Conf. Machine Learning, 49–56 (1999)'
- unstructured: 'Bertsekas, D., Tsitsiklis, J.: Neuro-Dynamic Programming. Athena
    Scientific (1996)'
- author: R. Sutton
  first-page: '1038'
  journal-title: Advances in Neural Information Processing Systems
  unstructured: 'Sutton, R.: Generalization in reinforcement learning: Successful
    examples using sparse coarse coding. Advances in Neural Information Processing
    Systems 8, 1038–1044 (1996)'
  volume: '8'
  year: '1996'
- author: J. Boyan
  first-page: '369'
  journal-title: Advances in Neural Information Processing Systems
  unstructured: 'Boyan, J., Moore, A.: Generalization in reinforcement learning: Safely
    approximating the value function. Advances in Neural Information Processing Systems 7,
    369–376 (1994)'
  volume: '7'
  year: '1994'
- author: G. Tesauro
  doi: 10.1162/neco.1994.6.2.215
  first-page: '215'
  issue: '2'
  journal-title: Neural Computation
  unstructured: 'Tesauro, G.: TD-Gammon, a self-teaching backgammon program, achieves
    master-level play. Neural Computation 6(2), 215–219 (1994)'
  volume: '6'
  year: '1994'
- author: S. Singh
  first-page: '361'
  journal-title: Advances in Neural Information Processing Systems
  unstructured: 'Singh, S., Jaakkola, T., Jordan, M.: Reinforcement learning with
    soft state aggregation. Advances in Neural Information Processing Systems 7, 361–368
    (1994)'
  volume: '7'
  year: '1994'
- unstructured: 'Gordon, G.: Stable function approximation in dynamic programming.
    Technical Report CMU-CS-95-103, School of Computer Science, Carnegie Mellon University
    (1995)'
- author: J. Tsitsiklis
  first-page: '59'
  journal-title: Machine Learning
  unstructured: 'Tsitsiklis, J., Van Roy, B.: Feature-based methods for large scale
    dynamic programming. Machine Learning 22, 59–94 (1996)'
  volume: '22'
  year: '1996'
- unstructured: 'Precup, D., Sutton, R., Dasgupta, S.: Off-policy temporal-difference
    learning with function approximation. In: Proc. 18th Int. Conf. Machine Learning,
    417–424 (2001)'
- doi: 10.1145/1015330.1015445
  unstructured: 'Szepesvári, C., Smart, W.: Interpolation-based Q-learning. In: Proc.
    21st Int. Conf. Machine learning, 100–107 (2004)'
- author: J. Tsitsiklis
  doi: 10.1109/9.580874
  first-page: '674'
  issue: '5'
  journal-title: IEEE Transactions on Automatic Control
  unstructured: 'Tsitsiklis, J., Van Roy, B.: An analysis of temporal-difference learning
    with function approximation. IEEE Transactions on Automatic Control AC-42(5),
    674–690 (1996)'
  volume: AC-42
  year: '1996'
- author: V. Borkar
  doi: 10.1017/S0269964800142081
  first-page: '243'
  journal-title: Probability in the Engineering and Informational Sciences
  unstructured: 'Borkar, V.: A learning algorithm for discrete-time stochastic control.
    Probability in the Engineering and Informational Sciences 14, 243–258 (2000)'
  volume: '14'
  year: '2000'
- doi: 10.23919/ECC.2007.7068926
  unstructured: 'Melo, F., Ribeiro, M.I.: Q-learning with linear function approximation.
    Technical Report RT-602-07, Institute for Systems and Robotics (March 2007)'
- author: C. Watkins
  first-page: '279'
  journal-title: Machine Learning
  unstructured: 'Watkins, C., Dayan, P.: Technical note: Q-learning. Machine Learning 8,
    279–292 (1992)'
  volume: '8'
  year: '1992'
- author: S. Meyn
  doi: 10.1007/978-1-4471-3267-7
  unstructured: 'Meyn, S., Tweedie, R.: Markov Chains and Stochastic Stability. Springer,
    Heidelberg (1993)'
  volume-title: Markov Chains and Stochastic Stability
  year: '1993'
- doi: 10.1016/B978-1-55860-377-6.50013-X
  unstructured: 'Baird, L.: Residual algorithms: Reinforcement learning with function
    approximation. In: Proc. 12th Int. Conf. Machine Learning, 30–37 (1995)'
- unstructured: 'Bertsekas, D., Borkar, V., Nedić, A.: 9. In: Improved temporal difference
    methods with linear function approximation. Wiley Publishers, 235–260 (2004)'
- unstructured: 'Baker, W.: Learning via stochastic approximation in function space.
    PhD Thesis (1997)'
- author: C. Lusena
  doi: 10.1613/jair.714
  first-page: '83'
  journal-title: J. Artificial Intelligence Research
  unstructured: 'Lusena, C., Goldsmith, J., Mundhenk, M.: Nonapproximability results
    for partially observable Markov decision processes. J. Artificial Intelligence
    Research 14, 83–103 (2001)'
  volume: '14'
  year: '2001'
- author: C. Papadimitriou
  doi: 10.1287/moor.12.3.441
  first-page: '441'
  issue: '3'
  journal-title: Mathematics of Operations Research
  unstructured: 'Papadimitriou, C., Tsitsiklis, J.: The complexity of Markov chain
    decision processes. Mathematics of Operations Research 12(3), 441–450 (1987)'
  volume: '12'
  year: '1987'
- unstructured: 'Cassandra, A.: Exact and approximate algorithms for partially observable
    Markov decision processes. PhD thesis, Brown University (May 1998)'
- unstructured: 'Aberdeen, D.: A (revised) survey of approximate methods for solving
    partially observable Markov decision processes. Technical report, National ICT
    Australia, Canberra, Australia (2003)'
- doi: 10.1016/B978-1-55860-377-6.50052-9
  unstructured: 'Littman, M., Cassandra, A., Kaelbling, L.: Learning policies for
    partially observable environments: Scaling up. In: Proc. 12th Int. Conf. Machine
    Learning, 362–370 (1995)'
- unstructured: 'Parr, R., Russell, S.: Approximating optimal policies for partially
    observable stochastic domains. In: Proc. Int. Joint Conf. Artificial Intelligence,
    1088–1094 (1995)'
- unstructured: 'He, Q., Shayman, M.: Solving POMDPs by on-policy linear approximate
    learning algorithm. In: Proc. Conf. Information Sciences and Systems (2000)'
- unstructured: 'Glaubius, R., Smart, W.: Manifold representations for value-function
    approximation in reinforcement learning. Technical Report 05-19, Department of
    Computer Science and Engineering, Washington University in St. Louis (2005)'
- doi: 10.1145/1143844.1143901
  unstructured: 'Keller, P., Mannor, S., Precup, D.: Automatic basis function construction
    for approximate dynamic programming and reinforcement learning. In: Proc. 23rd
    Int. Conf. Machine Learning, 449–456 (2006)'
- author: I. Menache
  doi: 10.1007/s10479-005-5732-z
  first-page: '215'
  issue: '1'
  journal-title: Annals of Operations Research
  unstructured: 'Menache, I., Mannor, S., Shimkin, N.: Basis function adaptation in
    temporal difference reinforcement learning. Annals of Operations Research 134(1),
    215–238 (2005)'
  volume: '134'
  year: '2005'
doi: 10.1007/978-3-540-72927-3_23
isbn:
- '9783540729259'
journal: Learning Theory
pages: 308--322
publisher: Springer Berlin Heidelberg
ref: QLearningWithMeloNone
time-added: 2023-01-12-22:52:40
title: Q-Learning with Linear Function Approximation
type: inbook
url: http://dx.doi.org/10.1007/978-3-540-72927-3_23
