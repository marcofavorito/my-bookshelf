abstract: Reasoning is a fundamental aspect of human intelligence that plays a crucial
  role in activities such as problem solving, decision making, and critical thinking.
  In recent years, large language models (LLMs) have made significant progress in
  natural language processing, and there is observation that these models may exhibit
  reasoning abilities when they are sufficiently large. However, it is not yet clear
  to what extent LLMs are capable of reasoning. This paper provides a comprehensive
  overview of the current state of knowledge on reasoning in LLMs, including techniques
  for improving and eliciting reasoning in these models, methods and benchmarks for
  evaluating reasoning abilities, findings and implications of previous research in
  this field, and suggestions on future directions. Our aim is to provide a detailed
  and up-to-date review of this topic and stimulate meaningful discussion and future
  work.
archiveprefix: arXiv
author: Huang, Jie and Chang, Kevin Chen-Chuan
author_list:
- family: Huang
  given: Jie
- family: Chang
  given: Kevin Chen-Chuan
eprint: 2212.10403v1
file: 2212.10403v1.pdf
files:
- huang-jie-and-chang-kevin-chen-chuantowards-reasoning-in-large-language-models-a-survey2022.pdf
month: Dec
primaryclass: cs.CL
ref: 2212.10403v1
time-added: 2023-02-18-18:50:03
title: 'Towards Reasoning in Large Language Models: A Survey'
type: article
url: http://arxiv.org/abs/2212.10403v1
year: '2022'
