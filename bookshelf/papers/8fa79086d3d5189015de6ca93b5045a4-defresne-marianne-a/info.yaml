abstract: In the ongoing quest for hybridizing discrete reasoning with neural nets,
  there is an increasing interest in neural architectures that can learn how to solve
  discrete reasoning or optimization problems from natural inputs. In this paper,
  we introduce a scalable neural architecture and loss function dedicated to learning
  the constraints and criteria of NP-hard reasoning problems expressed as discrete
  Graphical Models. Our loss function solves one of the main limitations of Besag's
  pseudo-loglikelihood, enabling learning of high energies. We empirically show it
  is able to efficiently learn how to solve NP-hard reasoning problems from natural
  inputs as the symbolic, visual or many-solutions Sudoku problems as well as the
  energy optimization formulation of the protein design problem, providing data efficiency,
  interpretability, and \textit{a posteriori} control over predictions.
archiveprefix: arXiv
author: Defresne, Marianne and Barbe, Sophie and Schiex, Thomas
author_list:
- family: Defresne
  given: Marianne
- family: Barbe
  given: Sophie
- family: Schiex
  given: Thomas
eprint: 2305.07617v1
file: 2305.07617v1.pdf
files:
- defresne-marianne-and-barbe-sophie-and-schiex-thomasscalable-coupling-of-deep-learning-with-logical-reasoning2023.pdf
month: May
primaryclass: cs.AI
ref: 2305.07617v1
time-added: 2023-05-18-13:55:46
title: Scalable Coupling of Deep Learning with Logical Reasoning
type: article
url: http://arxiv.org/abs/2305.07617v1
year: '2023'
