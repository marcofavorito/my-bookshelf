abstract: 'Advanced AI models hold the promise of tremendous benefits for humanity,
  but society needs to proactively manage the accompanying risks. In this paper, we
  focus on what we term "frontier AI" models: highly capable foundation models that
  could possess dangerous capabilities sufficient to pose severe risks to public safety.
  Frontier AI models pose a distinct regulatory challenge: dangerous capabilities
  can arise unexpectedly; it is difficult to robustly prevent a deployed model from
  being misused; and, it is difficult to stop a model''s capabilities from proliferating
  broadly. To address these challenges, at least three building blocks for the regulation
  of frontier models are needed: (1) standard-setting processes to identify appropriate
  requirements for frontier AI developers, (2) registration and reporting requirements
  to provide regulators with visibility into frontier AI development processes, and
  (3) mechanisms to ensure compliance with safety standards for the development and
  deployment of frontier AI models. Industry self-regulation is an important first
  step. However, wider societal discussions and government intervention will be needed
  to create standards and to ensure compliance with them. We consider several options
  to this end, including granting enforcement powers to supervisory authorities and
  licensure regimes for frontier AI models. Finally, we propose an initial set of
  safety standards. These include conducting pre-deployment risk assessments; external
  scrutiny of model behavior; using risk assessments to inform deployment decisions;
  and monitoring and responding to new information about model capabilities and uses
  post-deployment. We hope this discussion contributes to the broader conversation
  on how to balance public safety risks and innovation benefits from advances at the
  frontier of AI development.'
archiveprefix: arXiv
author: Anderljung, Markus and Barnhart, Joslyn and Korinek, Anton and Leung, Jade
  and O'Keefe, Cullen and Whittlestone, Jess and Avin, Shahar and Brundage, Miles
  and Bullock, Justin and Cass-Beggs, Duncan and Chang, Ben and Collins, Tantum and
  Fist, Tim and Hadfield, Gillian and Hayes, Alan and Ho, Lewis and Hooker, Sara and
  Horvitz, Eric and Kolt, Noam and Schuett, Jonas and Shavit, Yonadav and Siddarth,
  Divya and Trager, Robert and Wolf, Kevin
author_list:
- family: Anderljung
  given: Markus
- family: Barnhart
  given: Joslyn
- family: Korinek
  given: Anton
- family: Leung
  given: Jade
- family: O'Keefe
  given: Cullen
- family: Whittlestone
  given: Jess
- family: Avin
  given: Shahar
- family: Brundage
  given: Miles
- family: Bullock
  given: Justin
- family: Cass-Beggs
  given: Duncan
- family: Chang
  given: Ben
- family: Collins
  given: Tantum
- family: Fist
  given: Tim
- family: Hadfield
  given: Gillian
- family: Hayes
  given: Alan
- family: Ho
  given: Lewis
- family: Hooker
  given: Sara
- family: Horvitz
  given: Eric
- family: Kolt
  given: Noam
- family: Schuett
  given: Jonas
- family: Shavit
  given: Yonadav
- family: Siddarth
  given: Divya
- family: Trager
  given: Robert
- family: Wolf
  given: Kevin
eprint: 2307.03718v2
file: 2307.03718v2.pdf
files:
- anderljung-markus-and-barnhart-joslyn-and-korinek-anton-and-leung-jade-and-o-keefe-cullen-and-whittlestone-jess-and-avin-shahar-and-brundage-m.pdf
month: Jul
primaryclass: cs.CY
ref: 2307.03718v2
time-added: 2023-07-13-17:02:05
title: 'Frontier AI Regulation: Managing Emerging Risks to Public Safety'
type: article
url: http://arxiv.org/abs/2307.03718v2
year: '2023'
