abstract: Machine learning on graphs is an important and ubiquitous task with applications
  ranging from drug design to friendship recommendation in social networks. The primary
  challenge in this domain is finding a way to represent, or encode, graph structure
  so that it can be easily exploited by machine learning models. Traditionally, machine
  learning approaches relied on user-defined heuristics to extract features encoding
  structural information about a graph (e.g., degree statistics or kernel functions).
  However, recent years have seen a surge in approaches that automatically learn to
  encode graph structure into low-dimensional embeddings, using techniques based on
  deep learning and nonlinear dimensionality reduction. Here we provide a conceptual
  review of key advancements in this area of representation learning on graphs, including
  matrix factorization-based methods, random-walk based algorithms, and graph neural
  networks. We review methods to embed individual nodes as well as approaches to embed
  entire (sub)graphs. In doing so, we develop a unified framework to describe these
  recent approaches, and we highlight a number of important applications and directions
  for future work.
archiveprefix: arXiv
author: Hamilton, William L. and Ying, Rex and Leskovec, Jure
author_list:
- family: Hamilton
  given: William L.
- family: Ying
  given: Rex
- family: Leskovec
  given: Jure
eprint: 1709.05584v3
file: 1709.05584v3.pdf
files:
- hamilton-william-l.-and-ying-rex-and-leskovec-jurerepresentation-learning-on-graphs-methods-and-applications2017.pdf
month: Sep
primaryclass: cs.SI
ref: 1709.05584v3
time-added: 2021-09-30-15:10:37
title: 'Representation Learning on Graphs: Methods and Applications'
type: article
url: http://arxiv.org/abs/1709.05584v3
year: '2017'
