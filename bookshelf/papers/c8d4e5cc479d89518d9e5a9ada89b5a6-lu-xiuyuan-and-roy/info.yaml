abstract: Reinforcement learning agents have demonstrated remarkable achievements
  in simulated environments. Data efficiency poses an impediment to carrying this
  success over to real environments. The design of data-efficient agents calls for
  a deeper understanding of information acquisition and representation. We develop
  concepts and establish a regret bound that together offer principled guidance. The
  bound sheds light on questions of what information to seek, how to seek that information,
  and it what information to retain. To illustrate concepts, we design simple agents
  that build on them and present computational results that demonstrate improvements
  in data efficiency.
archiveprefix: arXiv
author: Lu, Xiuyuan and Roy, Benjamin Van and Dwaracherla, Vikranth and Ibrahimi,
  Morteza and Osband, Ian and Wen, Zheng
author_list:
- family: Lu
  given: Xiuyuan
- family: Roy
  given: Benjamin Van
- family: Dwaracherla
  given: Vikranth
- family: Ibrahimi
  given: Morteza
- family: Osband
  given: Ian
- family: Wen
  given: Zheng
eprint: 2103.04047v1
file: 2103.04047v1.pdf
files:
- lu-xiuyuan-and-roy-benjamin-van-and-dwaracherla-vikranth-and-ibrahimi-morteza-and-osband-ian-and-wen-zhengreinforcement-learning-bit-by-bit2021.pdf
month: Mar
primaryclass: cs.LG
ref: 2103.04047v1
time-added: 2021-03-15-19:49:10
title: Reinforcement Learning, Bit by Bit
type: article
url: http://arxiv.org/abs/2103.04047v1
year: '2021'
