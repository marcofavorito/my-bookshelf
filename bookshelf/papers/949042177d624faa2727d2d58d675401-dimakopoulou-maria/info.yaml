abstract: We consider a team of reinforcement learning agents that concurrently learn
  to operate in a common environment. We identify three properties - adaptivity, commitment,
  and diversity - which are necessary for efficient coordinated exploration and demonstrate
  that straightforward extensions to single-agent optimistic and posterior sampling
  approaches fail to satisfy them. As an alternative, we propose seed sampling, which
  extends posterior sampling in a manner that meets these requirements. Simulation
  results investigate how per-agent regret decreases as the number of agents grows,
  establishing substantial advantages of seed sampling over alternative exploration
  schemes.
archiveprefix: arXiv
author: Dimakopoulou, Maria and Roy, Benjamin Van
author_list:
- family: Dimakopoulou
  given: Maria
- family: Roy
  given: Benjamin Van
eprint: 1802.01282v1
file: 1802.01282v1.pdf
files:
- dimakopoulou-maria-and-roy-benjamin-vancoordinated-exploration-in-concurrent-reinforcement-learning2018.pdf
month: Feb
note: Proceedings of the 35th International Conference on Machine   Learning, volume
  80 of Proceedings of Machine Learning Research, pages   1271-1279, Stockholmsm\"assan,
  Stockholm Sweden, 10-15 Jul 2018
primaryclass: cs.AI
ref: 1802.01282v1
time-added: 2022-05-06-18:00:36
title: Coordinated Exploration in Concurrent Reinforcement Learning
type: article
url: http://arxiv.org/abs/1802.01282v1
year: '2018'
