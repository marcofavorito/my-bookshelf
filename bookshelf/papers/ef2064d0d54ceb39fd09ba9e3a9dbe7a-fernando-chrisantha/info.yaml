abstract: Popular prompt strategies like Chain-of-Thought Prompting can dramatically
  improve the reasoning abilities of Large Language Models (LLMs) in various domains.
  However, such hand-crafted prompt-strategies are often sub-optimal. In this paper,
  we present Promptbreeder, a general-purpose self-referential self-improvement mechanism
  that evolves and adapts prompts for a given domain. Driven by an LLM, Promptbreeder
  mutates a population of task-prompts, and subsequently evaluates them for fitness
  on a training set. Crucially, the mutation of these task-prompts is governed by
  mutation-prompts that the LLM generates and improves throughout evolution in a self-referential
  way. That is, Promptbreeder is not just improving task-prompts, but it is also improving
  the mutationprompts that improve these task-prompts. Promptbreeder outperforms state-of-the-art
  prompt strategies such as Chain-of-Thought and Plan-and-Solve Prompting on commonly
  used arithmetic and commonsense reasoning benchmarks. Furthermore, Promptbreeder
  is able to evolve intricate task-prompts for the challenging problem of hate speech
  classification.
archiveprefix: arXiv
author: Fernando, Chrisantha and Banarse, Dylan and Michalewski, Henryk and Osindero,
  Simon and Rocktäschel, Tim
author_list:
- family: Fernando
  given: Chrisantha
- family: Banarse
  given: Dylan
- family: Michalewski
  given: Henryk
- family: Osindero
  given: Simon
- family: Rocktäschel
  given: Tim
eprint: 2309.16797v1
file: 2309.16797v1.pdf
files:
- fernando-chrisantha-and-banarse-dylan-and-michalewski-henryk-and-osindero-simon-and-rocktaschel-timpromptbreeder-self-referential-self-improveme.pdf
month: Sep
primaryclass: cs.CL
ref: 2309.16797v1
time-added: 2023-10-04-09:40:04
title: 'Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution'
type: article
url: http://arxiv.org/abs/2309.16797v1
year: '2023'
