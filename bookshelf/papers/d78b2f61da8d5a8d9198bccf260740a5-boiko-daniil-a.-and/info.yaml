abstract: Transformer-based large language models are rapidly advancing in the field
  of machine learning research, with applications spanning natural language, biology,
  chemistry, and computer programming. Extreme scaling and reinforcement learning
  from human feedback have significantly improved the quality of generated text, enabling
  these models to perform various tasks and reason about their choices. In this paper,
  we present an Intelligent Agent system that combines multiple large language models
  for autonomous design, planning, and execution of scientific experiments. We showcase
  the Agent's scientific research capabilities with three distinct examples, with
  the most complex being the successful performance of catalyzed cross-coupling reactions.
  Finally, we discuss the safety implications of such systems and propose measures
  to prevent their misuse.
archiveprefix: arXiv
author: Boiko, Daniil A. and MacKnight, Robert and Gomes, Gabe
author_list:
- family: Boiko
  given: Daniil A.
- family: MacKnight
  given: Robert
- family: Gomes
  given: Gabe
eprint: 2304.05332v1
file: 2304.05332v1.pdf
files:
- boiko-daniil-a.-and-macknight-robert-and-gomes-gabeemergent-autonomous-scientific-research-capabilities-of-large-language-models2023.pdf
month: Apr
primaryclass: physics.chem-ph
ref: 2304.05332v1
time-added: 2023-04-14-10:47:44
title: Emergent autonomous scientific research capabilities of large language   models
type: article
url: http://arxiv.org/abs/2304.05332v1
year: '2023'
