abstract: We study how training molds the Riemannian geometry induced by neural network
  feature maps. At infinite width, neural networks with random parameters induce highly
  symmetric metrics on input space. Feature learning in networks trained to perform
  classification tasks magnifies local areas along decision boundaries. These changes
  are consistent with previously proposed geometric approaches for hand-tuning of
  kernel methods to improve generalization.
archiveprefix: arXiv
author: Zavatone-Veth, Jacob A. and Yang, Sheng and Rubinfien, Julian A. and Pehlevan,
  Cengiz
author_list:
- family: Zavatone-Veth
  given: Jacob A.
- family: Yang
  given: Sheng
- family: Rubinfien
  given: Julian A.
- family: Pehlevan
  given: Cengiz
eprint: 2301.11375v2
file: 2301.11375v2.pdf
files:
- zavatone-veth-jacob-a.-and-yang-sheng-and-rubinfien-julian-a.-and-pehlevan-cengizneural-networks-learn-to-magnify-areas-near-decision-boundaries20.pdf
month: Jan
primaryclass: cs.LG
ref: 2301.11375v2
time-added: 2023-05-19-10:41:13
title: Neural networks learn to magnify areas near decision boundaries
type: article
url: http://arxiv.org/abs/2301.11375v2
year: '2023'
