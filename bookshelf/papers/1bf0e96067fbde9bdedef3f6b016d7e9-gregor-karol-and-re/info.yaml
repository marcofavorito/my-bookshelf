abstract: In this paper we introduce a new unsupervised reinforcement learning method
  for discovering the set of intrinsic options available to an agent. This set is
  learned by maximizing the number of different states an agent can reliably reach,
  as measured by the mutual information between the set of options and option termination
  states. To this end, we instantiate two policy gradient based algorithms, one that
  creates an explicit embedding space of options and one that represents options implicitly.
  The algorithms also provide an explicit measure of empowerment in a given state
  that can be used by an empowerment maximizing agent. The algorithm scales well with
  function approximation and we demonstrate the applicability of the algorithm on
  a range of tasks.
archiveprefix: arXiv
author: Gregor, Karol and Rezende, Danilo Jimenez and Wierstra, Daan
author_list:
- family: Gregor
  given: Karol
- family: Rezende
  given: Danilo Jimenez
- family: Wierstra
  given: Daan
eprint: 1611.07507v1
file: 1611.07507v1.pdf
files:
- gregor-karol-and-rezende-danilo-jimenez-and-wierstra-daanvariational-intrinsic-control2016.pdf
month: Nov
primaryclass: cs.LG
ref: 1611.07507v1
time-added: 2020-12-20-11:28:20
title: Variational Intrinsic Control
type: article
url: http://arxiv.org/abs/1611.07507v1
year: '2016'
