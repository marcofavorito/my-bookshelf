abstract: 'Reward is the driving force for reinforcement-learning agents. This paper
  is dedicated to understanding the expressivity of reward as a way to capture tasks
  that we would want an agent to perform. We frame this study around three new abstract
  notions of "task" that might be desirable: (1) a set of acceptable behaviors, (2)
  a partial ordering over behaviors, or (3) a partial ordering over trajectories.
  Our main results prove that while reward can express many of these tasks, there
  exist instances of each task type that no Markov reward function can capture. We
  then provide a set of polynomial-time algorithms that construct a Markov reward
  function that allows an agent to optimize tasks of each of these three types, and
  correctly determine when no such reward function exists. We conclude with an empirical
  study that corroborates and illustrates our theoretical findings.'
archiveprefix: arXiv
author: Abel, David and Dabney, Will and Harutyunyan, Anna and Ho, Mark K. and Littman,
  Michael L. and Precup, Doina and Singh, Satinder
author_list:
- family: Abel
  given: David
- family: Dabney
  given: Will
- family: Harutyunyan
  given: Anna
- family: Ho
  given: Mark K.
- family: Littman
  given: Michael L.
- family: Precup
  given: Doina
- family: Singh
  given: Satinder
eprint: 2111.00876v2
file: 2111.00876v2.pdf
files:
- abel-david-and-dabney-will-and-harutyunyan-anna-and-ho-mark-k.-and-littman-michael-l.-and-precup-doina-and-singh-satinderon-the-expressivity-of.pdf
month: Nov
primaryclass: cs.LG
ref: 2111.00876v2
time-added: 2022-05-14-16:09:54
title: On the Expressivity of Markov Reward
type: article
url: http://arxiv.org/abs/2111.00876v2
year: '2021'
