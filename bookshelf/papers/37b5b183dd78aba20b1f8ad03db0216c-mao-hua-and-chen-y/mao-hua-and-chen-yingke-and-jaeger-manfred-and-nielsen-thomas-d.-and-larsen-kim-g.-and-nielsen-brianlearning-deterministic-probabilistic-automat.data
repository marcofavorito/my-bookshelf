

<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10994"/>

    <meta name="dc.title" content="Learning deterministic probabilistic automata from a model checking perspective"/>

    <meta name="dc.source" content="Machine Learning 2016 105:2"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2016-05-18"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2016 The Author(s)"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="Probabilistic automata models play an important role in the formal design and analysis of hard- and software systems. In this area of applications, one is often interested in formal model-checking procedures for verifying critical system properties. Since adequate system models are often difficult to design manually, we are interested in learning models from observed system behaviors. To this end we adopt techniques for learning finite probabilistic automata, notably the Alergia algorithm. In this paper we show how to extend the basic algorithm to also learn automata models for both reactive and timed systems. A key question of our investigation is to what extent one can expect a learned model to be a good approximation for the kind of probabilistic properties one wants to verify by model checking. We establish theoretical convergence properties for the learning algorithm as well as for probability estimates of system properties expressed in linear time temporal logic and linear continuous stochastic logic. We empirically compare the learning algorithm with statistical model checking and demonstrate the feasibility of the approach for practical system verification."/>

    <meta name="prism.issn" content="1573-0565"/>

    <meta name="prism.publicationName" content="Machine Learning"/>

    <meta name="prism.publicationDate" content="2016-05-18"/>

    <meta name="prism.volume" content="105"/>

    <meta name="prism.number" content="2"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="255"/>

    <meta name="prism.endingPage" content="299"/>

    <meta name="prism.copyright" content="2016 The Author(s)"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10994-016-5565-9"/>

    <meta name="prism.doi" content="doi:10.1007/s10994-016-5565-9"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10994-016-5565-9.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10994-016-5565-9"/>

    <meta name="citation_journal_title" content="Machine Learning"/>

    <meta name="citation_journal_abbrev" content="Mach Learn"/>

    <meta name="citation_publisher" content="Springer US"/>

    <meta name="citation_issn" content="1573-0565"/>

    <meta name="citation_title" content="Learning deterministic probabilistic automata from a model checking perspective"/>

    <meta name="citation_volume" content="105"/>

    <meta name="citation_issue" content="2"/>

    <meta name="citation_publication_date" content="2016/11"/>

    <meta name="citation_online_date" content="2016/05/18"/>

    <meta name="citation_firstpage" content="255"/>

    <meta name="citation_lastpage" content="299"/>

    <meta name="citation_article_type" content="Article"/>

    <meta name="citation_fulltext_world_readable" content=""/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10994-016-5565-9"/>

    <meta name="DOI" content="10.1007/s10994-016-5565-9"/>

    <meta name="citation_doi" content="10.1007/s10994-016-5565-9"/>

    <meta name="description" content="Probabilistic automata models play an important role in the formal design and analysis of hard- and software systems. In this area of applications, one is "/>

    <meta name="dc.creator" content="Hua Mao"/>

    <meta name="dc.creator" content="Yingke Chen"/>

    <meta name="dc.creator" content="Manfred Jaeger"/>

    <meta name="dc.creator" content="Thomas D. Nielsen"/>

    <meta name="dc.creator" content="Kim G. Larsen"/>

    <meta name="dc.creator" content="Brian Nielsen"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Control, Robotics, Mechatronics"/>

    <meta name="dc.subject" content="Artificial Intelligence"/>

    <meta name="dc.subject" content="Simulation and Modeling"/>

    <meta name="dc.subject" content="Natural Language Processing (NLP)"/>

    <meta name="citation_reference" content="Aarts, F., &amp; Vaandrager, F. W. (2010). Learning I/O automata. In Proceedings of the international conference on concurrency theory (CONCUR 2010), pp. 71&#8211;85."/>

    <meta name="citation_reference" content="Ammons, G., Bod&#237;k, R., &amp; Larus, J. R. (2002). Mining specifications. In Proceedings of the SIGPLAN-SIGACT symposium on principles of programming language (POPL 2002), pp. 4&#8211;16."/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Information and Computation; citation_title=Learning regular sets from queries and counterexamples; citation_author=D Angluin; citation_volume=75; citation_publication_date=1987; citation_pages=87-106; citation_doi=10.1016/0890-5401(87)90052-6; citation_id=CR3"/>

    <meta name="citation_reference" content="citation_title=Principles of model checking; citation_publication_date=2008; citation_id=CR4; citation_author=C Baier; citation_author=JP Katoen; citation_publisher=The MIT Press"/>

    <meta name="citation_reference" content="citation_journal_title=Journal of IEEE Transaction on Software Engineering; citation_title=Model-checking algorithms for continuous-time Markov chains; citation_author=C Baier, B Haverkort, H Hermanns, JP Katoen; citation_volume=29; citation_issue=6; citation_publication_date=2003; citation_pages=524-541; citation_doi=10.1109/TSE.2003.1205180; citation_id=CR5"/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Software: Practice and Experience; citation_title=Developing uppaal over 15 years; citation_author=G Behrmann, A David, KG Larsen, P Pettersson, W Yi; citation_volume=41; citation_issue=2; citation_publication_date=2011; citation_pages=133-142; citation_id=CR6"/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions on Software Engineering; citation_title=Learning communicating automata from MSCs; citation_author=B Bollig, JP Katoen, C Kern, M Leucker; citation_volume=36; citation_issue=3; citation_publication_date=2010; citation_pages=390-408; citation_doi=10.1109/TSE.2009.89; citation_id=CR7"/>

    <meta name="citation_reference" content="Bouyer, P., Larsen, K. G., &amp; Markey, N. (2008). Model checking one-clock priced timed automata. Journal of Logical Methods in Computer Science, 4(2), 1&#8211;28."/>

    <meta name="citation_reference" content="citation_journal_title=Communications of the ACM; citation_title=Quantitative analysis of real-time systems using priced timed automata; citation_author=P Bouyer, U Fahrenberg, KG Larsen, N Markey; citation_volume=54; citation_issue=9; citation_publication_date=2011; citation_pages=78-87; citation_doi=10.1145/1995376.1995396; citation_id=CR9"/>

    <meta name="citation_reference" content="Carrasco, R., &amp; Oncina, J. (1994). Learning stochastic regular grammars by means of a state merging method. In Proceedings of the international colloquium on grammatical inference and applications (ICGIA 1994), pp. 139&#8211;152."/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Theoretial Informatics and Applications; citation_title=Learning deterministic regular grammars from stochastic samples in polynomial time; citation_author=RC Carrasco, J Oncina; citation_volume=33; citation_issue=1; citation_publication_date=1999; citation_pages=1-20; citation_doi=10.1051/ita:1999102; citation_id=CR11"/>

    <meta name="citation_reference" content="Castro, J., &amp; Gavald&#224;, R. (2008). Towards feasible PAC-learning of probabilistic deterministic finite automata. In Grammatical inference: Algorithms and applications, pp. 163&#8211;174."/>

    <meta name="citation_reference" content="Chen, T., Han, T., Katoen, J. P., &amp; Mereacre, A. (2009). Quantitative model checking of continuous-time Markov chains against timed automata specifications. In 24th annual IEEE symposium on logic in computer science pp. 309&#8211;318."/>

    <meta name="citation_reference" content="Chen, Y., &amp; Nielsen, T. D. (2012). Active learning of Markov decision processes for system verification. In Proceedings of the international conference on machine learning and applications (ICMLA 2012), pp. 289&#8211;294."/>

    <meta name="citation_reference" content="Chen, Y., Mao, H., Jaeger, M., Nielsen, T. D., Larsen, K.G., &amp; Nielsen, B. (2012). Learning Markov models for stationary system behaviors. In NASA formal methods symposium (NFM), pp. 216&#8211;230."/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Machine Learning Research; citation_title=PAC-learnability of probabilistic deterministic finite state automata; citation_author=A Clark, F Thollard; citation_volume=5; citation_publication_date=2004; citation_pages=473-497; citation_id=CR16"/>

    <meta name="citation_reference" content="Cobleigh, J. M., Giannakopoulou, D., &amp; Pasareanu, C. S. (2003). Learning assumptions for compositional verification. In Proceedings of the 9th international conference on tools and algorithms for the construction and analysis of systems (TACAS), pp. 331&#8211;346."/>

    <meta name="citation_reference" content="citation_journal_title=Journal of the ACM; citation_title=The complexity of probabilistic verification; citation_author=C Courcoubetis, M Yannakakis; citation_volume=42; citation_issue=4; citation_publication_date=1995; citation_pages=857-907; citation_doi=10.1145/210332.210339; citation_id=CR18"/>

    <meta name="citation_reference" content="citation_journal_title=Biometrika; citation_title=Some simple approximate tests for Poisson variates; citation_author=DR Cox; citation_volume=40; citation_issue=3/4; citation_publication_date=1953; citation_pages=354-360; citation_doi=10.2307/2333353; citation_id=CR19"/>

    <meta name="citation_reference" content="de&#160;Higuera, C., &amp; Oncina, J. (2004). Learning stochastic finite automata. In Proceedings of the international conference on grammatical inference, pp. 175&#8211;186."/>

    <meta name="citation_reference" content="de&#160;la Higuera, C., &amp; Thollard, F. (2000). Identification in the limit with probability one of stochastic deterministic finite automata. In Proceedings of the international colloquium on grammatical inference: Algorithms and application (ICGI 2000), pp. 141&#8211;156."/>

    <meta name="citation_reference" content="Desharnais, J., Gupta, V., Jagadeesan, R., &amp; Panangaden, P. (1999). Metrics for labeled Markov systems. In Proceedings of international conference on concurrency theory (CONCUR), pp. 258&#8211;273."/>

    <meta name="citation_reference" content="Feng, L., Han, T., Kwiatkowska, M. Z., &amp; Parker, D. (2011). Learning-based compositional verification for synchronous probabilistic systems. In 9th international symposium on automated technology for verification and analysis (ATVA), pp. 511&#8211;521."/>

    <meta name="citation_reference" content="citation_journal_title=Biometrika; citation_title=The performance of some two-sample tests in small samples with and without censoring; citation_author=EA Gehan, DG Thomas; citation_volume=56; citation_issue=1; citation_publication_date=1969; citation_pages=127-132; citation_doi=10.1093/biomet/56.1.127; citation_id=CR24"/>

    <meta name="citation_reference" content="Giannakopoulou, D., &amp; P&#259;s&#259;reanu, C. S. (2005). Learning-based assume-guarantee verification (Tool Paper). In P. Godefroid (Ed.), Model Checking Software: 12th International SPIN Workshop (pp. 282&#8211;287). Berlin, Heidelberg: Springer."/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Electronic Notes in Theoretical Compututer Science; citation_title=Inference of timed transition systems; citation_author=O Grinchtein, B Jonsson, M Leucker; citation_volume=138; citation_issue=3; citation_publication_date=2005; citation_pages=87-99; citation_doi=10.1016/j.entcs.2005.02.062; citation_id=CR26"/>

    <meta name="citation_reference" content="Grinchtein, O., Jonsson, B., &amp; Pettersson, P. (2006). Inference of event-recording automata using timed decision trees. In Proceedings of the international conference on concurrency theory (CONCUR), pp. 435&#8211;449."/>

    <meta name="citation_reference" content="Haverkort, B. R., Hermanns, H., &amp; Katoen, J. P. (2000). On the use of model checking techniques for dependability evaluation. In Proceedings of the IEEE symposium on reliable distributed systems (SRDS 2000), pp. 228&#8211;237."/>

    <meta name="citation_reference" content="H&#233;rault, T., Lassaigne, R., Magniette, F., &amp; Peyronnet, S. (2004). Approximate probabilistic model checking. In Steffen, B., Levi, G. (Eds.), Verification, model checking, and abstract interpretation. Lecture Notes in Computer Science, Vol. 2937, Springer, Berlin, pp. 307&#8211;329."/>

    <meta name="citation_reference" content="citation_title=Grammatical inference: Learning automata and grammars; citation_publication_date=2010; citation_id=CR30; citation_author=Cd Higuera; citation_publisher=Cambridge University Press"/>

    <meta name="citation_reference" content="Jaeger, M., Mao, H., Larsen, K. G., &amp; Mardare, R. (2014). Continuity properties of distances for Markov processes. In Proceedings of QEST 2014, LNCS, Vol. 8657, pp. 297&#8211;312."/>

    <meta name="citation_reference" content="Jansen, D. N. (2002). Probabilistic UML statecharts for specification and verification a case study. In Proceedings of the workshop on critical systems development with UML, pp. 121&#8211;132."/>

    <meta name="citation_reference" content="Komuravelli, A., Pasareanu, C. S., &amp; Clarke, E. M. (2012). Learning probabilistic systems from tree samples. In Proceedings of the 27th annual IEEE/ACM symposium on logic in computer science, pp. 441&#8211;450."/>

    <meta name="citation_reference" content="Kwiatkowska, M.Z., Norman, G., &amp; Parker, D. (2011). Prism 4.0: Verification of probabilistic real-time systems. In Proceedings of the international conference on computer aided verification (CAV&#8217;11), pp. 585&#8211;591."/>

    <meta name="citation_reference" content="Laroussinie, F., Larsen, K. G., &amp; Weise, C. (1995). From timed automata to logic- and back. In Proceedings of international symposim on mathematical foundations of computer science (MFCS 1995), pp. 529&#8211;539."/>

    <meta name="citation_reference" content="Legay, A., Delahaye, B., &amp; Bensalem, S. (2010). Statistical model checking: An overview. In Proceedings of the first international conference on runtime verification, Springer, Berlin, RV&#8217;10, pp. 122&#8211;135."/>

    <meta name="citation_reference" content="Leucker, M. (2007). Learning meets verification. In Proceedings of the international conference on formal methods for components and objects (FMCO 2007), pp. 127&#8211;151."/>

    <meta name="citation_reference" content="Mao, H., &amp; Jaeger, M. (2012). Learning and model checking networks of I/O automata. In Proceedings of the fourth Asian conference on machine learning (ACML), pp. 285&#8211;300."/>

    <meta name="citation_reference" content="Mao, H., Chen, Y., Jaeger, M., Nielsen, T. D., Larsen, K. G., &amp; Nielsen, B. (2011). Learning probabilistic automata for model checking. In Proceedings of the international conference on quantitative evaluation of system (QEST 2011), pp. 111&#8211;120."/>

    <meta name="citation_reference" content="Mao, H., Chen, Y., Jaeger, M., Nielsen, T. D., Larsen, K. G., &amp; Nielsen, B. (2012). Learning Markov decision processes for model checking. In Proceedings of the first workshop on quantities in formal methods (QFM), pp. 49&#8211;63."/>

    <meta name="citation_reference" content="Niese, O. (2003). An integrated approach to testing complex systems. PhD thesis, Universit&#228;t Dortmund."/>

    <meta name="citation_reference" content="citation_journal_title=IEEE Transactions on Pattern Analysis Machine Intelligence; citation_title=Learning subsequential transducers for pattern recognition interpretation tasks; citation_author=J Oncina, P Garcia, E Vidal; citation_volume=15; citation_issue=5; citation_publication_date=1993; citation_pages=448-458; citation_doi=10.1109/34.211465; citation_id=CR42"/>

    <meta name="citation_reference" content="Pnueli, A. (1977). The temporal logic of programs. In Proceedings of the annual symposium on foundations of computer science (FOCS) pp. 46&#8211;57."/>

    <meta name="citation_reference" content="Rabin, M. O. (1963). Probabilistic automata. Information and Control, 6(3), 230&#8211;245. doi:
                    10.1016/S0019-9958(63)90290-0
                    
                  . 
                    http://www.sciencedirect.com/science/article/pii/S0019995863902900
                    
                  
                        "/>

    <meta name="citation_reference" content="Raffelt, H., &amp; Steffen, B. (2006). Learnlib: A library for automata learning and experimentation. In Proceedings of the international conference on fundamental approaches to software engineering (FASE), pp. 377&#8211;380."/>

    <meta name="citation_reference" content="citation_journal_title=Machine Learning; citation_title=The power of amnesia: Learning probabilistic automata with variable memory length; citation_author=D Ron, Y Singer, N Tishby; citation_volume=25; citation_issue=2&#8211;3; citation_publication_date=1996; citation_pages=117-149; citation_doi=10.1023/A:1026490906255; citation_id=CR46"/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Computer and System Sciences; citation_title=On the learnability and usage of acyclic probabilistic finite automata; citation_author=D Ron, Y Singer, N Tishby; citation_volume=56; citation_issue=2; citation_publication_date=1998; citation_pages=133-152; citation_doi=10.1006/jcss.1997.1555; citation_id=CR47"/>

    <meta name="citation_reference" content="Segala, R. (1996). Modeling and verification of randomized distributed real-time systems. Technical report. Cambridge, MA."/>

    <meta name="citation_reference" content="Sen, K., Viswanathan, M., &amp; Agha, G. (2004a). Learning continuous time Markov chains from sample executions. In Proceedings of international conference on quantitative evaluation of systems (QEST), pp. 146&#8211;155."/>

    <meta name="citation_reference" content="Sen, K., Viswanathan, M., &amp; Agha, G. (2004b). Statistical model checking of black-box probabilistic systems. In Alur, R., Peled, D. (Eds.), Computer aided verification. Lecture Notes in Computer Science, Vol. 3114, pp. 202&#8211;215."/>

    <meta name="citation_reference" content="Singh, R., Giannakopoulou, D., &amp; Pasareanu, C. S. (2010). Learningcomponent interfaces with may and must abstractions. In Computer aided verification. Lecture Notes in Computer Science, Vol. 3576, pp. 527&#8211;542."/>

    <meta name="citation_reference" content="Thollard, F., Dupont, P., &amp; de&#160;la Higuera, C. (2000). Probabilistic DFA inference using kullback-leibler divergence and minimality. In Proceedings of the international conference on machine learning (ICML), pp. 975&#8211;982."/>

    <meta name="citation_reference" content="citation_journal_title=Machine Learning; citation_title=Learning probabilistic automata and markov chains via queries; citation_author=WG Tzeng; citation_volume=8; citation_publication_date=1992; citation_pages=151-166; citation_id=CR53"/>

    <meta name="citation_reference" content="citation_journal_title=Theoretical Computer Science; citation_title=A behavioural pseudometric for probabilistic transition system; citation_author=F Breugel, J Worrell; citation_volume=331; citation_publication_date=2005; citation_pages=115-142; citation_doi=10.1016/j.tcs.2004.09.035; citation_id=CR54"/>

    <meta name="citation_reference" content="Vardi, M. Y. (1985). Automatic verification of probabilistic concurrent finite-state programs. In Proceedings of the IEEE symposium on foundations of computer science (FOCS), pp. 327&#8211;338."/>

    <meta name="citation_reference" content="Vardi, M. Y. (1999). Probabilistic linear-time model checking: An overview of the automata-theoretic approach. In Proceedings of the international AMAST workshop on formal methods for real-time and probabilstic systems (ARTS 1999), pp. 265&#8211;276."/>

    <meta name="citation_reference" content="Verwer, S. (2010). Efficient identification of timed automata&#8212;Theory and practice. PhD thesis, Technical University Delft."/>

    <meta name="citation_author" content="Hua Mao"/>

    <meta name="citation_author_institution" content="College of Computer Science, Sichuan University, Chengdu, China"/>

    <meta name="citation_author" content="Yingke Chen"/>

    <meta name="citation_author_institution" content="College of Computer Science, Sichuan University, Chengdu, China"/>

    <meta name="citation_author" content="Manfred Jaeger"/>

    <meta name="citation_author_email" content="jaeger@cs.aau.dk"/>

    <meta name="citation_author_institution" content="Department of Computer Science, Aalborg University, Aalborg East, Denmark"/>

    <meta name="citation_author" content="Thomas D. Nielsen"/>

    <meta name="citation_author_institution" content="Department of Computer Science, Aalborg University, Aalborg East, Denmark"/>

    <meta name="citation_author" content="Kim G. Larsen"/>

    <meta name="citation_author_institution" content="Department of Computer Science, Aalborg University, Aalborg East, Denmark"/>

    <meta name="citation_author" content="Brian Nielsen"/>

    <meta name="citation_author_institution" content="Department of Computer Science, Aalborg University, Aalborg East, Denmark"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10994-016-5565-9&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2016/11/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10994-016-5565-9"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Machine Learning"/>
        <meta property="og:title" content="Learning deterministic probabilistic automata from a model checking perspective"/>
        <meta property="og:description" content="Probabilistic automata models play an important role in the formal design and analysis of hard- and software systems. In this area of applications, one is often interested in formal model-checking procedures for verifying critical system properties. Since adequate system models are often difficult to design manually, we are interested in learning models from observed system behaviors. To this end we adopt techniques for learning finite probabilistic automata, notably the Alergia algorithm. In this paper we show how to extend the basic algorithm to also learn automata models for both reactive and timed systems. A key question of our investigation is to what extent one can expect a learned model to be a good approximation for the kind of probabilistic properties one wants to verify by model checking. We establish theoretical convergence properties for the learning algorithm as well as for probability estimates of system properties expressed in linear time temporal logic and linear continuous stochastic logic. We empirically compare the learning algorithm with statistical model checking and demonstrate the feasibility of the approach for practical system verification."/>
        <meta property="og:image" content="https://media.springernature.com/w200/springer-static/cover/journal/10994.jpg"/>
    

    <title>Learning deterministic probabilistic automata from a model checking perspective | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>
    
    <style>button{line-height:inherit}html,label{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}html{height:100%;overflow-y:scroll;box-sizing:border-box;color:#333;line-height:1.61803;-webkit-font-smoothing:subpixel-antialiased;font-size:62.5%}*{box-sizing:inherit}body{max-width:100%;min-height:100%;background-color:#fcfcfc;background-position:initial initial;background-repeat:initial initial;margin:0}button,div,form,input{margin:0;padding:0}body,p{padding:0}a{color:#004b83;text-decoration:underline}h1,h2{margin-top:0}h1{font-size:3.2rem}h2{font-size:2.8rem}h1,h2{font-style:normal;margin-bottom:1em;line-height:1.4;font-family:Georgia,Palatino,serif;font-weight:400}p{margin:0}ul{margin-top:0}p{margin-bottom:1.5em}.c-ad{display:none;padding:8px;text-align:center}@media only screen and (min-width:768px){.js .c-ad{display:block}}.c-ad--728x90{background-color:#ccc}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}.c-ad--300x250{background-color:#f2f2f2}.c-ad--300x250 .c-ad__inner{min-height:calc(1.5em + 254px)}.c-ad__label,.c-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-ad__label{font-size:1.4rem;font-weight:400;margin-bottom:4px;color:#333;line-height:1.5}.c-header{font-size:1.6rem}.c-header{background-color:#fff;padding:16px 0;border-bottom:4px solid #00285a}.c-header__container{margin:0 auto;max-width:1280px;padding:0 16px;display:-webkit-flex;-webkit-box-align:center;-webkit-align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between}.c-header__brand{margin-right:32px}.c-header__brand a{text-decoration:none}.c-header__menu,.c-header__navigation{display:-webkit-flex}.c-header__navigation{-webkit-box-align:center;-webkit-align-items:center}.c-header__menu{list-style:none;margin:0;padding:0}.c-header__item{color:inherit;margin-right:24px}.c-header__item:last-child{margin-right:0}.c-header__link{text-decoration:none;color:inherit}.js .c-popup{position:absolute;font-family:Georgia,Palatino,serif;z-index:100;padding:16px;border:1px solid rgba(151,191,216,.298039);-webkit-box-shadow:hsla(0,0%,50.2%,.0980392) 0 0 5px 0;box-shadow:0 0 5px 0 hsla(0,0%,50.2%,.0980392);width:auto;border-top-left-radius:2px;border-top-right-radius:2px;border-bottom-right-radius:2px;border-bottom-left-radius:2px;background-color:#fff}.js .c-popup__close{position:absolute;display:block;top:16px;right:16px;height:16px;background-image:url("data:image/svg+xml,%0A%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z' fill='%23666' fill-rule='evenodd'/%3E%3C/svg%3E");border:0;padding-right:16px;background-position:initial initial;background-repeat:no-repeat}.js .c-popup__close-text{border:0;clip:rect(0 0 0 0);height:1px;margin:-100%;overflow:hidden;padding:0;width:1px;position:absolute!important}.js .c-popup__arrow{content:"";position:absolute;width:20px;height:20px;background-color:#fff;border-top:1px solid rgba(151,191,216,.298039);border-left:1px solid rgba(151,191,216,.298039)}body{font-size:1.8em}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{list-style:none;font-size:1.6rem;line-height:1.3;display:-webkit-flex;-webkit-flex-wrap:wrap;color:#6f6f6f;padding:0;margin:0 0 8px}.c-article-identifiers__item{border-right:1px solid #6f6f6f;margin-right:8px;padding-right:8px;list-style:none}.c-article-identifiers__item a{color:#069;text-decoration:none}.c-article-identifiers__item:last-child{margin-right:0;padding-right:0;border-right-width:0}@media only screen and (min-width:768px){.c-author-popup .c-article-identifiers{-webkit-box-pack:end;-webkit-justify-content:flex-end}}.c-article-title{font-size:2.4rem;line-height:1.25;margin-bottom:16px}@media only screen and (min-width:768px){.c-article-title{font-size:3rem;line-height:1.2}}.c-author-list{font-size:1.6rem;list-style:none;margin-bottom:0;padding:0;width:100%}.c-author-list__item{margin-left:0}.c-author-list__item,.c-author-list li{display:inline;padding-right:0}.c-author-list__item svg{margin-left:4px}.c-article-info-details{font-size:1.6rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:-webkit-flex;-webkit-flex-wrap:wrap;line-height:1.3;font-size:1.6rem}.c-article-metrics-bar__wrapper{margin:0 0 16px}.c-article-metrics-bar__item{-webkit-box-align:baseline;-webkit-align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right-width:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-weight:400;font-style:normal;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-author-popup__subheading{font-weight:700;float:left;padding-right:8px;margin-bottom:8px;margin-top:4px}.c-author-popup .c-article-button{font-size:1.6rem;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-author-popup__author-list{list-style:none;font-size:1.6rem;padding:0;margin-top:0;clear:both;margin-bottom:16px}.c-author-popup__author-list>li{margin-bottom:8px}.c-author-popup__link{font-weight:700;vertical-align:baseline;color:#069;text-decoration:none}.c-author-popup .c-article-button{color:#fff;background-image:linear-gradient(#4d78af,#3365a0);border:1px solid transparent;border-top-left-radius:2px;border-top-right-radius:2px;border-bottom-right-radius:2px;border-bottom-left-radius:2px;text-decoration:none;display:block;width:100%;padding-top:8px;padding-bottom:8px;text-align:center;background-position:initial initial;background-repeat:initial initial}.c-article-section{clear:both}.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:2rem;line-height:1.3;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-section__title{font-size:2.4rem;line-height:1.24}}.c-article-section__content{margin-bottom:40px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-top:0;margin-bottom:24px}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-weight:700;margin:0;padding:0;font-size:1.7rem}.c-article-authors-search__item{font-size:1.6rem}.c-article-authors-search__text{margin:0}@media only screen and (min-width:768px){.c-author-popup .c-article-authors-search__list{display:-webkit-flex;-webkit-flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-webkit-box-align:center;-webkit-align-items:center}.c-author-popup .c-article-authors-search__list-item--left{-webkit-flex-basis:40%}}.c-author-popup .c-article-authors-search__list-item--right{margin-top:16px}@media only screen and (min-width:768px){.c-author-popup .c-article-authors-search__list-item--right{text-align:right;-webkit-box-flex:1;-webkit-flex:1 1 0px;margin-top:0}}.c-article-share-box__no-sharelink-info{font-size:1.3rem;font-weight:700;padding-top:4px;margin-bottom:24px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;display:inline-block;margin-bottom:8px;font-size:1.4rem;font-weight:700;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:1.4rem;margin-bottom:8px;margin-left:10px}.c-article-body{clear:both}.c-article-body p{word-wrap:break-word}.c-pdf-download{display:-webkit-flex;margin-bottom:24px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}@media only screen and (min-width:1024px){.c-pdf-button__container{display:none}}.c-context-bar{position:relative;width:100%;-webkit-box-shadow:rgba(51,51,51,.2) 0 0 10px 0;box-shadow:0 0 10px 0 rgba(51,51,51,.2)}.c-context-bar__title{display:none}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-pdf-download__link{display:-webkit-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;-webkit-box-pack:justify;-webkit-justify-content:space-between;color:#fff;background-image:linear-gradient(#4d78af,#3365a0);border:1px solid transparent;border-top-left-radius:2px;border-top-right-radius:2px;border-bottom-right-radius:2px;border-bottom-left-radius:2px;text-decoration:none;font-size:1.6rem;line-height:1.3;-webkit-box-flex:1;-webkit-flex:1 1 0px;padding:13px 24px;background-position:initial initial;background-repeat:initial initial}.c-reading-companion{clear:both}.c-reading-companion__sticky{max-width:582px}.c-reading-companion__scroll-pane{overflow-x:hidden;overflow-y:auto;margin:0 0 16px}.c-reading-companion__tabs{font-size:1.6rem;list-style:none;display:-webkit-flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-webkit-flex-flow:row nowrap;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{-webkit-box-flex:1;-webkit-flex-grow:1}.c-reading-companion__tab{color:#069;border:1px solid #d5d5d5;border-left-width:0;background-color:#eee;padding:8px 8px 8px 15px;text-align:left;font-size:1.6rem;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{color:#222;background-color:#fcfcfc;border-bottom:1px solid #fcfcfc;font-weight:700}.c-reading-companion__references-list,.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1.6rem;padding:0}.c-reading-companion__section-item a{display:block;padding:8px 0 8px 16px;line-height:1em;overflow:hidden;white-space:nowrap;text-overflow:ellipsis}.c-reading-companion__reference-item{padding:8px 8px 8px 0;border-top:1px solid #d5d5d5;font-size:1.6rem}.c-reading-companion__reference-item:first-child{border-top-style:none}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{list-style:none;text-align:right;margin:8px 0 0;padding:0;font-weight:700;font-size:1.3rem}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__panel{display:none;border-top:1px solid #d5d5d5;margin-top:-9px;padding-top:9px}.c-reading-companion__panel--active{display:block}.c-popup-search{position:relative;z-index:10;background-color:#eee;padding:16px 0;-webkit-box-shadow:rgba(0,0,0,.207843) 0 3px 3px -3px;box-shadow:0 3px 3px -3px rgba(0,0,0,.207843)}@media only screen and (min-width:1024px){.js .c-popup-search{position:absolute;width:100%;top:100%}.c-popup-search__container{margin:auto;max-width:70%}}.app-search__content{display:-webkit-flex}.app-search__label{font-size:1.4rem;display:inline-block;color:#666;margin-bottom:8px}.app-search__input{font-size:1.4rem;border:1px solid #b3b3b3;border-top-left-radius:3px;border-bottom-left-radius:3px;vertical-align:middle;line-height:1.2;-webkit-box-shadow:rgba(0,0,0,.207843) 0 1px 3px 0 inset;box-shadow:inset 0 1px 3px 0 rgba(0,0,0,.207843);padding:.75em 1em;width:100%;-webkit-box-flex:0;-webkit-flex:0 1 auto}.app-search__button{-webkit-box-align:center;-webkit-align-items:center;cursor:pointer;display:-webkit-inline-flex;margin:0;position:relative;text-decoration:none;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:16px;line-height:1.3;-webkit-box-pack:center;-webkit-justify-content:center;padding:8px;transition:.25s ease,color .25s ease,border-color .25s ease;-webkit-transition:.25s ease,color .25s ease,border-color .25s ease;color:#fff;background-color:#33629d;background-image:linear-gradient(#4d76a9,#33629d);border:1px solid rgba(0,59,132,.498039);width:50px;text-align:center;border-top-left-radius:0;border-bottom-left-radius:0}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-display-block{display:block}.u-display-flex{display:-webkit-flex;width:100%}.u-align-items-center{-webkit-box-align:center;-webkit-align-items:center}.u-flex-static{-webkit-box-flex:0;-webkit-flex:0 1 auto;-webkit-flex:0 0 auto}.u-display-none{display:none}.js .u-js-hide{display:none;visibility:hidden}@media print{.u-hide-print{display:none}}.u-icon{fill:currentColor;-webkit-transform:translate(0);display:inline-block;vertical-align:text-top}.u-list-reset{list-style:none;margin:0;padding:0}.u-button-reset{background-color:transparent;border:0;padding:0}.u-h3{font-size:1.8rem}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-position-relative{position:relative}.u-mt-32{margin-top:32px}.u-mr-24{margin-right:24px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.u-ml-8{margin-left:8px}.u-hide{display:none;visibility:hidden}.u-visually-hidden{border:0;clip:rect(0 0 0 0);height:1px;margin:-100%;overflow:hidden;padding:0;width:1px;position:absolute!important}.hide,.js .js-hide{display:none;visibility:hidden}.c-article-section__content p{line-height:1.8}.c-reading-companion__section-item a{text-decoration:none}.c-reading-companion__sections-list{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-main-column .c-pdf-button__container .c-pdf-download{display:none}@media only screen and (max-width:1023px){.c-article-main-column .c-pdf-button__container .c-pdf-download{display:block}}</style>



    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-02165187ac.css media="screen">
    <link rel="stylesheet" data-inline-css-source="critical-css" id="js-mustard" href="/oscar-static/app-springerlink/css/enhanced-article-8ad3ef172c.css" media="print" onload="this.media='only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)';this.onload=null">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"IT","doi":"10.1007-s10994-016-5565-9","Journal Title":"Machine Learning","Journal Id":10994,"Keywords":"Probabilistic model checking, Probabilistic automata learning, Linear time temporal logic","kwrd":["Probabilistic_model_checking","Probabilistic_automata_learning","Linear_time_temporal_logic"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":[],"Open Access":"N","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":[],"businessPartnerIDString":""}},"Access Type":"permanently-free","Bpids":"","Bpnames":"","BPID":["1"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s10994-016-5565-9","Full HTML":"Y","Subject Codes":["SCI","SCI21000","SCT19000","SCI19000","SCI21040"],"pmc":["I","I21000","T19000","I19000","I21040"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1573-0565","pissn":"0885-6125"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Artificial Intelligence","2":"Control, Robotics, Mechatronics","3":"Artificial Intelligence","4":"Simulation and Modeling","5":"Natural Language Processing (NLP)"},"secondarySubjectCodes":{"1":"I21000","2":"T19000","3":"I21000","4":"I19000","5":"I21040"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10994-016-5565-9","Page":"article","page":{"attributes":{"environment":"live"}}}];
    </script>


    
    
        
            <script src=/oscar-static/js/jquery-220afd743d.js></script>
        
    

    <script data-test="onetrust-control">
        
            (function(w,d,t) {
                var assetPath = '/oscar-static/js/cookie-consent-es5-bundle-0ea0aa3601.js';
                function cc() {
                    var h = w.location.hostname,
                        e = d.createElement(t),
                        s = d.getElementsByTagName(t)[0];

                    if (h === "link.springer.com") {
                        e.src = "https://cdn.cookielaw.org/scripttemplates/otSDKStub.js";
                        e.setAttribute("data-domain-script", "4f53bc14-4ee3-45bd-9935-e3d2b6b2a543");
                    } else {
                        e.src = assetPath;
                        e.setAttribute("data-consent", h);
                    }
                    s.parentNode.insertBefore(e, s);
                }
                w.google_tag_manager ? cc() : window.addEventListener("gtm_loaded", cc);
            })(window,document,"script");
        
    </script>
    <script>
        function OptanonWrapper() {
            var elementInside = function(candidate, element) {
                if (candidate === element) {
                    return true;
                } else if (candidate.nodeName.toLowerCase() === 'body') {
                    return false;
                } else {
                    return elementInside(candidate.parentNode, element);
                }
            };

            var disclaimer = document.querySelector('.c-disclaimer[aria-hidden="false"]');
            window.dataLayer.push({event:'OneTrustGroupsUpdated'});
            if (disclaimer) {
                if (!elementInside(document.activeElement, disclaimer)) {
                    disclaimer.querySelector('button').focus();
                }
            } else {
                document.activeElement.blur();
            }
        }
    </script>

    <script>
    window.config = window.config || {};
    window.config.mustardcut = false;

    
    if (window.matchMedia && window.matchMedia('only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)').matches) {
        window.config.mustardcut = true;
    }
</script>

    <!--Polyfills CustomEvent constructor in IE. Allows us to use events to manage race conditions in client side js-->
<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>

    
    
        
            <!-- Google Tag Manager -->
            <script data-test="gtm-head">
                if (window.config.mustardcut) {
                    (function (w, d, s, l, i) {
                        w[l] = w[l] || [];
                        w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                        var f = d.getElementsByTagName(s)[0],
                                j = d.createElement(s),
                                dl = l != 'dataLayer' ? '&l=' + l : '';
                        j.async = true;
                        j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                        
                        j.addEventListener('load', function() {
                            var _ge = new CustomEvent('gtm_loaded', { bubbles: true });
                            d.dispatchEvent(_ge);
                        });
                        f.parentNode.insertBefore(j, f);
                    })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
                }
            </script>
            <!-- End Google Tag Manager -->
        
    


    <script class="js-entry">
    if (window.config.mustardcut) {
        (function(w, d) {
            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                {'src': '/oscar-static/js/polyfill-es5-bundle-974eb189f7.js', 'async': false},
                {'src': '/oscar-static/js/airbrake-es5-bundle-53157587fc.js', 'async': false},
            ];

            var bodyScripts = [
                {'src': '/oscar-static/js/app-es5-bundle-05e3d0b21b.js', 'async': false, 'module': false},
                {'src': '/oscar-static/js/app-es6-bundle-8d5be091e0.js', 'async': false, 'module': true}
                
                
                    , {'src': '/oscar-static/js/global-article-es5-bundle-d29f1c3c45.js', 'async': false, 'module': false},
                    {'src': '/oscar-static/js/global-article-es6-bundle-ae63fd8909.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i = 0; i < headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i = 0; i < bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        })(window, document);
    }
</script>

    
    
    <link rel="canonical" href="https://link.springer.com/article/10.1007/s10994-016-5565-9"/>
    

</head>
<body class="shared-article-renderer">
    
    
    
        
            <!-- Google Tag Manager (noscript) -->
            <noscript data-test="gtm-body">
                <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
                height="0" width="0" style="display:none;visibility:hidden"></iframe>
            </noscript>
            <!-- End Google Tag Manager (noscript) -->
        
    


    <div class="u-vh-full">
        
    <div class="u-hide u-show-following-ad"></div>
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
                <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10994/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=5565;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="u-icon u-flex-static u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a
                        data-test="login-link"
                        class="c-header__link"
                        href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10994-016-5565-9"
                        data-track="click"
                        data-track-category="header"
                        data-track-action="login header"
                        data-track-label="link">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="u-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Learning deterministic probabilistic automata from a model checking perspective
                        </div>
                        
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10994-016-5565-9.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button" data-track-external  download>
            
                <span>Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>

                    </div>
                </div>
            

            <div class="c-pdf-button__container">
                
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10994-016-5565-9.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button" data-track-external  download>
            
                <span>Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>

            </div>

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2016-05-18" itemprop="datePublished">18 May 2016</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">Learning deterministic probabilistic automata from a model checking perspective</h1>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Hua-Mao" data-author-popup="auth-Hua-Mao">Hua Mao</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Sichuan University" /><meta itemprop="address" content="grid.13291.38, 0000000108071581, College of Computer Science, Sichuan University, Chengdu, 610065, China" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Yingke-Chen" data-author-popup="auth-Yingke-Chen">Yingke Chen</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Sichuan University" /><meta itemprop="address" content="grid.13291.38, 0000000108071581, College of Computer Science, Sichuan University, Chengdu, 610065, China" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Manfred-Jaeger" data-author-popup="auth-Manfred-Jaeger" data-corresp-id="c1">Manfred Jaeger<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Aalborg University" /><meta itemprop="address" content="grid.5117.2, 000000010742471X, Department of Computer Science, Aalborg University, 9220, Aalborg East, Denmark" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Thomas_D_-Nielsen" data-author-popup="auth-Thomas_D_-Nielsen">Thomas D. Nielsen</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Aalborg University" /><meta itemprop="address" content="grid.5117.2, 000000010742471X, Department of Computer Science, Aalborg University, 9220, Aalborg East, Denmark" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Kim_G_-Larsen" data-author-popup="auth-Kim_G_-Larsen">Kim G. Larsen</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Aalborg University" /><meta itemprop="address" content="grid.5117.2, 000000010742471X, Department of Computer Science, Aalborg University, 9220, Aalborg East, Denmark" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Brian-Nielsen" data-author-popup="auth-Brian-Nielsen">Brian Nielsen</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Aalborg University" /><meta itemprop="address" content="grid.5117.2, 000000010742471X, Department of Computer Science, Aalborg University, 9220, Aalborg East, Denmark" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10994"><i data-test="journal-title">Machine Learning</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 105</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">255</span>–<span itemprop="pageEnd">299</span>(<span data-test="article-publication-year">2016</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    <div class="c-article-metrics-bar__wrapper u-clear-both">
        <ul class="c-article-metrics-bar u-list-reset">
            
                <li class=" c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__count">2762 <span class="c-article-metrics-bar__label">Accesses</span></p>
                </li>
            
            
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__count">17 <span class="c-article-metrics-bar__label">Citations</span></p>
                </li>
            
            
            <li class="c-article-metrics-bar__item">
                <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10994-016-5565-9/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
            </li>
        </ul>
    </div>
</div>

                        </div>
                            
    

    

                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Probabilistic automata models play an important role in the formal design and analysis of hard- and software systems. In this area of applications, one is often interested in formal model-checking procedures for verifying critical system properties. Since adequate system models are often difficult to design manually, we are interested in learning models from observed system behaviors. To this end we adopt techniques for learning finite probabilistic automata, notably the <span class="u-small-caps">Alergia</span> algorithm. In this paper we show how to extend the basic algorithm to also learn automata models for both reactive and timed systems. A key question of our investigation is to what extent one can expect a learned model to be a good approximation for the kind of probabilistic properties one wants to verify by model checking. We establish theoretical convergence properties for the learning algorithm as well as for probability estimates of system properties expressed in linear time temporal logic and linear continuous stochastic logic. We empirically compare the learning algorithm with statistical model checking and demonstrate the feasibility of the approach for practical system verification.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1" data-title="Introduction"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>
                        <i>Grammatical inference</i> (GI) (Higuera <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Higuera, Cd. (2010). Grammatical inference: Learning automata and grammars. Cambridge: Cambridge University Press." href="/article/10.1007/s10994-016-5565-9#ref-CR30" id="ref-link-section-d52740e371">2010</a>), also known as grammar induction or grammar learning, is concerned with learning language specifications in the form of grammars or automata from data consisting of strings over some alphabet. Starting with Angluin’s seminal work (Angluin <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Angluin, D. (1987). Learning regular sets from queries and counterexamples. Journal of Information and Computation, 75, 87–106." href="/article/10.1007/s10994-016-5565-9#ref-CR3" id="ref-link-section-d52740e374">1987</a>), methods have been developed for learning deterministic, non-deterministic and probabilistic grammars and automata. The learning techniques in GI have been applied in many areas, such as speech recognition, software development, pattern recognition, and computational biology. In this paper we adapt the learning techniques in the GI area to learn models for model checking.</p><p>
                        <i>Model Checking</i> is a verification technique for determining whether a system model complies with a specification provided in a formal language (Baier and Katoen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Baier, C., &amp; Katoen, J. P. (2008). Principles of model checking. Cambridge, MA: The MIT Press." href="/article/10.1007/s10994-016-5565-9#ref-CR4" id="ref-link-section-d52740e383">2008</a>). In the simplest case, system models are given by finite non-deterministic or probabilistic automata, but model-checking techniques have also been developed for more sophisticated system models, e.g., timed automata (Laroussinie et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Laroussinie, F., Larsen, K. G., &amp; Weise, C. (1995). From timed automata to logic- and back. In Proceedings of international symposim on mathematical foundations of computer science (MFCS 1995), pp. 529–539." href="/article/10.1007/s10994-016-5565-9#ref-CR35" id="ref-link-section-d52740e386">1995</a>; Bouyer et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Bouyer, P., Fahrenberg, U., Larsen, K. G., &amp; Markey, N. (2011). Quantitative analysis of real-time systems using priced timed automata. Communications of the ACM, 54(9), 78–87." href="/article/10.1007/s10994-016-5565-9#ref-CR9" id="ref-link-section-d52740e389">2011</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Bouyer, P., Larsen, K. G., &amp; Markey, N. (2008). Model checking one-clock priced timed automata. Journal of Logical Methods in Computer Science, 4(2), 1–28." href="/article/10.1007/s10994-016-5565-9#ref-CR8" id="ref-link-section-d52740e392">2008</a>). Powerful software tools that are available for model checking include UPPAAL (Behrmann et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Behrmann, G., David, A., Larsen, K. G., Pettersson, P., &amp; Yi, W. (2011). Developing uppaal over 15 years. Journal of Software: Practice and Experience, 41(2), 133–142." href="/article/10.1007/s10994-016-5565-9#ref-CR6" id="ref-link-section-d52740e396">2011</a>) and PRISM (Kwiatkowska et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Kwiatkowska, M.Z., Norman, G., &amp; Parker, D. (2011). Prism 4.0: Verification of probabilistic real-time systems. In Proceedings of the international conference on computer aided verification (CAV’11), pp. 585–591." href="/article/10.1007/s10994-016-5565-9#ref-CR34" id="ref-link-section-d52740e399">2011</a>).</p><p>Traditionally, models used in model-checking are manually constructed, either in the development phase as system designs, or for existing hard- or software systems from known specifications and documentation. This procedure can be both time-consuming and error-prone, especially for systems lacking updated and detailed documentation, such as legacy software, 3rd party components, and black-box systems. These difficulties are generally considered a hindrance for adopting otherwise powerful model checking techniques, and have led to an increased interest in methods for data-driven <i>model learning</i> (or <i>specification mining</i>) for formal verification (Ammons et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Ammons, G., Bodík, R., &amp; Larus, J. R. (2002). Mining specifications. In Proceedings of the SIGPLAN-SIGACT symposium on principles of programming language (POPL 2002), pp. 4–16." href="/article/10.1007/s10994-016-5565-9#ref-CR2" id="ref-link-section-d52740e411">2002</a>; Sen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004a" title="Sen, K., Viswanathan, M., &amp; Agha, G. (2004a). Learning continuous time Markov chains from sample executions. In Proceedings of international conference on quantitative evaluation of systems (QEST), pp. 146–155." href="/article/10.1007/s10994-016-5565-9#ref-CR49" id="ref-link-section-d52740e414">2004a</a>; Mao et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Mao, H., Chen, Y., Jaeger, M., Nielsen, T. D., Larsen, K. G., &amp; Nielsen, B. (2011). Learning probabilistic automata for model checking. In Proceedings of the international conference on quantitative evaluation of system (QEST 2011), pp. 111–120." href="/article/10.1007/s10994-016-5565-9#ref-CR39" id="ref-link-section-d52740e417">2011</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Mao, H., Chen, Y., Jaeger, M., Nielsen, T. D., Larsen, K. G., &amp; Nielsen, B. (2012). Learning Markov decision processes for model checking. In Proceedings of the first workshop on quantities in formal methods (QFM), pp. 49–63." href="/article/10.1007/s10994-016-5565-9#ref-CR40" id="ref-link-section-d52740e421">2012</a>).</p><p>In this paper we investigate methods for learning deterministic probabilistic finite automata (DPFA) from data consisting of previously observed system behaviors, i.e., sample executions. The probabilistic models considered in this paper include labeled Markov decision processes (MDPs) and continuous-time labeled Markov chains (CTMCs), where the former model class also covers labeled Markov chains (LMCs) as a special case. Labeled Markov decision processes can be used to model reactive systems, where input actions are chosen non-deterministically and the resulting output for a given input action is determined probabilistically. Nondeterminism can model the free and unpredictable choices from an environment or the concurrency between components in a system. MDPs and by extension LMCs are discrete-time models, where each transition takes a universal discrete time unit. CTMCs, on the other hand, are real-time models, where the time delays between transitions are determined probabilistically. We show how methods for learning deterministic probabilistic finite automata (DPFA) (Carrasco and Oncina <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Carrasco, R., &amp; Oncina, J. (1994). Learning stochastic regular grammars by means of a state merging method. In Proceedings of the international colloquium on grammatical inference and applications (ICGIA 1994), pp. 139–152." href="/article/10.1007/s10994-016-5565-9#ref-CR10" id="ref-link-section-d52740e427">1994</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Carrasco, R. C., &amp; Oncina, J. (1999). Learning deterministic regular grammars from stochastic samples in polynomial time. Journal of Theoretial Informatics and Applications, 33(1), 1–20." href="/article/10.1007/s10994-016-5565-9#ref-CR11" id="ref-link-section-d52740e430">1999</a>; Higuera <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Higuera, Cd. (2010). Grammatical inference: Learning automata and grammars. Cambridge: Cambridge University Press." href="/article/10.1007/s10994-016-5565-9#ref-CR30" id="ref-link-section-d52740e433">2010</a>) can be adapted for learning the above three model classes and pose the results within a model checking context. We give consistency results for the learning algorithms, and we analyze both theoretically and experimentally how the convergence of the learned models relates to the convergence of system properties expressed in linear time logics.</p><p>We also compare the accuracy of model checking learned models with the accuracy of a statistical model checking approach, where probabilities of query properties are directly estimated from the empirical frequencies in the data. Our results here demonstrate a smoothing effect of model learning which can prevent overfitting, but may in some cases also lead to less accurate results compared to statistical model checking. Our results also indicate a significant advantage of model learning over statistical model checking for the amortized time complexity over multiple queries.</p><h3 class="c-article__sub-heading" id="Sec2">Related work</h3><p>Work on learning finite automata models can first be divided into two broad categories: active learning following Angluin’s <span class="mathjax-tex">\(\mathbf {L}^*\)</span> algorithm (Angluin <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Angluin, D. (1987). Learning regular sets from queries and counterexamples. Journal of Information and Computation, 75, 87–106." href="/article/10.1007/s10994-016-5565-9#ref-CR3" id="ref-link-section-d52740e475">1987</a>), and passive learning based on a state-merging procedure.</p><p>Active learning is based on the assumption that there exists a teacher or an oracle that answers <i>membership</i> and <i>equivalence</i> queries. Originally developed by Angluin (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1987" title="Angluin, D. (1987). Learning regular sets from queries and counterexamples. Journal of Information and Computation, 75, 87–106." href="/article/10.1007/s10994-016-5565-9#ref-CR3" id="ref-link-section-d52740e487">1987</a>) for learning deterministic finite automata, <span class="mathjax-tex">\(\mathbf {L}^*\)</span> has been generalized in many different ways that also include extensions to learning automata models with inputs and outputs, as well as probabilistic automata: in Bollig et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Bollig, B., Katoen, J. P., Kern, C., &amp; Leucker, M. (2010). Learning communicating automata from MSCs. IEEE Transactions on Software Engineering, 36(3), 390–408." href="/article/10.1007/s10994-016-5565-9#ref-CR7" id="ref-link-section-d52740e518">2010</a>), <span class="mathjax-tex">\(\mathbf {L}^*\)</span> is exploited to learn communicating finite-state machines by using a given set of positive and negative message sequence charts to answer the membership and equivalence queries. In Niese (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Niese, O. (2003). An integrated approach to testing complex systems. PhD thesis, Universität Dortmund." href="/article/10.1007/s10994-016-5565-9#ref-CR41" id="ref-link-section-d52740e550">2003</a>), <span class="mathjax-tex">\(\mathbf {L}^*\)</span> is adapted to learn deterministic Mealy machines. This work is further extended to learn deterministic I/O automata by placing a transducer between the teacher and the Mealy machine learner (Aarts and Vaandrager <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Aarts, F., &amp; Vaandrager, F. W. (2010). Learning I/O automata. In Proceedings of the international conference on concurrency theory (CONCUR 2010), pp. 71–85." href="/article/10.1007/s10994-016-5565-9#ref-CR1" id="ref-link-section-d52740e581">2010</a>). In Grinchtein et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Grinchtein, O., Jonsson, B., &amp; Leucker, M. (2005). Inference of timed transition systems. Journal of Electronic Notes in Theoretical Compututer Science, 138(3), 87–99." href="/article/10.1007/s10994-016-5565-9#ref-CR26" id="ref-link-section-d52740e584">2005</a>, (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Grinchtein, O., Jonsson, B., &amp; Pettersson, P. (2006). Inference of event-recording automata using timed decision trees. In Proceedings of the international conference on concurrency theory (CONCUR), pp. 435–449." href="/article/10.1007/s10994-016-5565-9#ref-CR27" id="ref-link-section-d52740e587">2006</a>), <span class="mathjax-tex">\(\mathbf {L}^*\)</span> is adapted to learn <i>deterministic event-recording automata</i> which is a subclass of real-time automata.</p><p>To learn probabilistic automata models, modified versions of <span class="mathjax-tex">\(\mathbf {L}^*\)</span> have been proposed in which a membership query now asks for the probability of a given word in the target model (Tzeng <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Tzeng, W. G. (1992). Learning probabilistic automata and markov chains via queries. Machine Learning, 8, 151–166." href="/article/10.1007/s10994-016-5565-9#ref-CR53" id="ref-link-section-d52740e653">1992</a>; de Higuera and Oncina <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="de Higuera, C., &amp; Oncina, J. (2004). Learning stochastic finite automata. In Proceedings of the international conference on grammatical inference, pp. 175–186." href="/article/10.1007/s10994-016-5565-9#ref-CR20" id="ref-link-section-d52740e656">2004</a>; Feng et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Feng, L., Han, T., Kwiatkowska, M. Z., &amp; Parker, D. (2011). Learning-based compositional verification for synchronous probabilistic systems. In 9th international symposium on automated technology for verification and analysis (ATVA), pp. 511–521." href="/article/10.1007/s10994-016-5565-9#ref-CR23" id="ref-link-section-d52740e659">2011</a>). In Komuravelli et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Komuravelli, A., Pasareanu, C. S., &amp; Clarke, E. M. (2012). Learning probabilistic systems from tree samples. In Proceedings of the 27th annual IEEE/ACM symposium on logic in computer science, pp. 441–450." href="/article/10.1007/s10994-016-5565-9#ref-CR33" id="ref-link-section-d52740e662">2012</a>), <span class="mathjax-tex">\(\mathbf {L}^*\)</span> combined with a stochastic state-space partitioning algorithm makes it possible to learn nondeterministic labeled probabilistic transition systems from tree samples. Exact oracles for (classical or probabilistic) membership and equivalence queries are usually not available in practice and have to be approximated. For deterministic finite automata this has been implemented using a conformance testing sub-routine (Raffelt and Steffen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Raffelt, H., &amp; Steffen, B. (2006). Learnlib: A library for automata learning and experimentation. In Proceedings of the international conference on fundamental approaches to software engineering (FASE), pp. 377–380." href="/article/10.1007/s10994-016-5565-9#ref-CR45" id="ref-link-section-d52740e694">2006</a>).</p><p>Passive learning methods that only require data consisting of observed system behaviors have been developed for probabilistic automata models (Carrasco and Oncina <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Carrasco, R., &amp; Oncina, J. (1994). Learning stochastic regular grammars by means of a state merging method. In Proceedings of the international colloquium on grammatical inference and applications (ICGIA 1994), pp. 139–152." href="/article/10.1007/s10994-016-5565-9#ref-CR10" id="ref-link-section-d52740e700">1994</a>; Ron et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Ron, D., Singer, Y., &amp; Tishby, N. (1996). The power of amnesia: Learning probabilistic automata with variable memory length. Machine Learning, 25(2–3), 117–149." href="/article/10.1007/s10994-016-5565-9#ref-CR46" id="ref-link-section-d52740e703">1996</a>). These approaches are based on iteratively merging candidate states. Different approaches differ with respect to the strategy according to which candidate states are generated, and the criteria used for deciding whether to merge states. In algorithms following the paradigm of the <span class="u-small-caps">Alergia</span> algorithm (Carrasco and Oncina <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Carrasco, R., &amp; Oncina, J. (1994). Learning stochastic regular grammars by means of a state merging method. In Proceedings of the international colloquium on grammatical inference and applications (ICGIA 1994), pp. 139–152." href="/article/10.1007/s10994-016-5565-9#ref-CR10" id="ref-link-section-d52740e709">1994</a>), first a maximal, tree-shaped automaton is constructed, and iteratively reduced by recursive merge operations. The learning paradigm introduced by Ron et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Ron, D., Singer, Y., &amp; Tishby, N. (1996). The power of amnesia: Learning probabilistic automata with variable memory length. Machine Learning, 25(2–3), 117–149." href="/article/10.1007/s10994-016-5565-9#ref-CR46" id="ref-link-section-d52740e712">1996</a>), on the other hand, starts with a minimal automaton and successively refines it by expanding existing states with new candidate states. More important than these architectural differences, however, are differences in the criteria used for state merging. The most common approach is to use a statistical test for the equivalence of the distributions defined at the nodes (Carrasco and Oncina <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Carrasco, R., &amp; Oncina, J. (1994). Learning stochastic regular grammars by means of a state merging method. In Proceedings of the international colloquium on grammatical inference and applications (ICGIA 1994), pp. 139–152." href="/article/10.1007/s10994-016-5565-9#ref-CR10" id="ref-link-section-d52740e716">1994</a>; de la Higuera and Thollard <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="de la Higuera, C., &amp; Thollard, F. (2000). Identification in the limit with probability one of stochastic deterministic finite automata. In Proceedings of the international colloquium on grammatical inference: Algorithms and application (ICGI 2000), pp. 141–156." href="/article/10.1007/s10994-016-5565-9#ref-CR21" id="ref-link-section-d52740e719">2000</a>). For basic probabilistic automata only tests for the equivalence of binomial distributions are required, for which the use of the Hoeffding test is usually suggested. For timed automata models, this has been extended in Sen et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004a" title="Sen, K., Viswanathan, M., &amp; Agha, G. (2004a). Learning continuous time Markov chains from sample executions. In Proceedings of international conference on quantitative evaluation of systems (QEST), pp. 146–155." href="/article/10.1007/s10994-016-5565-9#ref-CR49" id="ref-link-section-d52740e722">2004a</a>) to also test the equivalence of two exponential distributions defining the delay times at the states. Thollard et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Thollard, F., Dupont, P., &amp; de la Higuera, C. (2000). Probabilistic DFA inference using kullback-leibler divergence and minimality. In Proceedings of the international conference on machine learning (ICML), pp. 975–982." href="/article/10.1007/s10994-016-5565-9#ref-CR52" id="ref-link-section-d52740e725">2000</a>) provide the minimum divergence inference algorithm to control state merging: two nodes should be merged if the loss of the likelihood can be compensated by the reduced complexity of the resulting model. Ron et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Ron, D., Singer, Y., &amp; Tishby, N. (1998). On the learnability and usage of acyclic probabilistic finite automata. Journal of Computer and System Sciences, 56(2), 133–152." href="/article/10.1007/s10994-016-5565-9#ref-CR47" id="ref-link-section-d52740e728">1998</a>) base the state merging decision on the existence of a distinguishing string, i.e. a string for which the difference of probability at the two candidate states exceeds a certain threshold. The state merging algorithms have been extended to learn stochastic transducers (Oncina et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993" title="Oncina, J., Garcia, P., &amp; Vidal, E. (1993). Learning subsequential transducers for pattern recognition interpretation tasks. IEEE Transactions on Pattern Analysis Machine Intelligence, 15(5), 448–458." href="/article/10.1007/s10994-016-5565-9#ref-CR42" id="ref-link-section-d52740e731">1993</a>) and timed automata (Verwer <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Verwer, S. (2010). Efficient identification of timed automata—Theory and practice. PhD thesis, Technical University Delft." href="/article/10.1007/s10994-016-5565-9#ref-CR57" id="ref-link-section-d52740e735">2010</a>).</p><p>In a number of papers the convergence properties of learning algorithms have been studied. Carrasco and Oncina (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Carrasco, R., &amp; Oncina, J. (1994). Learning stochastic regular grammars by means of a state merging method. In Proceedings of the international colloquium on grammatical inference and applications (ICGIA 1994), pp. 139–152." href="/article/10.1007/s10994-016-5565-9#ref-CR10" id="ref-link-section-d52740e742">1994</a>), de la Higuera and Thollard (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="de la Higuera, C., &amp; Thollard, F. (2000). Identification in the limit with probability one of stochastic deterministic finite automata. In Proceedings of the international colloquium on grammatical inference: Algorithms and application (ICGI 2000), pp. 141–156." href="/article/10.1007/s10994-016-5565-9#ref-CR21" id="ref-link-section-d52740e745">2000</a>) and Sen et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004a" title="Sen, K., Viswanathan, M., &amp; Agha, G. (2004a). Learning continuous time Markov chains from sample executions. In Proceedings of international conference on quantitative evaluation of systems (QEST), pp. 146–155." href="/article/10.1007/s10994-016-5565-9#ref-CR49" id="ref-link-section-d52740e748">2004a</a>) give learning in the limit results, i.e., the unknown automaton is correctly identified in the limit of large sample sizes. Quantitative bounds on the speed of convergence in the form of PAC learnability results are given in Ron et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Ron, D., Singer, Y., &amp; Tishby, N. (1996). The power of amnesia: Learning probabilistic automata with variable memory length. Machine Learning, 25(2–3), 117–149." href="/article/10.1007/s10994-016-5565-9#ref-CR46" id="ref-link-section-d52740e751">1996</a>), Clark and Thollard (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Clark, A., &amp; Thollard, F. (2004). PAC-learnability of probabilistic deterministic finite state automata. Journal of Machine Learning Research, 5, 473–497." href="/article/10.1007/s10994-016-5565-9#ref-CR16" id="ref-link-section-d52740e754">2004</a>) and Castro and Gavaldà (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Castro, J., &amp; Gavaldà, R. (2008). Towards feasible PAC-learning of probabilistic deterministic finite automata. In Grammatical inference: Algorithms and applications, pp. 163–174." href="/article/10.1007/s10994-016-5565-9#ref-CR12" id="ref-link-section-d52740e758">2008</a>).</p><p>The use of grammatical inference techniques for model construction in a verification context has been proposed in several papers (Cobleigh et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Cobleigh, J. M., Giannakopoulou, D., &amp; Pasareanu, C. S. (2003). Learning assumptions for compositional verification. In Proceedings of the 9th international conference on tools and algorithms for the construction and analysis of systems (TACAS), pp. 331–346." href="/article/10.1007/s10994-016-5565-9#ref-CR17" id="ref-link-section-d52740e764">2003</a>; Giannakopoulou and Păsăreanu <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Giannakopoulou, D., &amp; Păsăreanu, C. S. (2005). Learning-based assume-guarantee verification (Tool Paper). In P. Godefroid (Ed.), Model Checking Software: 12th International SPIN Workshop (pp. 282–287). Berlin, Heidelberg: Springer." href="/article/10.1007/s10994-016-5565-9#ref-CR25" id="ref-link-section-d52740e767">2005</a>; Leucker <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Leucker, M. (2007). Learning meets verification. In Proceedings of the international conference on formal methods for components and objects (FMCO 2007), pp. 127–151." href="/article/10.1007/s10994-016-5565-9#ref-CR37" id="ref-link-section-d52740e770">2007</a>; Singh et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Singh, R., Giannakopoulou, D., &amp; Pasareanu, C. S. (2010). Learningcomponent interfaces with may and must abstractions. In Computer aided verification. Lecture Notes in Computer Science, Vol. 3576, pp. 527–542." href="/article/10.1007/s10994-016-5565-9#ref-CR51" id="ref-link-section-d52740e773">2010</a>; Feng et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Feng, L., Han, T., Kwiatkowska, M. Z., &amp; Parker, D. (2011). Learning-based compositional verification for synchronous probabilistic systems. In 9th international symposium on automated technology for verification and analysis (ATVA), pp. 511–521." href="/article/10.1007/s10994-016-5565-9#ref-CR23" id="ref-link-section-d52740e776">2011</a>). These papers focus on active learning using variants of <span class="mathjax-tex">\(\mathbf {L}^*\)</span>, and only Feng et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Feng, L., Han, T., Kwiatkowska, M. Z., &amp; Parker, D. (2011). Learning-based compositional verification for synchronous probabilistic systems. In 9th international symposium on automated technology for verification and analysis (ATVA), pp. 511–521." href="/article/10.1007/s10994-016-5565-9#ref-CR23" id="ref-link-section-d52740e808">2011</a>) consider the probabilistic case.</p><p>Statistical model checking (SMC) (Sen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004b" title="Sen, K., Viswanathan, M., &amp; Agha, G. (2004b). Statistical model checking of black-box probabilistic systems. In Alur, R., Peled, D. (Eds.), Computer aided verification. Lecture Notes in Computer Science, Vol. 3114, pp. 202–215." href="/article/10.1007/s10994-016-5565-9#ref-CR50" id="ref-link-section-d52740e814">2004b</a>; Legay et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Legay, A., Delahaye, B., &amp; Bensalem, S. (2010). Statistical model checking: An overview. In Proceedings of the first international conference on runtime verification, Springer, Berlin, RV’10, pp. 122–135." href="/article/10.1007/s10994-016-5565-9#ref-CR36" id="ref-link-section-d52740e817">2010</a>) or approximate model-checking (Hérault et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Hérault, T., Lassaigne, R., Magniette, F., &amp; Peyronnet, S. (2004). Approximate probabilistic model checking. In Steffen, B., Levi, G. (Eds.), Verification, model checking, and abstract interpretation. Lecture Notes in Computer Science, Vol. 2937, Springer, Berlin, pp. 307–329." href="/article/10.1007/s10994-016-5565-9#ref-CR29" id="ref-link-section-d52740e820">2004</a>) has a similar objective as model learning for verification. Instead of constructing a model from sample executions, one directly checks the empirical probabilities of properties in the data. Since the sample executions can only be finite strings, this approach is limited with respect to checking probabilities for unbounded properties.</p><h3 class="c-article__sub-heading" id="Sec3">Contribution and outline</h3><p>Our work follows the <span class="u-small-caps">Alergia</span> paradigm and is closely linked to previous work (Carrasco and Oncina <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Carrasco, R., &amp; Oncina, J. (1994). Learning stochastic regular grammars by means of a state merging method. In Proceedings of the international colloquium on grammatical inference and applications (ICGIA 1994), pp. 139–152." href="/article/10.1007/s10994-016-5565-9#ref-CR10" id="ref-link-section-d52740e834">1994</a>; Sen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004a" title="Sen, K., Viswanathan, M., &amp; Agha, G. (2004a). Learning continuous time Markov chains from sample executions. In Proceedings of international conference on quantitative evaluation of systems (QEST), pp. 146–155." href="/article/10.1007/s10994-016-5565-9#ref-CR49" id="ref-link-section-d52740e837">2004a</a>). We here do not introduce any major algorithmic novelties, but give an integrated account of learning system models that can also represent input/output behaviors and time delays. The novel aspect of this paper is a theoretical and experimental analysis of the feasibility of using the learned model for formal verification of temporal logic properties. We present theoretical results that based on the convergence properties for <span class="u-small-caps">Alergia</span>-like algorithms establish the convergence also of probability estimates for system properties of interest. An extensive empirical evaluation provides insight into the workings of the algorithm and demonstrates the feasibility of the learning approach for verification applications in practice. The evaluation also includes a detailed comparison of the learning approach with statistical model checking, considering both accuracy results and the time and space complexity for performing model checking. Finally, we provide a new detailed proof of the fundamental convergence results. While generally following the lines of argument pioneered in Carrasco and Oncina (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Carrasco, R., &amp; Oncina, J. (1994). Learning stochastic regular grammars by means of a state merging method. In Proceedings of the international colloquium on grammatical inference and applications (ICGIA 1994), pp. 139–152." href="/article/10.1007/s10994-016-5565-9#ref-CR10" id="ref-link-section-d52740e843">1994</a>), de la Higuera and Thollard (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="de la Higuera, C., &amp; Thollard, F. (2000). Identification in the limit with probability one of stochastic deterministic finite automata. In Proceedings of the international colloquium on grammatical inference: Algorithms and application (ICGI 2000), pp. 141–156." href="/article/10.1007/s10994-016-5565-9#ref-CR21" id="ref-link-section-d52740e847">2000</a>) and Sen et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004a" title="Sen, K., Viswanathan, M., &amp; Agha, G. (2004a). Learning continuous time Markov chains from sample executions. In Proceedings of international conference on quantitative evaluation of systems (QEST), pp. 146–155." href="/article/10.1007/s10994-016-5565-9#ref-CR49" id="ref-link-section-d52740e850">2004a</a>), our new proof contains the following improvements: it is cast in a very general framework, and accommodates in a uniform manner different classes of automata models, including input/output and timed automata. It is presented in a modular form that clearly identifies separate conditions for the algorithmic structure of the state merging procedure, for the statistical tests used for state-merging decisons, and for the data-generating process. The structure of the proof thereby facilitates the application of the convergence result to new learning scenarios. Since this general convergence analysis is somewhat independent from the rest of this paper, it is placed in a self-contained “Appendix”.</p><p>The paper is structured as follows: Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec4">2</a> presents background material. Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec8">3</a> describes the adapted <span class="u-small-caps">Alergia</span> algorithm for learning system models, and Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec15">4</a> analyzes the consistency and convergence properties of the learning algorithm. Section <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec16">5</a> provides empirical results on the behavior of the learning algorithm and demonstrates the use of the algorithm in a model checking context. The last section concludes the paper and outlines directions for future research. The “Appendix” contains our general convergence analysis. This paper is an extended version of Mao et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Mao, H., Chen, Y., Jaeger, M., Nielsen, T. D., Larsen, K. G., &amp; Nielsen, B. (2011). Learning probabilistic automata for model checking. In Proceedings of the international conference on quantitative evaluation of system (QEST 2011), pp. 111–120." href="/article/10.1007/s10994-016-5565-9#ref-CR39" id="ref-link-section-d52740e872">2011</a>, (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Mao, H., Chen, Y., Jaeger, M., Nielsen, T. D., Larsen, K. G., &amp; Nielsen, B. (2012). Learning Markov decision processes for model checking. In Proceedings of the first workshop on quantities in formal methods (QFM), pp. 49–63." href="/article/10.1007/s10994-016-5565-9#ref-CR40" id="ref-link-section-d52740e875">2012</a>). Compared to these earlier conference publications, this paper significantly expands the theoretical analysis of the consistency aspects. It also includes a much more comprehensive experimental evaluation, in which the comparison against statistical model checking is added as a new dimension.</p></div></div></section><section aria-labelledby="Sec4" data-title="Preliminaries"><div class="c-article-section" id="Sec4-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec4">Preliminaries</h2><div class="c-article-section__content" id="Sec4-content"><h3 class="c-article__sub-heading" id="Sec5">Strings</h3><p>We start by introducing the notion of strings that will be used throughout the paper.</p><ul class="u-list-style-dash">
                    <li>
                      <p>Given a finite alphabet <span class="mathjax-tex">\(\varSigma \)</span>, we use <span class="mathjax-tex">\(\varSigma ^*\)</span> and <span class="mathjax-tex">\(\varSigma ^{\omega }\)</span> to denote the set of all finite and infinite strings over <span class="mathjax-tex">\(\varSigma \)</span>, respectively.</p>
                    </li>
                    <li>
                      <p>Given a infinite string <span class="mathjax-tex">\(s=\sigma _0\sigma _1 \ldots \in \varSigma ^{\omega }\)</span> starting with the symbol <span class="mathjax-tex">\(\sigma _0\)</span>, <span class="mathjax-tex">\(s[j\ldots ] = \sigma _{j} \sigma _{j+1} \sigma _{j+2} \ldots \)</span> is the suffix of <i>s</i> starting with the <span class="mathjax-tex">\((j+1)\)</span>st symbol <span class="mathjax-tex">\(\sigma _j\)</span> and <span class="mathjax-tex">\(\sigma _0 \sigma _1\ldots \sigma _j \in \varSigma ^{*}\)</span> is the prefix of <i>s</i>.</p>
                    </li>
                    <li>
                      <p>Given an input alphabet <span class="mathjax-tex">\(\varSigma ^{\text {in}} \)</span> and an output alphabet <span class="mathjax-tex">\(\varSigma ^{\text {out}} \)</span>, an infinite I/O string is denoted as <span class="mathjax-tex">\(\pi =\sigma _0\alpha _1\sigma _1\ldots \in \varSigma ^{\text {out}} \times (\varSigma ^{\text {in}} \times \varSigma ^{\text {out}})^{\omega }\)</span>, and <span class="mathjax-tex">\(\sigma _0 \alpha _1 \sigma _1 \ldots \alpha _n \sigma _n \in \varSigma ^{\text {out}} \times (\varSigma ^{\text {in}} \times \varSigma ^{\text {out}})^{*}\)</span> is the prefix of <i>s</i> with <span class="mathjax-tex">\(2n+1\)</span> alternating I/O symbols.</p>
                    </li>
                    <li>
                      <p>Given a finite string <span class="mathjax-tex">\(s=\sigma _0\sigma _1 \ldots \sigma _n\)</span>, we use <span class="mathjax-tex">\(\mathrm {prefix}(s)=\{\sigma _0 \ldots \sigma _j | 0\le j \le n\}\)</span> to denote the set of all prefixes of string <i>s</i>. For a finite I/O string <span class="mathjax-tex">\(\pi =\sigma _0\alpha _1\sigma _1\ldots \alpha _n \sigma _n\)</span>, <span class="mathjax-tex">\(\mathrm {prefix}(\pi )=\{\sigma _0 \alpha _1\sigma _1\ldots \alpha _j \sigma _j | 0\le j \le n\}\)</span>. Given a set of finite strings <span class="mathjax-tex">\(S\)</span>, <span class="mathjax-tex">\(\mathrm {prefix}(S)\)</span> denotes all prefixes of strings in <i>S</i>.</p>
                    </li>
                    <li>
                      <p>A timed string <span class="mathjax-tex">\(\rho =\sigma _0 t_0 \sigma _1 t_1\ldots \)</span> includes the time delay <span class="mathjax-tex">\(t_i \in \mathbb R_{&gt;0}\)</span> between the observation of two consecutive symbols <span class="mathjax-tex">\(\sigma _i\)</span> and <span class="mathjax-tex">\(\sigma _{i+1}\)</span> in the string. Given a timed string <span class="mathjax-tex">\(\rho \)</span>, <span class="mathjax-tex">\(\rho [n] = \sigma _n\)</span> is the (<span class="mathjax-tex">\(n+1\)</span>)th symbol of <span class="mathjax-tex">\(\rho \)</span>, <span class="mathjax-tex">\(\rho [n\ldots ] = \sigma _n t_n \sigma _{n+1} t_{n+1}\ldots \)</span> is the suffix starting from the (<span class="mathjax-tex">\(n+1\)</span>)th symbol, <span class="mathjax-tex">\(\rho \langle n\rangle =t_n\)</span> is the time spent between observing the symbols <span class="mathjax-tex">\(\sigma _n\)</span> and <span class="mathjax-tex">\(\sigma _{n+1}\)</span>, and <span class="mathjax-tex">\(\rho @t\)</span> is the suffix starting at time <span class="mathjax-tex">\(t\in \mathbb R_{&gt;0}\)</span>, i.e., <span class="mathjax-tex">\(\rho @ t = \rho [n\ldots ] \)</span>, where <i>n</i> is the smallest index such that <span class="mathjax-tex">\(\sum \nolimits _{i = 0}^n {\rho \left\langle i \right\rangle } \ge t\)</span>. The skeleton of <span class="mathjax-tex">\(\rho \)</span>, denoted <span class="mathjax-tex">\(\mathbb S(\rho )\)</span>, is the string <span class="mathjax-tex">\(\sigma _0\sigma _1 \ldots \in \varSigma ^{\omega }\)</span>.</p>
                    </li>
                  </ul>
                        <h3 class="c-article__sub-heading" id="Sec6">Stochastic system models</h3><p>We begin with the definition of the basic (D)MC model, which quantifies transitions with probabilities. We next extend (D)MCs to DMDPs by introducing input actions, where each input action on a state defines a probability distribution over successor states. In both DMCs and DMDPs, the time spent in each state is given by a universal discrete time unit. We lift this assumption in DCTMCs by modeling the transition times using a probabilistic model.</p>
                  <h3 class="c-article__sub-heading" id="FPar1">Definition 1</h3>
                  <p>(MC) A <i>labeled Markov chain (MC)</i> is a tuple <span class="mathjax-tex">\( \mathcal {M}^c =\langle Q, \varSigma ^{\text {out}},\mathbb {I}, \delta , L\rangle \)</span>, where</p><ul class="u-list-style-dash">
                      <li>
                        <p>
                                       <i>Q</i> is a finite set of states,</p>
                      </li>
                      <li>
                        <p>
                                       <span class="mathjax-tex">\(\varSigma ^{\text {out}}\)</span> is a finite alphabet,</p>
                      </li>
                      <li>
                        <p>
                                       <span class="mathjax-tex">\(\mathbb {I}:Q \rightarrow [0,1]\)</span> is an initial probability distribution over <i>Q</i> such that <span class="mathjax-tex">\(\sum _{q\in Q}\mathbb {I}(q)=1\)</span>,</p>
                      </li>
                      <li>
                        <p>
                                       <span class="mathjax-tex">\(\delta :Q\times Q\rightarrow [0,1]\)</span> is the transition probability function such that for all <span class="mathjax-tex">\(q\in Q\)</span>, <span class="mathjax-tex">\(\sum _{q'\in Q}\delta (q,q')=1\)</span>, and</p>
                      </li>
                      <li>
                        <p>
                                       <span class="mathjax-tex">\(L: Q\rightarrow \varSigma ^{\text {out}}\)</span> is a labeling function.</p>
                      </li>
                    </ul>
                           
                
                  <h3 class="c-article__sub-heading" id="FPar2">Definition 2</h3>
                  <p>(DMC) A labeled Markov chain is <i>deterministic (DMC)</i>, if</p><ul class="u-list-style-dash">
                      <li>
                        <p>there exists a <i>start</i> state <span class="mathjax-tex">\(q^s\in Q\)</span> with <span class="mathjax-tex">\(\mathbb {I}(q^s)=1\)</span>, and</p>
                      </li>
                      <li>
                        <p>for all <span class="mathjax-tex">\(q\in Q\)</span> and <span class="mathjax-tex">\(\sigma \in \varSigma ^{\text {out}} \)</span>: there exists at most one <span class="mathjax-tex">\(q'\in Q\)</span> with <span class="mathjax-tex">\(L(q')=\sigma \)</span> for which <span class="mathjax-tex">\(\delta (q,q')&gt;0\)</span>.</p>
                      </li>
                    </ul>
                           
                <p>Since the possible successor states in a DMC are uniquely labeled, we sometimes abuse notation and write <span class="mathjax-tex">\(\delta (q,\sigma )\)</span> for <span class="mathjax-tex">\(\delta (q,q')\)</span> where <span class="mathjax-tex">\(L(q')=\sigma \)</span>.</p><p>Each state in the <span class="mathjax-tex">\( \mathcal {M}^c \)</span> represents a configuration of the system being modeled, and each transition represents the movement from one system configuration to another (quantified by a probability). An (infinite) <i>path</i> in <span class="mathjax-tex">\( \mathcal {M}^c \)</span> is a string of states: <span class="mathjax-tex">\(h = q_0 q_1 \ldots \in Q^{\omega }\)</span> where <span class="mathjax-tex">\(q_i \in Q\)</span> and <span class="mathjax-tex">\(\delta (q_i,q_{i+1}) &gt; 0\)</span>, for all <span class="mathjax-tex">\(i \in \mathbb N\)</span>. The <i>trace</i> for <i>h</i>, denoted <span class="mathjax-tex">\( trace (h)\)</span>, is a sequence of state labels <span class="mathjax-tex">\(s= \sigma _0\sigma _1\ldots \in (\varSigma ^{\text {out}})^{\omega }\)</span>, where <span class="mathjax-tex">\(\sigma _i=L(q_i)\)</span> for all <span class="mathjax-tex">\(i \in \mathbb N\)</span>. Given a finite path <span class="mathjax-tex">\(h=q_0q_1\ldots q_n\)</span>, the cylinder set of <i>h</i>, denoted <span class="mathjax-tex">\( Cyl (q_0 q_1\ldots q_n)\)</span>, is defined as the set of infinite paths with the prefix <i>h</i>. The probability of the cylinder set is given by</p><div id="Equ23" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P_{ \tiny \mathcal {M}^c }( Cyl (q_0 q_1\ldots q_n)) = \mathbb {I}(q_0) \cdot \prod _{i=1}^{n} \delta (q_{i-1},q_{i}). \end{aligned}$$</span></div></div><p>For any trace <span class="mathjax-tex">\(s\)</span> in a DMC, there exists at most one path <i>h</i> such that <span class="mathjax-tex">\( trace (h)=s\)</span>, hence the definition above readily extends to cylinder sets for strings. If the MC is non-deterministic, there may exist more than one path with trace <span class="mathjax-tex">\(s\)</span> in which case the probability of <span class="mathjax-tex">\( Cyl (s)\)</span> is given by</p><div id="Equ24" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P_{ \tiny { \mathcal {M}^c }}( Cyl (s)) = \sum \limits _{h:trace(h)=s}{P_{ \tiny \mathcal {M}^c }( Cyl (h))}. \end{aligned}$$</span></div></div><p>The probabilities assigned to cylinder sets induce a unique probability distribution on <span class="mathjax-tex">\((\varSigma ^{\text {out}})^{\omega }\)</span> (equipped with the <span class="mathjax-tex">\(\sigma \)</span>-algebra generated by the cylinder sets) (Baier and Katoen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Baier, C., &amp; Katoen, J. P. (2008). Principles of model checking. Cambridge, MA: The MIT Press." href="/article/10.1007/s10994-016-5565-9#ref-CR4" id="ref-link-section-d52740e4557">2008</a>). We denote this distribution also with <span class="mathjax-tex">\(P_{ \tiny { \mathcal {M}^c }}\)</span>. Moreover, we denote by <span class="mathjax-tex">\(P_{{\tiny \mathcal {M}^c },q}\)</span> the distribution obtained by (re)defining <span class="mathjax-tex">\(q\in Q\)</span> as the unique <i>start</i> state.</p><p>Note that our definition of (D)MCs differs from other versions of probabilistic automata, such as Rabin (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1963" title="Rabin, M. O. (1963). Probabilistic automata. Information and Control, 6(3), 230–245. doi:&#xA;                    10.1016/S0019-9958(63)90290-0&#xA;                    &#xA;                  . &#xA;                    http://www.sciencedirect.com/science/article/pii/S0019995863902900&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10994-016-5565-9#ref-CR44" id="ref-link-section-d52740e4666">1963</a>) and Segala (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Segala, R. (1996). Modeling and verification of randomized distributed real-time systems. Technical report. Cambridge, MA." href="/article/10.1007/s10994-016-5565-9#ref-CR48" id="ref-link-section-d52740e4669">1996</a>): we assume states to be labeled, whereas the more common automaton model puts the labels on the transitions. Both types of models are equivalent, but a translation of a transition-labeled automaton to a state-labeled automaton may increase the number of states by a factor of <span class="mathjax-tex">\(\mid \! \varSigma ^{\text {out}} \!\mid \)</span>. Despite the increase in model size, we still adopt (D)MCs as system models due to the model checking tools and algorithms already developed for this model class.</p><p>The MC is a purely probabilistic model, i.e., in a certain state, the probability of reaching a specific state in the next step is known. Deterministic labeled Markov decision processes (DMDPs) extend DMCs with non-determinism, which can be used to model reactive systems where input actions are chosen non-deterministically and the resulting output for a given input action is determined probabilistically.</p>
                  <h3 class="c-article__sub-heading" id="FPar3">Definition 3</h3>
                  <p>(DMDP) A <i>deterministic labeled Markov decision process (DMDP)</i> is a tuple <span class="mathjax-tex">\( \mathcal {M}^p = \langle Q, \varSigma ^{\text {in}}, \varSigma ^{\text {out}}, q^s, \delta , L \rangle \)</span>, where</p><ul class="u-list-style-dash">
                      <li>
                        <p>
                                       <span class="mathjax-tex">\(Q, \mathbb {I},\text { and } L\)</span> are the same as for DMCs,</p>
                      </li>
                      <li>
                        <p>
                                       <span class="mathjax-tex">\(\varSigma ^{\text {in}}\)</span> is a finite alphabet of input actions,</p>
                      </li>
                      <li>
                        <p>
                                       <span class="mathjax-tex">\(\varSigma ^{\text {out}}\)</span> is a finite alphabet of output symbols,</p>
                      </li>
                      <li>
                        <p>the transition probability function is defined as <span class="mathjax-tex">\(\delta :Q \times \varSigma ^{\text {in}} \times Q \rightarrow [0,1]\)</span>, such that for all <span class="mathjax-tex">\(q\in Q \)</span> and all <span class="mathjax-tex">\(\alpha \in \varSigma ^{\text {in}} \)</span>, <span class="mathjax-tex">\(\sum _{q'\in Q} \delta (q,\alpha ,q')=1\)</span>, and</p>
                      </li>
                      <li>
                        <p>for all <span class="mathjax-tex">\(q\in Q \)</span>, <span class="mathjax-tex">\(\alpha \in \varSigma ^{\text {in}} \)</span>, and <span class="mathjax-tex">\(\sigma \in \varSigma ^{\text {out}} \)</span>, there exists at most one <span class="mathjax-tex">\(q'\in Q \)</span> with <span class="mathjax-tex">\(L(q')=\sigma \in \varSigma ^{\text {out}} \)</span> and <span class="mathjax-tex">\(\delta (q,\alpha , q')&gt;0\)</span>.</p>
                      </li>
                    </ul>
                           
                <p>The last condition in the definition above together with the existence of a unique initial state <span class="mathjax-tex">\(q^s\)</span> makes the behavior of the model deterministic conditioned on the (non-deterministically chosen) input actions. Analogously to DMCs, we will sometimes abuse notation and write <span class="mathjax-tex">\(\delta (q,\alpha ,\sigma )\)</span> instead of <span class="mathjax-tex">\(\delta (q,\alpha ,q')\)</span> where <span class="mathjax-tex">\(L(q')=\sigma \)</span>. A path in a DMDP <span class="mathjax-tex">\( \mathcal {M}^p \)</span> is an alternating sequence of states <span class="mathjax-tex">\(q_i \in Q\)</span> and input symbols <span class="mathjax-tex">\(\alpha _i\in \varSigma ^{\text {in}} \)</span>, denoted as <span class="mathjax-tex">\(q_0 \alpha _1 q_1 \alpha _2 q_2 \ldots \)</span>. The trace of a path in a DMDP is defined analogously to the notion of trace in MCs. That is, the trace of a path <span class="mathjax-tex">\(q_0 \alpha _1 q_1 \alpha _2 q_2 \ldots \)</span> is an alternating sequence of input symbols and state labels <span class="mathjax-tex">\(\pi =\sigma _0\alpha _1 \sigma _1\alpha _2\sigma _2\ldots \in \varSigma ^{\text {out}} \times (\varSigma ^{\text {in}} \times \varSigma ^{\text {out}})^{\omega }\)</span>, where <span class="mathjax-tex">\(\sigma _i =L(q_i)\)</span>. To reason about the probability of a set of paths in the DMDP, a <i>scheduler</i> (also known as an <i>adversary</i> or a <i>strategy</i>) is introduced to resolve the non-deterministic choices on the input actions.</p>
                  <h3 class="c-article__sub-heading" id="FPar4">Definition 4</h3>
                  <p>(Scheduler) Let <span class="mathjax-tex">\( \mathcal {M}^p \)</span> be a DMDP and <span class="mathjax-tex">\(Q^+\)</span> be the set of state sequences of non-zero length. A <i>scheduler</i> for <span class="mathjax-tex">\( \mathcal {M}^p \)</span> is a function <span class="mathjax-tex">\(\mathfrak {S}: Q^+\times \varSigma ^{\text {in}} \rightarrow [0,1]\)</span> such that for all <span class="mathjax-tex">\(\varvec{q}=q_0q_1 \ldots q_n\in Q^+\)</span>, <span class="mathjax-tex">\(\sum _{\alpha \in \varSigma ^{\text {in}}}\mathfrak {S}(\varvec{q},\alpha )=1\)</span>. A scheduler is said to be <i>deterministic</i> if for all <span class="mathjax-tex">\(\varvec{q}\in Q^+\)</span> there exists an <span class="mathjax-tex">\(\alpha \in \varSigma ^{\text {in}} \)</span> for which <span class="mathjax-tex">\(\mathfrak {S}(\varvec{q},\alpha )=1\)</span>.</p>
                <p>The scheduler specifies an action for each state based on the path history for that state. It is said to be <i>fair</i> if in any state <i>q</i> all input actions can be chosen with non-zero probability. If a scheduler <span class="mathjax-tex">\(\mathfrak {S}\)</span> only depends on the current state we say that <span class="mathjax-tex">\(\mathfrak {S}\)</span> is <i>memoryless</i>. An <span class="mathjax-tex">\( \mathcal {M}^p \)</span> together with a scheduler <span class="mathjax-tex">\(\mathfrak {S}\)</span> induce a probability distribution defined by the cylinder set of all finite path fragments in <span class="mathjax-tex">\( \mathcal {M}^p \)</span>. For a cylinder set <span class="mathjax-tex">\( Cyl (q_0 \alpha _1q_1\ldots \alpha _nq_n)\)</span> the probability is defined as</p><div id="Equ25" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P_{\tiny { \mathcal {M}^p ,\mathfrak {S}}}( Cyl (q_0 \alpha _1q_1\ldots \alpha _nq_n)) = \mathbb {I}(q_0) \cdot \prod _{i=1}^{n} \mathfrak {S}(q_0\ldots q_{i-1},\alpha _i)\delta (q_{i-1},\alpha _i,q_{i}). \end{aligned}$$</span></div></div><p>Similarly to DMCs, the probability distribution defined above induces a probability distribution over cylinder sets of I/O strings, and hence a distribution over infinite I/O sequences.</p>
                  <h3 class="c-article__sub-heading" id="FPar5">Example 1</h3>
                  <p>The graphical model of a three-state DMDP <span class="mathjax-tex">\( \mathcal {M}^p \)</span> is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig1">1</a>a, where <span class="mathjax-tex">\(\varSigma ^{\text {in}} =\{\alpha ,\beta \}\)</span> and <span class="mathjax-tex">\(\varSigma ^{\text {out}} =\{A, B\}\)</span>. From the initial state <span class="mathjax-tex">\(q^s\)</span> (double circled) labeled with symbol <i>A</i>, the actions <span class="mathjax-tex">\(\alpha \)</span> and <span class="mathjax-tex">\(\beta \)</span> are chosen nondeterministically. Consider now the two memoryless schedulers <span class="mathjax-tex">\(\mathfrak {S}_1\)</span> and <span class="mathjax-tex">\(\mathfrak {S}_2\)</span> given by <span class="mathjax-tex">\(\mathfrak {S}_1(q) = \beta \)</span>, and <span class="mathjax-tex">\(\mathfrak {S}_2(q) = \alpha \)</span> if <span class="mathjax-tex">\(q = q^s\)</span> and <span class="mathjax-tex">\(\mathfrak {S}_2(q) =\beta \)</span> otherwise. The schedulers induce the DMCs in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig1">1</a>b, c, where for the string <span class="mathjax-tex">\(s=AAAA\)</span> we have <span class="mathjax-tex">\(P_{\tiny \mathcal {M}^c_{\mathfrak {S}_1}}(AAAA)=1\)</span>, and <span class="mathjax-tex">\(P_{\tiny \mathcal {M}^c_{\mathfrak {S}_2}}(AAAA)=4/9\)</span>.</p>
                
                  <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Fig. 1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig1_HTML.gif?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig1_HTML.gif" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>
                                       <b>a</b> A DMDP <span class="mathjax-tex">\( \mathcal {M}^p \)</span>. <b>b</b> The DMC <span class="mathjax-tex">\(\mathcal {M}^c_{\tiny \mathfrak {S}_1}\)</span> induced by the scheduler <span class="mathjax-tex">\(\mathfrak {S}_1\)</span>. <b>c</b> The DMC <span class="mathjax-tex">\(\mathcal {M}^c_{\mathfrak {S}_2}\)</span> induced by the scheduler <span class="mathjax-tex">\(\mathfrak {S}_2\)</span>
                                    </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>Both DMCs and DMDPs are discrete-time models, i.e., each transition takes a universal discrete time unit. The labeled deterministic continuous-time Markov chain (DCTMC) is a time-extension of the DMC, which models the amount of time the system stays in a specific state before making a transition to one of its successor states (Sen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004a" title="Sen, K., Viswanathan, M., &amp; Agha, G. (2004a). Learning continuous time Markov chains from sample executions. In Proceedings of international conference on quantitative evaluation of systems (QEST), pp. 146–155." href="/article/10.1007/s10994-016-5565-9#ref-CR49" id="ref-link-section-d52740e7521">2004a</a>; Chen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Chen, T., Han, T., Katoen, J. P., &amp; Mereacre, A. (2009). Quantitative model checking of continuous-time Markov chains against timed automata specifications. In 24th annual IEEE symposium on logic in computer science pp. 309–318." href="/article/10.1007/s10994-016-5565-9#ref-CR13" id="ref-link-section-d52740e7524">2009</a>).</p>
                  <h3 class="c-article__sub-heading" id="FPar6">Definition 5</h3>
                  <p>(DCTMC) A <i>deterministic labeled continuous-time Markov chain (DCTMC)</i> is a tuple <span class="mathjax-tex">\( \mathcal {M}^t = \langle Q, \varSigma ^{\text {out}}, q^s, \delta , {R}, L, \rangle \)</span>, where:</p><ul class="u-list-style-dash">
                      <li>
                        <p>
                                       <span class="mathjax-tex">\(Q, \varSigma ^{\text {out}}, q^s, \delta , L\)</span> are defined as for DMCs;</p>
                      </li>
                      <li>
                        <p>
                                       <span class="mathjax-tex">\({R}: Q \rightarrow \mathbb R_{\ge 0}\)</span> is the exit rate function.</p>
                      </li>
                    </ul>
                           
                <p>In a DCTMC, the probability of making a transition from state <i>q</i> to one of its successor states <span class="mathjax-tex">\(q'\)</span> within <i>t</i> time units is given by <span class="mathjax-tex">\( \delta (q,q') \cdot \left( {1 - e^{ - {R}(q) \cdot t} } \right) \)</span>, where <span class="mathjax-tex">\((1 - e^{ - {R}(q) \cdot t} )\)</span> is the cumulative distribution of an exponential function with rate parameter <span class="mathjax-tex">\({R}(q)\)</span>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Fig. 2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig2_HTML.gif?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig2_HTML.gif" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>
                                       <b>a</b> A DLMC <span class="mathjax-tex">\( \mathcal {M}^c \)</span> and <b>b</b> a structurally identical DCTMC <span class="mathjax-tex">\( \mathcal {M}^t \)</span> modeling the amount of time between state transitions</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        
                  <h3 class="c-article__sub-heading" id="FPar7">Example 2</h3>
                  <p>Consider the DMC <span class="mathjax-tex">\( \mathcal {M}^c \)</span> and the DCTMC <span class="mathjax-tex">\( \mathcal {M}^t \)</span> shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig2">2</a>. Both models have three states with initial state <span class="mathjax-tex">\(q^s\)</span> (double circled) and <span class="mathjax-tex">\(\varSigma ^{\text {out}} =\{A,B\}\)</span>. From <span class="mathjax-tex">\(q^s\)</span>, the probability of taking one of its two transitions are 1 / 3 and 2 / 3, respectively. Compared with <span class="mathjax-tex">\( \mathcal {M}^c \)</span> in (a), the DCTMC <span class="mathjax-tex">\( \mathcal {M}^t \)</span> in (b) has exit-rates associated with the states, e.g., 0.9 on <span class="mathjax-tex">\(q^s\)</span>. In <span class="mathjax-tex">\( \mathcal {M}^t \)</span>, the probability of leaving the initial state and moving to state <span class="mathjax-tex">\(q_2\)</span> within <i>t</i> time units is calculated as <span class="mathjax-tex">\(2/3\cdot (1-e^{0.9\cdot t})\)</span>.</p>
                <p>A <i>timed path</i> 
                           <i>h</i> in a DCTMC is an alternating sequence of states and time stamps <span class="mathjax-tex">\(q_0 {t_0} q_{1} {t_1} q_{2} \ldots \)</span>, where <span class="mathjax-tex">\(t_i \in \mathbb R_{&gt;0}\)</span> denotes the amount of time spent in state <span class="mathjax-tex">\(q_i\)</span> before going to <span class="mathjax-tex">\(q_{i+1}\)</span>. By adopting the notation for timed strings we let <span class="mathjax-tex">\(h[n]= q_n\)</span> and <span class="mathjax-tex">\(h\langle n\rangle = t_n\)</span>.</p><p>Let <span class="mathjax-tex">\( Cyl (q_0, I_0, \ldots , q_{k-1}, I_k,q_k)\)</span> denote the cylinder set containing all paths with <span class="mathjax-tex">\(h \langle i \rangle \in I_i\)</span> and <span class="mathjax-tex">\(h[i] = q_i\)</span>, for <span class="mathjax-tex">\(i&lt;k\)</span>. The probability of <span class="mathjax-tex">\( Cyl (q_0, I_0, \ldots , q_{k-1}, I_k,q_k)\)</span> is then defined inductively as follows (for <span class="mathjax-tex">\(k \ge 1\)</span>) (Baier et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Baier, C., Haverkort, B., Hermanns, H., &amp; Katoen, J. P. (2003). Model-checking algorithms for continuous-time Markov chains. Journal of IEEE Transaction on Software Engineering, 29(6), 524–541." href="/article/10.1007/s10994-016-5565-9#ref-CR5" id="ref-link-section-d52740e8923">2003</a>):</p><div id="Equ26" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned}&amp;P_{\tiny \mathcal {M}^t } ( Cyl (q_0, I_0, \ldots , q_{k-1}, I_k,q_k)) \nonumber \\&amp;\quad = P_{\tiny \mathcal {M}^t } ( Cyl (q_0, I_0, \ldots , q_{k-1})) \cdot \delta (q_{k-1}, q_k) \cdot (e^{ - {R}(q_{k-1})\inf (I_k)} - e^{ - {R}(q_{k-1})\sup (I_k)} ). \end{aligned}$$</span></div></div><p>Following the definition of cylinder sets for DMCs, we can directly extend the definition above to probability distributions over cylinder sets for timed strings.</p><h3 class="c-article__sub-heading" id="Sec7">Specification languages</h3><p>As will be detailed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec8">3</a>, the proposed learning algorithms assume that data appears in the form of sequences of linearly ordered observations of the system in question. When learning system models, we therefore only look for models that preserve linear-time properties, which include safety properties (something bad will never happen) and liveness properties (something good will always happen).</p><p>Linear-time temporal logic (LTL) (Pnueli <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1977" title="Pnueli, A. (1977). The temporal logic of programs. In Proceedings of the annual symposium on foundations of computer science (FOCS) pp. 46–57." href="/article/10.1007/s10994-016-5565-9#ref-CR43" id="ref-link-section-d52740e9328">1977</a>) is a logical formalism used for specifying system properties from a linear time perspective. The property specified by an LTL formula does not only depend on the current state, but can also relate to future states. The basic ingredients of an LTL formula are atomic propositions (state labels <span class="mathjax-tex">\(\sigma \in \varSigma ^{\text {out}} \)</span>), the Boolean connectors conjunction (<span class="mathjax-tex">\(\wedge \)</span>) and negation (<span class="mathjax-tex">\(\lnot \)</span>), and two basic temporal modalities <span class="mathjax-tex">\(\bigcirc \)</span> (<i>next</i>) and <span class="mathjax-tex">\(\text{ U }\)</span> (<i>until</i>) (Baier and Katoen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Baier, C., &amp; Katoen, J. P. (2008). Principles of model checking. Cambridge, MA: The MIT Press." href="/article/10.1007/s10994-016-5565-9#ref-CR4" id="ref-link-section-d52740e9454">2008</a>).</p>
                  <h3 class="c-article__sub-heading" id="FPar8">Definition 6</h3>
                  <p>(LTL) Linear-time temporal logic (LTL) over <span class="mathjax-tex">\(\varSigma ^{\text {out}} \)</span> is defined by the following syntax</p><div id="Equ27" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \varphi {:}{:} {=} true \;|\;a \;|\; \varphi {}_1 \wedge \varphi _2 \;|\; \lnot \varphi \;|\; \bigcirc \varphi \; |\; \varphi _1 \text{ U }\varphi _2, \text { where } a\in \varSigma ^{\text {out}}. \end{aligned}$$</span></div></div>
                           
                
                  <h3 class="c-article__sub-heading" id="FPar9">Definition 7</h3>
                  <p>(LTL Semantics) Let <span class="mathjax-tex">\(\varphi \)</span> be an LTL formula over <span class="mathjax-tex">\(\varSigma ^{\text {out}} \)</span>. For <span class="mathjax-tex">\( s= \sigma _0\sigma _1 \ldots \in (\varSigma ^{\text {out}})^\omega \)</span>, the LTL semantics of <span class="mathjax-tex">\(\varphi \)</span> are as follows:</p><ul class="u-list-style-dash">
                      <li>
                        <p>
                          <span class="mathjax-tex">\(s \; \models \; true \)</span>
                        </p>
                      </li>
                      <li>
                        <p>
                                       <span class="mathjax-tex">\(s \; \models a \)</span> iff <span class="mathjax-tex">\(a = \sigma _0\)</span>
                                    </p>
                      </li>
                      <li>
                        <p>
                                       <span class="mathjax-tex">\(s \; \models \; \varphi _1 \wedge \varphi _2\)</span> iff <span class="mathjax-tex">\(s \; \models \; \varphi _1\)</span> and <span class="mathjax-tex">\( s \; \models \; \varphi _2\)</span>
                                    </p>
                      </li>
                      <li>
                        <p>
                                       <span class="mathjax-tex">\(s \; \models \; \lnot \; \varphi \)</span> iff <span class="mathjax-tex">\( s \nvDash \varphi \)</span>
                                    </p>
                      </li>
                      <li>
                        <p>
                                       <span class="mathjax-tex">\(s \; \models \; \bigcirc \; \varphi \)</span> iff <span class="mathjax-tex">\( s[1\ldots ]\models \;\varphi \)</span>
                                    </p>
                      </li>
                      <li>
                        <p>
                                       <span class="mathjax-tex">\(s \; \models \; \varphi _1 \text{ U }\varphi _2 \)</span> iff <span class="mathjax-tex">\( \exists j\ge 0.\; s[j\ldots ]\models \; \varphi _2\)</span> and <span class="mathjax-tex">\(s[i\ldots ] \models \; \varphi _1\)</span>, for all <span class="mathjax-tex">\(0 \le i&lt; j\)</span>
                                    </p>
                      </li>
                    </ul>
                           
                <p>For better readability, we also use the derived temporal operators <span class="mathjax-tex">\(\Box \)</span> (<i>always</i>) and <span class="mathjax-tex">\(\lozenge \)</span> (<i>eventually</i>) given by <span class="mathjax-tex">\(\lozenge \varphi =(true \text{ U }\varphi )\)</span> (the model will eventually satisfy property <span class="mathjax-tex">\(\varphi \)</span>) and <span class="mathjax-tex">\(\Box \varphi =\lnot (\lozenge \lnot \varphi )\)</span> (property <span class="mathjax-tex">\(\varphi \)</span> always holds).</p><p>Model checking an MC <span class="mathjax-tex">\( \mathcal {M}^c \)</span> wrt. a LTL formula <span class="mathjax-tex">\(\varphi \)</span> means to compute the total probability of the traces in <span class="mathjax-tex">\( \mathcal {M}^c \)</span> which satisfy <span class="mathjax-tex">\(\varphi \)</span>, i.e., <span class="mathjax-tex">\(P_{\tiny \mathcal {M}^c }(\{ s \mid s \models \varphi , s \in (\varSigma ^{\text {out}})^\omega \})\)</span>.</p>
                  <h3 class="c-article__sub-heading" id="FPar10">Example 3</h3>
                  <p>The LTL formula <span class="mathjax-tex">\(A \text{ U }B\)</span> requires that a state <i>q</i> labeled with <i>B</i> will eventually be reached, and all states visited before <i>q</i> should all be labeled with <i>A</i>. For the DMC <span class="mathjax-tex">\( \mathcal {M}^c \)</span> in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig2">2</a>a, only paths starting with <span class="mathjax-tex">\(q^s q_2\)</span> satisfy the LTL formula. Model checking <span class="mathjax-tex">\( \mathcal {M}^c \)</span> wrt. <span class="mathjax-tex">\(A \text{ U }B\)</span> therefore amounts to computing the probability of all paths starting with <span class="mathjax-tex">\(q^s q_2\)</span>, i.e., <span class="mathjax-tex">\(P_{\tiny \mathcal {M}^c }(Cyl(q^s q_2)) = 2/3\)</span>. The LTL formula <span class="mathjax-tex">\(\lozenge \Box A\)</span>, read as <i>eventually forever</i> 
                              <i>A</i>, requires that after a certain point only states labeled with <i>A</i> will be visited. Paths starting from <span class="mathjax-tex">\(q_1\)</span> satisfy <span class="mathjax-tex">\(\Box A\)</span> and paths <i>eventually</i> reaching <span class="mathjax-tex">\(q_1\)</span> satisfy <span class="mathjax-tex">\(\lozenge \Box A\)</span>. Model checking <span class="mathjax-tex">\( \mathcal {M}^c \)</span> wrt. <span class="mathjax-tex">\(\lozenge \Box A\)</span> can therefore be similarly reduced to the calculation of the probability <span class="mathjax-tex">\(P_{\tiny \mathcal {M}^c }(\mathop \cup \limits _{i \in [0,\infty )} {Cyl(q^s(q_2 q^s)^i q_1)}) = 1/3 + 2/3\cdot 1/3+ (2/3)^2\cdot 1/3 + \cdots = 1\)</span>.</p>
                <p>The quantitative analysis of a DMDP <span class="mathjax-tex">\( \mathcal {M}^p \)</span> against a specification <span class="mathjax-tex">\(\varphi \)</span> amounts to establishing the lower and upper bounds that can be guaranteed when ranging over all possible schedulers. This corresponds to computing</p><div id="Equ28" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P^{\mathrm {max}}_{\tiny \mathcal {M}^p }(\varphi ) = \mathop {\sup }\limits _{\tiny \mathfrak {S}} P_{\tiny \mathcal {M}^p , \mathfrak {S}} (\varphi ) \;\; \text {and} \;\; P^{\mathrm {min}}_{\tiny \mathcal {M}^p } (\varphi ) = \mathop {\inf }\limits _{\tiny \mathfrak {S}} P_{\tiny \mathcal {M}^p , \mathfrak {S}} (\varphi ), \end{aligned}$$</span></div></div><p>where the infimum and supremum are taken over all possible schedulers for <span class="mathjax-tex">\( \mathcal {M}^p \)</span>.</p><p>Continuous stochastic logic (CSL) (Baier et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Baier, C., Haverkort, B., Hermanns, H., &amp; Katoen, J. P. (2003). Model-checking algorithms for continuous-time Markov chains. Journal of IEEE Transaction on Software Engineering, 29(6), 524–541." href="/article/10.1007/s10994-016-5565-9#ref-CR5" id="ref-link-section-d52740e11735">2003</a>) is a general branching-time temporal logic proposed for CTMCs that allows for a recursive combination of state and path formulas. However, as discussed in the beginning of the section, we only consider linear time properties of system models and we therefore define a linear sub-class of CSL, called sub-CSL, in which at most one temporal operator is allowed.</p>
                  <h3 class="c-article__sub-heading" id="FPar11">Definition 8</h3>
                  <p>(sub-CSL) A sub-CSL formula <span class="mathjax-tex">\(\varphi \)</span> is defined as follows:</p><div id="Equ29" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \varphi {:}{:} {=} \varPhi \;|\; \varPhi _1 \text{ U }_I \varPhi _2 \;|\; \lozenge _I \varPhi \;|\; \Box _I \varPhi , \end{aligned}$$</span></div></div><p>where <span class="mathjax-tex">\(\varPhi \)</span> is a propositional logic formula defined as <span class="mathjax-tex">\(\varPhi {:}{:} {=}true \;|\;a\;|\; \varPhi _1 \wedge \varPhi _2 \;|\; \lnot \varPhi a\in \varSigma ^{\text {out}} \)</span>, and <i>I</i> is an interval in <span class="mathjax-tex">\(\mathbb Q_{\ge 0}\)</span>.</p>
                
                  <h3 class="c-article__sub-heading" id="FPar12">Definition 9</h3>
                  <p>(Semantics for sub-CSL) Let <span class="mathjax-tex">\(\varphi \)</span> be a sub-CSL formula over <span class="mathjax-tex">\(\varSigma ^{\text {out}} \)</span>. The semantics of <span class="mathjax-tex">\(\varphi \)</span> over a timed trace <span class="mathjax-tex">\(\rho =\sigma _0 t_0 \sigma _1 t_1 \ldots \)</span> over <span class="mathjax-tex">\(\varSigma ^{\text {out}} \)</span> is as follows</p><ul class="u-list-style-dash">
                      <li>
                        <p>
                                       <span class="mathjax-tex">\(\rho \; \models \; \varPhi _1 \text{ U }_I \varPhi _2 \)</span>, iff <span class="mathjax-tex">\( \exists t \in I.\; (\rho @ t \models \varPhi _2 \wedge \forall t' &lt; t, \rho @ t' \models \varPhi _1)\)</span>
                                    </p>
                      </li>
                      <li>
                        <p>
                                       <span class="mathjax-tex">\(\rho \; \models \; \lozenge _I \varPhi \)</span>, iff <span class="mathjax-tex">\( \exists t \in I.\; (\rho @ t \models \varPhi )\)</span>
                                    </p>
                      </li>
                      <li>
                        <p>
                                       <span class="mathjax-tex">\(\rho \; \models \; \Box _I \varPhi \)</span>, iff <span class="mathjax-tex">\( \forall t \in I.\; (\rho @ t \models \varPhi )\)</span>
                                    </p>
                      </li>
                    </ul><p>The semantics for the Boolean connectives are defined as for LTL.</p>
                <p>Model checking a CTMC <span class="mathjax-tex">\( \mathcal {M}^t \)</span> wrt. a sub-CSL formula <span class="mathjax-tex">\(\varphi \)</span> amounts to computing the probability of the timed traces which satisfy <span class="mathjax-tex">\(\varphi \)</span>, i.e., <span class="mathjax-tex">\(P_{\tiny { \mathcal {M}^t }}(\varphi ) = P_{\tiny { \mathcal {M}^t }}(\{ \rho \mid \rho \models \varphi \})\)</span>.</p>
                  <h3 class="c-article__sub-heading" id="FPar13">Example 4</h3>
                  <p>The sub-CSL formula <span class="mathjax-tex">\(\varphi = A \; \text{ U }_{[1.5,2.3]} \;B\)</span> requires that a state <i>q</i> labeled with <i>B</i> will be reached within the time interval [1.5, 2.3] and that all states visited before <i>q</i> are labeled with <i>A</i>. For instance, the path <span class="mathjax-tex">\(q^s\; 1.8\; q_2\)</span>, generated by the DCTMC <span class="mathjax-tex">\( \mathcal {M}^t \)</span> in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig2">2</a>b, satisfies <span class="mathjax-tex">\(\varphi \)</span>. Model checking <span class="mathjax-tex">\( \mathcal {M}^t \)</span> against <span class="mathjax-tex">\(\varphi \)</span> amounts to calculating <span class="mathjax-tex">\(P_{\tiny \mathcal {M}^t }(Cyl(q^s,[1.5,2.3],q_2)) = 2/3 \cdot (e^{-0.9\times 1.5} - e^{-0.9\times 2.3}) \approx 0.0444 \)</span>.</p>
                </div></div></section><section aria-labelledby="Sec8" data-title="Learning stochastic models"><div class="c-article-section" id="Sec8-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec8">Learning stochastic models</h2><div class="c-article-section__content" id="Sec8-content"><p>In what follows we consider methods for automatically learning stochastic system models, as defined in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec4">2</a>, from data. The proposed algorithms are based on the <span class="u-small-caps">Alergia</span> algorithm (Carrasco and Oncina <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Carrasco, R., &amp; Oncina, J. (1994). Learning stochastic regular grammars by means of a state merging method. In Proceedings of the international colloquium on grammatical inference and applications (ICGIA 1994), pp. 139–152." href="/article/10.1007/s10994-016-5565-9#ref-CR10" id="ref-link-section-d52740e13124">1994</a>; Higuera <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Higuera, Cd. (2010). Grammatical inference: Learning automata and grammars. Cambridge: Cambridge University Press." href="/article/10.1007/s10994-016-5565-9#ref-CR30" id="ref-link-section-d52740e13127">2010</a>) and adapted to a verification context. The <span class="u-small-caps">Alergia</span> algorithm starts with the construction of a <i>frequency prefix tree acceptor</i> (FPTA), which serves as a representation of the data. The basic idea of the learning algorithm is to approximate the generating model by <i>merging</i> together nodes in the FPTA which correspond to the same state in the generating model. Two nodes are merged after they pass a <i>compatibility</i> test based on the statistical information associated with the nodes. Both the <i>compatibility</i> test and the state <i>merge</i> are conducted recursively over all successor nodes.</p><p>In this section, we first present the original FPTA for strings, which only contain output symbols, and then extend it to handle I/O strings and timed strings. Afterwards, we discuss the general procedure of the <span class="u-small-caps">Alergia</span> algorithm. At the end, we customize the compatibility tests and merge operations for learning different types of system models.</p><h3 class="c-article__sub-heading" id="Sec9">Data representation</h3><p>An FPTA <i>T</i> represents a set of strings <span class="mathjax-tex">\(S\)</span> over <span class="mathjax-tex">\(\varSigma ^{\text {out}} \)</span> in a tree structure, where each node is labeled by a symbol <span class="mathjax-tex">\(\sigma \in \varSigma ^{\text {out}} \)</span> and each path from the root to a node <span class="mathjax-tex">\(q_s\)</span> corresponds to a string <span class="mathjax-tex">\(s\in \mathrm {prefix}(S)\)</span>. Since a string <i>s</i> uniquely identifies a node in <i>T</i> and vice versa, we will sometimes use the symbol <span class="mathjax-tex">\(q_s\)</span> for states and <i>s</i> for strings interchangeably. Each node <span class="mathjax-tex">\(q_s\)</span> is associated with a <i>transition frequency function</i> 
                           <span class="mathjax-tex">\(f(q_s,\sigma )\)</span>, which encodes the number of strings with prefix <span class="mathjax-tex">\(s\sigma \)</span> in <span class="mathjax-tex">\(S\)</span>; we define <span class="mathjax-tex">\(f (s,\cdot ) = \sum \nolimits _{\sigma \in \varSigma ^{\text {out}}} {f (s, \sigma )}\)</span>. The successor state of <span class="mathjax-tex">\(q_s\)</span> given <span class="mathjax-tex">\(\sigma \)</span> is denoted <span class="mathjax-tex">\(succ (s,\sigma ) = s\sigma \)</span>, and the set of all successor states of <span class="mathjax-tex">\(q_s\)</span> is denoted <span class="mathjax-tex">\(succs (s)\)</span>. By normalizing the transition frequency functions <span class="mathjax-tex">\(f (s, \sigma )\)</span> by <span class="mathjax-tex">\(f (s, \cdot )\)</span> we obtain the <i>transition probability function</i>s <span class="mathjax-tex">\(\delta (s, \sigma )\)</span>. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig3">3</a>a shows an FPTA constructed from observation sequences generated by the DMC in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig2">2</a>b. The root of the tree is labeled with the symbol <i>A</i> and associated with the frequencies <span class="mathjax-tex">\(f(A,B)=15\)</span> and <span class="mathjax-tex">\(f(A,A)=7\)</span>. The frequency functions indicate that in the dataset there are 15 strings with prefix <i>AB</i>, 7 strings with prefix <i>AA</i> and there are 22 strings with prefix <i>A</i>, i.e., <span class="mathjax-tex">\(f(A,\cdot )=22\)</span>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="Fig. 3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig3_HTML.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig3_HTML.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Examples of frequency prefix tree acceptors</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The <i>I/O frequency prefix tree acceptor</i> (IOFPTA) is an extension of the FPTA for representing a set of I/O strings <span class="mathjax-tex">\(S_{io}\)</span>. In addition to the output symbols <span class="mathjax-tex">\(\sigma \in \varSigma ^{\text {out}} \)</span> attached to the nodes, each edge is labeled with an input action <span class="mathjax-tex">\(\alpha \in \varSigma ^{\text {in}} \)</span>. Similar to FPTAs, a string from the root to a node <span class="mathjax-tex">\(q_{\pi }\)</span> corresponds to an I/O string <span class="mathjax-tex">\(\pi \in \mathrm {prefix}(S_{io})\)</span>. A <i>transition frequency function</i> 
                           <span class="mathjax-tex">\(f (\pi ,\alpha ,\sigma )\)</span> is associated with the node <span class="mathjax-tex">\(q_{\pi }\)</span>, to encode the number of strings with the prefix <span class="mathjax-tex">\(\pi \alpha \sigma \)</span> in <span class="mathjax-tex">\(S_{io}\)</span>. As for FPTAs, we let <span class="mathjax-tex">\(f (\pi , \alpha , \cdot ) = \sum \nolimits _{\sigma \in \varSigma ^{\text {out}}} {f (\pi ,\alpha ,\sigma )}\)</span>.</p><p>By normalizing the transition frequency functions we obtain the <i>transition probability functions</i> 
                           <span class="mathjax-tex">\(\delta (\pi ,\alpha ,\sigma )\)</span> for the IOFPTA. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig3">3</a>b shows an IOFPTA constructed from I/O strings obtained from the DMDP in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig1">1</a>a.</p><p>A <i>timed frequency prefix tree acceptor</i> (TFPTA) represents a set of timed strings <span class="mathjax-tex">\(S_t\)</span>. A TFPTA is structurally identical to an FPTA and can be obtained from the skeleton of <span class="mathjax-tex">\(S_t\)</span>. Thus, the path from the root to a node <span class="mathjax-tex">\(q_s\)</span> in an TFPTA corresponds to a prefix of the skeleton of a timed string in <span class="mathjax-tex">\(S_t\)</span>, i.e., <span class="mathjax-tex">\(s\in \mathrm {prefix}(\mathbb S(S_t))\)</span>. The transition frequency function associated with a node <span class="mathjax-tex">\(q_s\)</span> is defined as for FPTAs by only considering the skeleton of <span class="mathjax-tex">\(S_t\)</span>. In addition to the <i>transition frequency function</i>, each node <span class="mathjax-tex">\(q_s\)</span> is also associated with an <i>average empirical exit time</i> 
                           <span class="mathjax-tex">\(\hat{t}(s)\)</span> (which is approximately the inverse of the exit-rate):</p><div id="Equ30" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \hat{t}(s)=\frac{1}{f(s, \cdot )} \cdot \sum \nolimits _{\rho \in X} \rho \langle |s| \rangle , \end{aligned}$$</span></div></div><p>where <span class="mathjax-tex">\(X= \{\rho \mid s\in \mathrm {prefix}(\mathbb S(\rho )) , \rho \in S_t\}\)</span> and |<i>s</i>| is the number of symbols in the string <i>s</i>. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig3">3</a>c illustrates an TFPTA constructed from strings sampled from the DCTMC in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig2">2</a>. Each node in the tree is associated with an average exit time, i.e., the time spent in the state before observing the next symbol. With the symbol <i>A</i> occurring 22 times as prefix of a string, we get an average exit time of 1.2 time units for the root node and the estimation of the exit rate is therefore <span class="mathjax-tex">\(\frac{1}{1.2}\approx 0.83\)</span>.</p><h3 class="c-article__sub-heading" id="Sec10">
                  <span class="u-small-caps">Alergia</span>
                </h3><p>In this section we first sketch the main flow of the <span class="u-small-caps">Alergia</span> algorithm for learning DMCs as a modified version of the algorithm presented in Carrasco and Oncina (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Carrasco, R., &amp; Oncina, J. (1994). Learning stochastic regular grammars by means of a state merging method. In Proceedings of the international colloquium on grammatical inference and applications (ICGIA 1994), pp. 139–152." href="/article/10.1007/s10994-016-5565-9#ref-CR10" id="ref-link-section-d52740e14939">1994</a>) and Higuera (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Higuera, Cd. (2010). Grammatical inference: Learning automata and grammars. Cambridge: Cambridge University Press." href="/article/10.1007/s10994-016-5565-9#ref-CR30" id="ref-link-section-d52740e14942">2010</a>). Afterwards we adapt the general learning algorithm to the different stochastic system models considered in this paper.</p><p>The <span class="u-small-caps">Alergia</span> algorithm is initialized by creating two identical FPTAs <i>T</i> and <i>A</i> as representations of the dataset <span class="mathjax-tex">\(S\)</span> (line <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec10">2</a> of Algorithm 1). The FPTA <i>T</i> is kept as a data representation from which relevant statistics are retrieved during the execution of the algorithm. The FPTA <i>A</i> is iteratively transformed by merging nodes that have passed a statistical <i>compatibility</i> test. Observe that an FPTA (with normalized transition functions) is a DMC, and so is any model obtained by iteratively merging nodes. Similar properties hold for IOFPTAs and TFPTAs.</p><p>All compatibility tests are based on <i>T</i> to ensure the statistical validity of the compatibility tests that are performed. In some accounts of the <span class="u-small-caps">Alergia</span> algorithm it is suggested to join samples associated with different nodes of the original FPTA when the nodes are merged (Carrasco and Oncina <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Carrasco, R., &amp; Oncina, J. (1994). Learning stochastic regular grammars by means of a state merging method. In Proceedings of the international colloquium on grammatical inference and applications (ICGIA 1994), pp. 139–152." href="/article/10.1007/s10994-016-5565-9#ref-CR10" id="ref-link-section-d52740e14998">1994</a>), and to base subsequent tests on these joined samples. While intuitively beneficial, since more data becomes available for testing, this latter approach invalidates some statistical arguments for the overall consistency of the algorithm: if <span class="mathjax-tex">\(S_1\)</span> and <span class="mathjax-tex">\(S_2\)</span> are two sets of samples that each are drawn by independent sampling from the same distribution, then the union <span class="mathjax-tex">\(S_1\cup S_2\)</span> no longer is a set of independent samples, if the union is performed conditional on the fact that <span class="mathjax-tex">\(S_1\)</span> and <span class="mathjax-tex">\(S_2\)</span> have passed a statistical test of compatibility. Since the assumption of independent sampling underlies all statistical tests we are using, such a join, therefore, makes a theoretical analysis of the resulting procedure very challenging. In order to maintain a strong match between the algorithmic solution, and the theoretical analysis we can provide, we generally do not join the associated samples when merging nodes. However, we have also conducted a few experiments comparing the performance of the algorithm with and without joining of the samples. It turned out that the differences in the constructed models and the runtime were only minor (cf. Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec17">5.1</a>).</p><p>Following the terminology of Higuera (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Higuera, Cd. (2010). Grammatical inference: Learning automata and grammars. Cambridge: Cambridge University Press." href="/article/10.1007/s10994-016-5565-9#ref-CR30" id="ref-link-section-d52740e15140">2010</a>), Algorithm 1 maintains two sets of nodes: <span class="u-small-caps">RED</span> nodes, which have already been determined as representative nodes and will be included in the final output model, and <span class="u-small-caps">BLUE</span> nodes which are scheduled for testing. Initially, <span class="u-small-caps">RED</span> contains only the initial node <span class="mathjax-tex">\(q^s_A\)</span> while <span class="u-small-caps">BLUE</span> contains the immediate successor nodes of the initial node. When performing the outer loop of the algorithm, the lexicographically minimal node <span class="mathjax-tex">\(q_b\)</span> in <span class="u-small-caps">BLUE</span> will be chosen. If there exists a node <span class="mathjax-tex">\(q_r\)</span> in <span class="u-small-caps">RED</span> which is compatible with <span class="mathjax-tex">\(q_b\)</span>, then <span class="mathjax-tex">\(q_b\)</span> and its successor nodes are merged to <span class="mathjax-tex">\(q_r\)</span> and the corresponding successor nodes of <span class="mathjax-tex">\(q_r\)</span>, respectively (line <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec10">10</a>). If <span class="mathjax-tex">\(q_b\)</span> is not compatible with any state in <span class="u-small-caps">RED</span>, it will be included in <span class="u-small-caps">RED</span> (line <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec10">15</a>). At the end of each iteration, <span class="u-small-caps">BLUE</span> will be updated with the immediate successor nodes of <span class="u-small-caps">RED</span> that are not contained in <span class="u-small-caps">RED</span> (line <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec10">17</a>). After merging all compatible nodes in the tree, the frequencies in <i>A</i> are normalized (line <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec10">18</a> of Algorithm 1).</p><p>In order to adapt the <span class="u-small-caps">Alergia</span> algorithm to the different model classes presented in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec4">2</a>, we only need to tailor the compatibility test (line <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec10">9</a>) and the merge operator (line <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec10">10</a>) to each specific model class. In the following section, the required model-specific compatibility tests and merge operators are presented.</p><div class="c-article-section__figure c-article-section__figure--no-border" data-test="figure" data-container-section="figure" id="figure-a"><figure><div class="c-article-section__figure-content" id="Figa"><div class="c-article-section__figure-item"><div class="c-article-section__figure-content"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Figa_HTML.gif?as=webp"></source><img aria-describedby="figure-a-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Figa_HTML.gif" alt="figurea" loading="lazy" /></picture></div></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-a-desc"></div></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec11">Local compatibility test and merge</h3><p>Formally, two nodes <span class="mathjax-tex">\(q_r\)</span> and <span class="mathjax-tex">\(q_b\)</span> in an FPTA <i>T</i> are said to be <span class="mathjax-tex">\(\epsilon \)</span>-<i>compatible</i> (<span class="mathjax-tex">\(\epsilon &gt;0\)</span>), if the following properties are satisfied:</p><ol class="u-list-style-none">
                    <li>
                      <span class="u-custom-list-number">1.</span>
                      
                        <p>
                                       <span class="mathjax-tex">\(L(q_r)=L(q_b)\)</span>,</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">2.</span>
                      
                        <p>
                                       <span class="mathjax-tex">\(\text {LocalCompatible }(q_r,q_b, \epsilon )\)</span> is TRUE, and</p>
                      
                    </li>
                    <li>
                      <span class="u-custom-list-number">3.</span>
                      
                        <p>the successor nodes of <span class="mathjax-tex">\(q_r\)</span> and <span class="mathjax-tex">\(q_b\)</span> are pair-wise <span class="mathjax-tex">\(\epsilon \)</span>-<i>compatible</i>.</p>
                      
                    </li>
                  </ol>
                           <div class="c-article-section__figure c-article-section__figure--no-border" data-test="figure" data-container-section="figure" id="figure-b"><figure><div class="c-article-section__figure-content" id="Figb"><div class="c-article-section__figure-item"><div class="c-article-section__figure-content"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Figb_HTML.gif?as=webp"></source><img aria-describedby="figure-b-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Figb_HTML.gif" alt="figureb" loading="lazy" /></picture></div></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-b-desc"></div></div></figure></div>
                        <p>Algorithm 2 illustrates the <i>compatibility</i> test. Condition (1) requires the two nodes to have the same label (line <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec11">1</a>). Condition (2) is model-specific and defines the local compatibility test for <span class="mathjax-tex">\(q_r\)</span> and <span class="mathjax-tex">\(q_b\)</span> (line <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec11">4</a>). The last condition requires the compatibility to be recursively satisfied for every pair of successor nodes of <span class="mathjax-tex">\(q_r\)</span> and <span class="mathjax-tex">\(q_b\)</span> (line <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec11">10</a>). Note that only pairs of successor nodes reached by the same output symbol (as well as the same input symbol in the IOFPTA case) are tested. For example, <span class="mathjax-tex">\(q_r'\)</span> and <span class="mathjax-tex">\(q_b'\)</span> are being tested only if <span class="mathjax-tex">\(q_r' = succ(q_r, \sigma )\)</span> and <span class="mathjax-tex">\(q_b' = succ(q_b, \sigma )\)</span> (in an IOFPTA, <span class="mathjax-tex">\(q_r'\)</span> and <span class="mathjax-tex">\(q_b'\)</span> are determined as <span class="mathjax-tex">\(q_r' = succ(q_r, \alpha , \sigma )\)</span> and <span class="mathjax-tex">\(q_b' = succ(q_b, \alpha , \sigma )\)</span>).</p><p>The compatibility test depends on a parameter <span class="mathjax-tex">\(\epsilon \)</span> that controls the severity of the <i>LocalCompatible</i> tests, which are defined so that smaller values of <span class="mathjax-tex">\(\epsilon \)</span> will make <i>LocalCompatible</i> return <i>false</i> less often. In most cases, <span class="mathjax-tex">\(\epsilon \)</span> directly translates to the significance level of a statistical test that is the core of the <i>LocalCompatible</i> test.</p><p>In the following sections, we start by specifying the <i>local compatibility</i> test and <i>merge</i> procedure for FPTAs, and afterwards extend the specifications to IOFPTAs and TFPTAs. For FPTAs and IOFPTAs, the local compatibility test depends only on the local transition frequency functions, whereas for TFPTAs we also need to take the estimated exit rates into account. Analogous considerations apply for the <i>merge</i> procedure.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec12">Local compatibility test and merge in FPTAs</h4><p>Given two nodes <span class="mathjax-tex">\(q_r\)</span> and <span class="mathjax-tex">\(q_b\)</span> in an FPTA, their <i>local compatibility</i> requires that the difference between the next symbol distributions defined at two nodes is bounded. Specifically, we check for local compatibility (Line <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec11">4</a> in Algorithm 2) by employing the <i>Hoeffding</i> test (see Algorithm 3) realized by the call <span class="mathjax-tex">\(\text {Hoeffding }(f(q_r,\sigma ), f(q_r, \cdot ),f(q_b,\sigma ),f(q_b,\cdot ),\epsilon )\)</span>, for all <span class="mathjax-tex">\(\sigma \in \varSigma ^{\text {out}} \)</span>. Line 4 of Algorithm 3 is a statistical test for the identity of the transition probabilities at the states <span class="mathjax-tex">\(q_r\)</span> and <span class="mathjax-tex">\(q_b\)</span> to their <span class="mathjax-tex">\(\sigma \)</span>-successors (Carrasco and Oncina <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Carrasco, R. C., &amp; Oncina, J. (1999). Learning deterministic regular grammars from stochastic samples in polynomial time. Journal of Theoretial Informatics and Applications, 33(1), 1–20." href="/article/10.1007/s10994-016-5565-9#ref-CR11" id="ref-link-section-d52740e16610">1999</a>). The actual statistical level of significance of this test is given by <span class="mathjax-tex">\(2\epsilon \)</span> rather than <span class="mathjax-tex">\(\epsilon \)</span> itself. However, for the asymptotic consistency analysis that we will be concerned with in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec15">4</a> and “Consistency of Alergia-style Learning” of Appendix the constant factor 2 is immaterial, and we will a little loosely refer to <span class="mathjax-tex">\(\epsilon \)</span> as the significance level of the Hoeffding compatibility test. Also observe that the feasible range of the <span class="mathjax-tex">\(\epsilon \)</span> parameter is (0, 2]. At <span class="mathjax-tex">\(\epsilon =2\)</span> line 4 will always return <i>false</i>.</p><div class="c-article-section__figure c-article-section__figure--no-border" data-test="figure" data-container-section="figure" id="figure-c"><figure><div class="c-article-section__figure-content" id="Figc"><div class="c-article-section__figure-item"><div class="c-article-section__figure-content"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Figc_HTML.gif?as=webp"></source><img aria-describedby="figure-c-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Figc_HTML.gif" alt="figurec" loading="lazy" /></picture></div></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-c-desc"></div></div></figure></div>
                           <p>If two nodes <span class="mathjax-tex">\(q_r\)</span> and <span class="mathjax-tex">\(q_b\)</span> are <i>compatible</i>, <span class="mathjax-tex">\(q_b\)</span> is merged to <span class="mathjax-tex">\(q_r\)</span>. The <i>merge</i> procedure (line <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec10">10</a> of Algorithm 1) follows the same steps as described in Higuera (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Higuera, Cd. (2010). Grammatical inference: Learning automata and grammars. Cambridge: Cambridge University Press." href="/article/10.1007/s10994-016-5565-9#ref-CR30" id="ref-link-section-d52740e16850">2010</a>). Firstly, the (unique) transition leading to <span class="mathjax-tex">\(q_b\)</span> from its predecessor node <span class="mathjax-tex">\(q'\)</span> (<span class="mathjax-tex">\(f^A(q', q_b)&gt;0\)</span>) is re-directed to <span class="mathjax-tex">\(q_r\)</span> by setting <span class="mathjax-tex">\(f^A(q',q_r) \leftarrow f^A(q', q_b)\)</span> and <span class="mathjax-tex">\(f^A(q', q_b)=0\)</span>. Secondly, the successor nodes of <span class="mathjax-tex">\(q_b\)</span> are recursively folded to the corresponding successor nodes of <span class="mathjax-tex">\(q_r\)</span> and the associated frequencies are updated. The complete merge procedure is illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig4">4</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4" data-title="Fig. 4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig4_HTML.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig4_HTML.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Merge node <span class="mathjax-tex">\(q_b\)</span> (shadowed) to node <span class="mathjax-tex">\(q_r\)</span> (shadowed and double circled) in the FPTA. <b>a</b> The transition from <span class="mathjax-tex">\(q'\)</span> to <span class="mathjax-tex">\(q_b\)</span> is redirected to <span class="mathjax-tex">\(q_r\)</span>. <b>b</b> Node <span class="mathjax-tex">\(q_b\)</span> and its two outgoing transitions are folded to <span class="mathjax-tex">\(q_r\)</span> and the frequencies are updated: <span class="mathjax-tex">\(f(q_r,B)=f(q_r,B)+f(q_b,B)=25\)</span> and <span class="mathjax-tex">\(f(q_r,C)=f(q_r,C)+f(q_b,C)=11\)</span>. <b>c</b> The resulting FPTA obtained after recursively folding the successor nodes of <span class="mathjax-tex">\(q_r\)</span> and <span class="mathjax-tex">\(q_b\)</span>
                                       </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec13">Local compatibility test and merge in IOFPTAs</h4><p>In an IOFPTA, the transition frequency function on node <i>q</i>, <span class="mathjax-tex">\(f(q_r, \alpha , q')\)</span>, is also conditioned on the input action <span class="mathjax-tex">\(\alpha \)</span>. Thus, in order to adapt the local compatibility test to IOFPTAs, we compare the transition probability distribution defined for each input action. Specifically, given two nodes <span class="mathjax-tex">\(q_r\)</span> and <span class="mathjax-tex">\(q_b\)</span>, the <i>Hoeffding</i> test, realized by the procedure call <span class="mathjax-tex">\(\text {Hoeffding }(f(q_r, \alpha , \sigma ), f(q_r,\alpha , \cdot ), f(q_b,\alpha , \sigma ), f(q_b,\alpha ,\cdot ), \epsilon )\)</span>, is conducted for all <span class="mathjax-tex">\(\sigma \in \varSigma ^{\text {out}} \)</span> conditioned on <span class="mathjax-tex">\(\alpha \in \varSigma ^{\text {in}} \)</span>. Similarly, the test is performed iteratively for all input actions at two given nodes.</p><p>The merge procedure for two compatible nodes in IOFPTA is similar to the one in FPTAs. An example is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig5">5</a>. Observe that the frequencies are aggregated along the different input actions.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5" data-title="Fig. 5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Node <span class="mathjax-tex">\(q_b\)</span> is merged to node <span class="mathjax-tex">\(q_r\)</span> in the IOFPTA. <b>a</b> The transition from <span class="mathjax-tex">\(q'\)</span> to <span class="mathjax-tex">\(q_b\)</span> is redirected to <span class="mathjax-tex">\(q_r\)</span>. <b>b</b> Successor nodes of <span class="mathjax-tex">\(q_b\)</span> are locally folded along input actions to <span class="mathjax-tex">\(q_r\)</span>. <b>c</b> The IOFPTA resulting from recursively folding the subtrees rooted at <span class="mathjax-tex">\(q_r\)</span> and <span class="mathjax-tex">\(q_b\)</span>
                                       </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec14">Local compatibility test and merge in TFPTAs</h4><p>The nodes in a TFPTA are associated with transition frequency functions and exit-rates encoding the local transition times. We therefore define two nodes <span class="mathjax-tex">\(q_r\)</span> and <span class="mathjax-tex">\(q_b\)</span> in a TFPTA to be compatible if the transition probability distributions over their successor nodes as well as their exit-rates are compatible. The compatibility of transition distributions for two nodes are, as for MCs, tested by the Hoeffding test (Algorithm 3). The compatibility test of the exit rates follows the procedure described in Sen et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004a" title="Sen, K., Viswanathan, M., &amp; Agha, G. (2004a). Learning continuous time Markov chains from sample executions. In Proceedings of international conference on quantitative evaluation of systems (QEST), pp. 146–155." href="/article/10.1007/s10994-016-5565-9#ref-CR49" id="ref-link-section-d52740e18277">2004a</a>), which is essentially the <i>F</i>-test originally introduced in Cox (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1953" title="Cox, D. R. (1953). Some simple approximate tests for Poisson variates. Biometrika, 40(3/4), 354–360." href="/article/10.1007/s10994-016-5565-9#ref-CR19" id="ref-link-section-d52740e18283">1953</a>). The test is based on the ratio <span class="mathjax-tex">\({{\hat{t}_r }}/{{\hat{t}_b }}\)</span> of the average empirical time delays at <span class="mathjax-tex">\(q_r\)</span> and <span class="mathjax-tex">\(q_b\)</span>. The precise test criterion is given in Algorithm 4.</p><div class="c-article-section__figure c-article-section__figure--no-border" data-test="figure" data-container-section="figure" id="figure-d"><figure><div class="c-article-section__figure-content" id="Figd"><div class="c-article-section__figure-item"><div class="c-article-section__figure-content"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Figd_HTML.gif?as=webp"></source><img aria-describedby="figure-d-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Figd_HTML.gif" alt="figured" loading="lazy" /></picture></div></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-d-desc"></div></div></figure></div>
                           </div></div></section><section aria-labelledby="Sec15" data-title="Consistency and convergence analysis"><div class="c-article-section" id="Sec15-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec15">Consistency and convergence analysis</h2><div class="c-article-section__content" id="Sec15-content"><p>In this section we investigate theoretical convergence results for <span class="u-small-caps">Alergia</span> learning. These results consist of two components: first, we establish that in the large sample limit the learning algorithm will correctly identify the structure of a data generating model (modulo equivalence of the states). This component is related to previous convergence results (Carrasco and Oncina <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Carrasco, R. C., &amp; Oncina, J. (1999). Learning deterministic regular grammars from stochastic samples in polynomial time. Journal of Theoretial Informatics and Applications, 33(1), 1–20." href="/article/10.1007/s10994-016-5565-9#ref-CR11" id="ref-link-section-d52740e18405">1999</a>; de la Higuera and Thollard <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="de la Higuera, C., &amp; Thollard, F. (2000). Identification in the limit with probability one of stochastic deterministic finite automata. In Proceedings of the international colloquium on grammatical inference: Algorithms and application (ICGI 2000), pp. 141–156." href="/article/10.1007/s10994-016-5565-9#ref-CR21" id="ref-link-section-d52740e18408">2000</a>; Sen et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004a" title="Sen, K., Viswanathan, M., &amp; Agha, G. (2004a). Learning continuous time Markov chains from sample executions. In Proceedings of international conference on quantitative evaluation of systems (QEST), pp. 146–155." href="/article/10.1007/s10994-016-5565-9#ref-CR49" id="ref-link-section-d52740e18411">2004a</a>), and we provide the main technical results in “Consistency of Alergia-style Learning” of Appendix. The second component is to establish that identification of the structure together with convergence of the estimates for the probabilistic parameters of the models (transition probabilities and exit rates) guarantees convergence of the probabilities for model properties expressed in our formal specification languages.</p><p>Our analysis, thus, focuses on exact identification in the limit, and thereby differs from <i>probably approximately correct (PAC)</i> learning results, such as presented in Ron et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1996" title="Ron, D., Singer, Y., &amp; Tishby, N. (1996). The power of amnesia: Learning probabilistic automata with variable memory length. Machine Learning, 25(2–3), 117–149." href="/article/10.1007/s10994-016-5565-9#ref-CR46" id="ref-link-section-d52740e18420">1996</a>) and Clark and Thollard (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Clark, A., &amp; Thollard, F. (2004). PAC-learnability of probabilistic deterministic finite state automata. Journal of Machine Learning Research, 5, 473–497." href="/article/10.1007/s10994-016-5565-9#ref-CR16" id="ref-link-section-d52740e18423">2004</a>). PAC learning results are stronger than identification in the limit results in that they provide bounds on the sample complexity required to learn a good approximation of the true model. However, a PAC learnability analysis first requires the specification of a suitable metric to measure the quality of approximation. Existing PAC learning approaches for probabilistic automata are based on a semantics for the automata as defining a probability distribution over <span class="mathjax-tex">\(\varSigma ^*\)</span>. In that case, the Kullback-Leibler divergence between the distributions defined by the true and the approximate model is a canonical measure of approximation error.</p><p>Being interested in the probability of LTL properties, we, on the other hand, have to see automata as defining distributions on <span class="mathjax-tex">\(\varSigma ^{\omega }\)</span>. The Kullback–Leibler divergence between the distributions defined on <span class="mathjax-tex">\(\varSigma ^{\omega }\)</span> is not a suitable measure for approximation quality, since it will almost always be infinite (even in the case where the approximate model is structurally identical to the true one, and differs with respect to transition probabilities only by an arbitrarily small <span class="mathjax-tex">\(\epsilon &gt; 0\)</span>). Within the verification literature, various versions of the <i>bisimulation distance</i> are a popular measure for approximate equivalence between system models (Desharnais et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Desharnais, J., Gupta, V., Jagadeesan, R., &amp; Panangaden, P. (1999). Metrics for labeled Markov systems. In Proceedings of international conference on concurrency theory (CONCUR), pp. 258–273." href="/article/10.1007/s10994-016-5565-9#ref-CR22" id="ref-link-section-d52740e18536">1999</a>; Breugel and Worrell <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="van Breugel, F., &amp; Worrell, J. (2005). A behavioural pseudometric for probabilistic transition system. Theoretical Computer Science, 331, 115–142." href="/article/10.1007/s10994-016-5565-9#ref-CR54" id="ref-link-section-d52740e18540">2005</a>). However, it turns out that these metrics suffer from the same problem as the Kullback-Leibler distance, and fail to measure approximation quality as a smooth function of <span class="mathjax-tex">\(\epsilon \)</span>-errors in the estimates of transition probabilities. These and other candidate measures for approximate equivalence of automata defining distributions on <span class="mathjax-tex">\(\varSigma ^{\omega }\)</span> are investigated in detail in Jaeger et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Jaeger, M., Mao, H., Larsen, K. G., &amp; Mardare, R. (2014). Continuity properties of distances for Markov processes. In Proceedings of QEST 2014, LNCS, Vol. 8657, pp. 297–312." href="/article/10.1007/s10994-016-5565-9#ref-CR31" id="ref-link-section-d52740e18589">2014</a>). A number of counterexamples and impossibility results derived in Jaeger et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Jaeger, M., Mao, H., Larsen, K. G., &amp; Mardare, R. (2014). Continuity properties of distances for Markov processes. In Proceedings of QEST 2014, LNCS, Vol. 8657, pp. 297–312." href="/article/10.1007/s10994-016-5565-9#ref-CR31" id="ref-link-section-d52740e18592">2014</a>) indicate that there exist fundamental obstacles to defining measures for approximation error that simultaneously satisfy the two desiderata: (a) to provide a basis on which PAC learnability results could be derived, and (b) small approximation errors between models should also entail bounds on the differences between the probabilities of LTL properties in the models (a desideratum called “LTL continuity” in Jaeger et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Jaeger, M., Mao, H., Larsen, K. G., &amp; Mardare, R. (2014). Continuity properties of distances for Markov processes. In Proceedings of QEST 2014, LNCS, Vol. 8657, pp. 297–312." href="/article/10.1007/s10994-016-5565-9#ref-CR31" id="ref-link-section-d52740e18595">2014</a>)).</p><p>For the analysis of the identification of the structure, we now begin by formally defining the relevant equivalence relation of states. In the following, for any automaton <span class="mathjax-tex">\({\mathcal {M}}\)</span> and state <i>q</i> of <span class="mathjax-tex">\({\mathcal {M}}\)</span>, we denote with <span class="mathjax-tex">\(({\mathcal {M}},q)\)</span> the automaton obtained by (re-)defining <i>q</i> as the start state of <span class="mathjax-tex">\({\mathcal {M}}\)</span>.</p>
                <h3 class="c-article__sub-heading" id="FPar14">Definition 10</h3>
                <p>Let <span class="mathjax-tex">\({\mathcal {M}}\)</span> be a DLMC or DCTMC. States <span class="mathjax-tex">\(q,q'\)</span> of <span class="mathjax-tex">\({\mathcal {M}}\)</span> are equivalent, written <span class="mathjax-tex">\(q\sim q'\)</span>, if <span class="mathjax-tex">\(P_{\tiny (\mathcal {M},q)}=P_{\tiny (\mathcal {M},q')}\)</span>. States <span class="mathjax-tex">\(q,q'\)</span> of a DMDP <span class="mathjax-tex">\({\mathcal {M}}\)</span> are equivalent, if for all schedulers <span class="mathjax-tex">\(\mathfrak {S}\)</span> of <span class="mathjax-tex">\(({\mathcal {M}},q)\)</span> there exists a scheduler <span class="mathjax-tex">\(\mathfrak {S}'\)</span> of <span class="mathjax-tex">\(({\mathcal {M}},q')\)</span>, such that <span class="mathjax-tex">\(P_{{\tiny (\mathcal {M},q)},\mathfrak {S}}=P_{{\tiny (\mathcal {M},q')},\mathfrak {S}'}\)</span>, and vice-versa.</p>
              <p>When <span class="mathjax-tex">\(q\sim q'\)</span>, then also <span class="mathjax-tex">\(\delta (q,\alpha ,\sigma )\sim \delta (q',\alpha ,\sigma )\)</span> for all <span class="mathjax-tex">\((\alpha ,\sigma )\in \varSigma ^{\text {in}} \times \varSigma ^{\text {out}} \)</span>. Therefore, <span class="mathjax-tex">\(\delta \)</span> is also well-defined on <span class="mathjax-tex">\((Q/\sim ) \times \varSigma ^{\text {in}} \times (Q/\sim )\)</span>, and we thereby obtain the quotient automaton <span class="mathjax-tex">\({\mathcal {M}}/\sim \)</span> whose states are the <span class="mathjax-tex">\(\sim \)</span>-equivalence classes of <span class="mathjax-tex">\({\mathcal {M}}\)</span>.</p><p>Next, we formally define the structure of an automaton.</p>
                <h3 class="c-article__sub-heading" id="FPar15">Definition 11</h3>
                <p>Let <span class="mathjax-tex">\({\mathcal {M}}\)</span> be a DLMC, DMDP, or DCTMC. The <i>structure</i> of <span class="mathjax-tex">\({\mathcal {M}}\)</span> is defined as <span class="mathjax-tex">\(\widehat{\mathcal {M}}:=\langle Q, \varSigma ^{\text {in}}, \varSigma ^{\text {out}}, q^s, \hat{\delta }, L\rangle \)</span>, where <span class="mathjax-tex">\(\hat{\delta } \subseteq Q\times \varSigma ^{\text {in}} \times Q\)</span> is the transition relation defined by <span class="mathjax-tex">\((q,\alpha ,q')\in \hat{\delta } \Leftrightarrow \delta (q,\alpha ,q')&gt;0\)</span>.</p>
              <p>For DLMCs and DCTMCs the <span class="mathjax-tex">\(\varSigma ^{\text {in}} \)</span> component should be regarded as vacuous in the preceding definition.</p><p>The first component of the convergence result will be the identification in the limit of <span class="mathjax-tex">\(\widehat{ {\mathcal {M}}/\sim }\)</span>. Before we can state that result, however, we have to consider the question of how training data for the learner is assumed to be generated. Since our automaton models are generative models for infinite sequences, one cannot simply assume that the training data consists of sampled runs of an automaton. All we can observe (and all that <span class="u-small-caps">Alergia</span> will accept) are finite initial segments of such runs. Thus, in the data-generation process, one has to assume that there is an external process that decides at what point the generation of a sequence is terminated. Furthermore, in the case of DMDP learning, an external scheduler is required to generate inputs. Both these external components must satisfy certain conditions, so that the generated data is rich enough to contain sufficiently many sampled transitions from all states and under all inputs. At the same time, the significance level <span class="mathjax-tex">\(\epsilon \)</span> for <span class="u-small-caps">Alergia</span> must be chosen so that certain correctness guarantees for the compatibility tests performed during the execution of the algorithm are obtained. The sampling mechanism for finite sequences and the choice of significance levels for the compatibility tests are interrelated. The details of this relationship are elaborated in “Appendix”. For the present section, we only consider the case where data is generated as follows:</p><ul class="u-list-style-dash">
                  <li>
                    <p>The length of the observed sequence is randomly determined by a geometric distribution with parameter <span class="mathjax-tex">\(\lambda \)</span>. This is equivalent to generating strings with an automaton where at each state the generating process terminates with probability <span class="mathjax-tex">\(\lambda \)</span>.</p>
                  </li>
                  <li>
                    <p>Inputs are generated by a scheduler that always chooses inputs uniformly at random.</p>
                  </li>
                </ul><p>We refer to this procedure as <i>geometric sampling</i>. It defines a probability distribution <span class="mathjax-tex">\(P^s\)</span> on <span class="mathjax-tex">\((\varSigma ^*)^{\omega }\)</span>, where depending on the underlying automaton, <span class="mathjax-tex">\(\varSigma \)</span> is <span class="mathjax-tex">\(\varSigma ^{\text {out}} \)</span> (for DLMCs), <span class="mathjax-tex">\(\varSigma ^{\text {in}} \times \varSigma ^{\text {out}} \)</span> (for DMDPs), or <span class="mathjax-tex">\(\varSigma ^{\text {out}} \times \mathbb R_{&gt;0}\)</span> (for DCTMCs).</p>
                <h3 class="c-article__sub-heading" id="FPar16">Theorem 1</h3>
                <p>Let <span class="mathjax-tex">\({\mathcal {M}}\)</span> be a DLMC or DMDP. Let <span class="mathjax-tex">\(S\in (\varSigma ^*)^{\omega }\)</span> be generated by geometric sampling. Let <span class="mathjax-tex">\(\epsilon _N=1/N^r\)</span> for some <span class="mathjax-tex">\(r&gt;2\)</span>, and let <span class="mathjax-tex">\({\mathcal {M}}_N\)</span> be the model learned by <span class="u-small-caps">Alergia</span> from the first <i>N</i> strings in <i>S</i> using significance level <span class="mathjax-tex">\(\epsilon _N\)</span> in the compatibility tests. Then</p><div id="Equ1" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P^s(\widehat{{\mathcal {M}}_N} = \widehat{ {\mathcal {M}}/\sim }\ \text{ for } \text{ almost } \text{ all } N)=1. \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (1)
                </div></div><p>Let <span class="mathjax-tex">\({\mathcal {M}}\)</span> be a DCTMC, and <i>S</i> as above. There exist values <span class="mathjax-tex">\(\epsilon _N\)</span> with <span class="mathjax-tex">\(1/N\le \epsilon _N\le 1/\sqrt{N}\)</span>, such that for <span class="mathjax-tex">\({\mathcal {M}}_N\)</span> the model learned by <span class="u-small-caps">Alergia</span> from the first <i>N</i> strings in <i>S</i> using significance level <span class="mathjax-tex">\(\epsilon _N\)</span>:</p><div id="Equ2" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \lim _{N\rightarrow \infty } P^s(\widehat{{\mathcal {M}}_N} = \widehat{ {\mathcal {M}}/\sim })=1. \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (2)
                </div></div><p>(<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10994-016-5565-9#Equ2">2</a>) also holds when <span class="mathjax-tex">\({\mathcal {M}}\)</span> is a DLMC or DMDP, and <span class="mathjax-tex">\(\epsilon _N=1/N^r\)</span> for some <span class="mathjax-tex">\(r\ge 1\)</span>.</p>
              <p>The Theorem is a consequence of Theorem <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar34">4</a> and Lemmas <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar38">3</a> and <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar40">4</a> in “Consistency of Alergia-style Learning” of Appendix. The second part of the Theorem does not provide a complete description of the required sequence of significance levels <span class="mathjax-tex">\(\epsilon _N\)</span>, because the exact <span class="mathjax-tex">\(\epsilon _N\)</span> values (obtained in the proof of Lemma <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar40">4</a>) are defined in terms of the expected values of the size of the IOFPTA constructed from a sample of size <i>N</i>, and we can only bound this expected value, but do not have a closed-form expression as a function of <i>N</i>.</p><p>The reason we obtain somewhat stronger convergence guarantees for DLMCs and DMDPs than for DCTMCs lies in the fact that we have stronger results on the power of the Hoeffding test, than the F-test (cf. “Statistical Tests” of Appendix). It is an open problem whether almost sure convergence actually also holds for DCTMCs with the currently used F-test, or whether it could be obtained with a different, more powerful test for the compatibility of exponential distributions.</p><p>We are now ready to turn to the second component of our consistency analysis: ultimately, we are interested in whether the probabilities of properties expressed in the formal specification languages LTL and sub-CSL computed on the learned models converge to the probabilities defined by the true model. By Theorem <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar16">1</a> we know that the learned model will eventually have the correct structure, and the laws of large numbers also guarantee that the estimates of the transition probability and exit rate parameters will converge to the correct values. This, however, in general will not be enough to guarantee the convergence of the probabilities of complex system properties. As the following two Theorems show, however, we do obtain such a guarantee for properties expressed in LTL and sub-CSL. Since the sub-CSL case here is simpler, we consider it first.</p>
                <h3 class="c-article__sub-heading" id="FPar17">Theorem 2</h3>
                <p>Let <span class="mathjax-tex">\({\mathcal {M}}\)</span> be a DCTMC. Let <span class="mathjax-tex">\({\mathcal {M}}_N\)</span> as in Theorem <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar16">1</a>. For all sub-CSL properties <span class="mathjax-tex">\(\varphi \)</span>, and all <span class="mathjax-tex">\(\delta &gt; 0\)</span> then:</p><div id="Equ31" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \lim _{N\rightarrow \infty } P^s( \mid \! P_{{\mathcal {M}}_N}(\varphi ) - P_{{\mathcal {M}}}(\varphi ) \!\mid &gt; \delta ) = 0. \end{aligned}$$</span></div></div>
                        
              
                <h3 class="c-article__sub-heading" id="FPar18">Proof</h3>
                <p>By Theorem <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar16">1</a> we have that the probability that <span class="mathjax-tex">\({\mathcal {M}}_N\)</span> and <span class="mathjax-tex">\({\mathcal {M}}/\sim \)</span> have different structures is negligible in the limit. Conditional on <span class="mathjax-tex">\({\mathcal {M}}_N\)</span> and <span class="mathjax-tex">\({\mathcal {M}}/\sim \)</span> having the same structure, we also have by the law of large numbers that the parameters of <span class="mathjax-tex">\({\mathcal {M}}_N\)</span> converge to the parameters of <span class="mathjax-tex">\({\mathcal {M}}/\sim \)</span>. It is therefore sufficient to show that then also <span class="mathjax-tex">\(P_{{\mathcal {M}}_N}(\varphi )\)</span> converges to <span class="mathjax-tex">\(P_{{\mathcal {M}}/\sim }(\varphi )=P_{{\mathcal {M}}}(\varphi )\)</span>.</p>
                <p>All properties <span class="mathjax-tex">\(\varphi \)</span> expressible in sub-CSL are finite-horizon in the sense that there exists a fixed time limit <i>t</i>, such that whether a timed trace <span class="mathjax-tex">\(\rho =\sigma _0 t_0 \sigma _1 t_1 \ldots \)</span> satisfies <span class="mathjax-tex">\(\varphi \)</span> only depends on the prefix <span class="mathjax-tex">\(\rho [0:k]\)</span>, where <i>k</i> is such that <span class="mathjax-tex">\(t_0+\cdots + t_k&gt;t\)</span>. For a purely propositional formula <span class="mathjax-tex">\(\varPhi \)</span> this is <span class="mathjax-tex">\(t=0\)</span>, and for a formula containing a temporal operator with subscript <i>I</i>, <i>t</i> is the upper bound <span class="mathjax-tex">\(I^u\)</span> of <i>I</i>. The set of traces satisfying <span class="mathjax-tex">\(\varphi \)</span>, therefore, can be represented as a countable disjoint union of sets of paths that are slightly generalized forms of cylinder sets. For example, the set of paths satisfying <span class="mathjax-tex">\(\varPhi _1 \text{ U }_I \varPhi _2\)</span> is the union over all paths of the form <span class="mathjax-tex">\(q_0t_0\ldots q_{k-1}t_{k-1}q_k t_k\)</span> where <span class="mathjax-tex">\(q_0,\ldots ,q_{k-1}\)</span> satisfy <span class="mathjax-tex">\(\varPhi _1\)</span>, <span class="mathjax-tex">\(q_k\)</span> satisfies <span class="mathjax-tex">\(\varPhi _2\)</span>, and <span class="mathjax-tex">\(t_0+\cdots +t_{k}\in I\)</span>. The probabilities of such slightly generalized cylinder sets are a continuous function of the transition probability and exit rate parameters of <span class="mathjax-tex">\({\mathcal {M}}_N\)</span>, and therefore the convergence of these parameters guarantees the convergence of the probabilities of the generalized cylinder sets, and thereby the convergence of the probability of <span class="mathjax-tex">\(\varphi \)</span>. <span class="mathjax-tex">\(\square \)</span>
                        </p>
              <p>We now state the corresponding results for LTL and DMDPs, which subsumes the case of LTL and DLMCs</p>
                <h3 class="c-article__sub-heading" id="FPar19">Theorem 3</h3>
                <p>Let <span class="mathjax-tex">\({\mathcal {M}}\)</span> be a DMDP, and <span class="mathjax-tex">\({\mathcal {M}}_N\)</span> as in Theorem <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar16">1</a> using significance levels <span class="mathjax-tex">\(\epsilon _N=1/N^r\)</span>. If <span class="mathjax-tex">\(r&gt;2\)</span>, then for all LTL properties <span class="mathjax-tex">\(\varphi \)</span>:</p><div id="Equ3" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P^s( \lim _{N\rightarrow \infty }P^{\mathrm {max}}_{{\mathcal {M}}_N}(\varphi ) = P^{\mathrm {max}}_{{\mathcal {M}}}(\varphi ))= P^s( \lim _{N\rightarrow \infty }P^{\mathrm {min}}_{{\mathcal {M}}_N}(\varphi ) = P^{\mathrm {min}}_{{\mathcal {M}}}(\varphi ))=1. \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (3)
                </div></div><p>If <span class="mathjax-tex">\(r\ge 1\)</span>, then for all <span class="mathjax-tex">\(\delta &gt;0\)</span>:</p><div id="Equ4" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \lim _{N\rightarrow \infty } P^s(\mid \! P^{\mathrm {max}}_{{\mathcal {M}}_N}(\varphi ) - P^{\mathrm {max}}_{{\mathcal {M}}}(\varphi ) \!\mid&gt;\delta ) = \lim _{N\rightarrow \infty } P^s(\mid \! P^{\mathrm {min}}_{{\mathcal {M}}_N}(\varphi ) - P^{\mathrm {min}}_{{\mathcal {M}}}(\varphi ) \!\mid &gt;\delta ) =0 \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (4)
                </div></div>
                        
              <p>The following is a slightly generalized version of the proof that was given for DLMCs in Mao et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Mao, H., Chen, Y., Jaeger, M., Nielsen, T. D., Larsen, K. G., &amp; Nielsen, B. (2011). Learning probabilistic automata for model checking. In Proceedings of the international conference on quantitative evaluation of system (QEST 2011), pp. 111–120." href="/article/10.1007/s10994-016-5565-9#ref-CR39" id="ref-link-section-d52740e22680">2011</a>).</p>
                <h3 class="c-article__sub-heading" id="FPar20">Proof</h3>
                <p>Using the automata-theoretic approach to verification (Vardi <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1985" title="Vardi, M. Y. (1985). Automatic verification of probabilistic concurrent finite-state programs. In Proceedings of the IEEE symposium on foundations of computer science (FOCS), pp. 327–338." href="/article/10.1007/s10994-016-5565-9#ref-CR55" id="ref-link-section-d52740e22690">1985</a>; Courcoubetis and Yannakakis <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Courcoubetis, C., &amp; Yannakakis, M. (1995). The complexity of probabilistic verification. Journal of the ACM, 42(4), 857–907." href="/article/10.1007/s10994-016-5565-9#ref-CR18" id="ref-link-section-d52740e22693">1995</a>; Vardi <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Vardi, M. Y. (1999). Probabilistic linear-time model checking: An overview of the automata-theoretic approach. In Proceedings of the international AMAST workshop on formal methods for real-time and probabilstic systems (ARTS 1999), pp. 265–276." href="/article/10.1007/s10994-016-5565-9#ref-CR56" id="ref-link-section-d52740e22696">1999</a>; Baier and Katoen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Baier, C., &amp; Katoen, J. P. (2008). Principles of model checking. Cambridge, MA: The MIT Press." href="/article/10.1007/s10994-016-5565-9#ref-CR4" id="ref-link-section-d52740e22699">2008</a>, Section 10.6.4), the probabilities <span class="mathjax-tex">\(P^{\mathrm {max}}_{{\mathcal {M}}_N}(\varphi )\)</span> and <span class="mathjax-tex">\(P^{\mathrm {max}}_{{\mathcal {M}}}(\varphi )\)</span> can be identified with maximum reachability probabilities in the respective products of <span class="mathjax-tex">\({\mathcal {M}}_N\)</span> and <span class="mathjax-tex">\({\mathcal {M}}\)</span> with a Rabin automaton <i>B</i> representing <span class="mathjax-tex">\(\phi \)</span>. The maximum here is with respect to all possible memoryless schedulers on the product MDPs. Since <span class="mathjax-tex">\({\mathcal {M}}\)</span> and <span class="mathjax-tex">\({\mathcal {M}}/\sim \)</span> are equivalent with respect to LTL properties, one can consider the product of <span class="mathjax-tex">\({\mathcal {M}}/\sim \)</span> with <i>B</i> instead, which then by Theorem <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar16">1</a> for the case <span class="mathjax-tex">\(r&gt;2\)</span> will for almost all <i>N</i> have the same structure as the product of <span class="mathjax-tex">\({\mathcal {M}}_N\)</span> with <i>B</i>. Maximum reachability probabilities in the product MDPs are a continuous function of the transition probability parameters on the interior of the parameter space, i.e., for sequences of parameters <span class="mathjax-tex">\(p_N\rightarrow p\)</span> where <span class="mathjax-tex">\(p\ne 0,1\)</span>. Since <span class="mathjax-tex">\({\mathcal {M}}_N\)</span> and <span class="mathjax-tex">\({\mathcal {M}}/\sim \)</span> agree on all 0/1-valued parameters, and for all others the parameters of <span class="mathjax-tex">\({\mathcal {M}}_N\)</span> converge to those of <span class="mathjax-tex">\({\mathcal {M}}/\sim \)</span>, one also obtains <span class="mathjax-tex">\(P^{\mathrm {max}}_{{\mathcal {M}}_N}(\varphi ) \rightarrow P^{\mathrm {max}}_{{\mathcal {M}}}(\varphi )\)</span>. The argument for <span class="mathjax-tex">\(P^{\mathrm {min}}\)</span> is analogous by considering minimum reachability instead of maximum reachability. The proof for the case <span class="mathjax-tex">\(r\ge 1\)</span> is identical, using the weaker convergence guarantee of Theorem <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar16">1</a> for this case. <span class="mathjax-tex">\(\square \)</span>
                        </p>
              <p>Theorem <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar19">3</a> makes a strictly stronger statement for the choice of significance levels <span class="mathjax-tex">\(\epsilon _N=1/N^r\)</span> with <span class="mathjax-tex">\(r&gt;2\)</span>. However, all statements are strictly asymptotic, and these very small <span class="mathjax-tex">\(\epsilon _N\)</span>-values may lead to significantly under-estimate the size of the generating model when learning from a given limited dataset. In practice, therefore, one may prefer the weaker guarantees obtained for <span class="mathjax-tex">\(\epsilon _N=1/N\)</span> in exchange for a lower risk of learning an over-simplified model.</p><p>An important observation is that Theorems <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar17">2</a> and <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar19">3</a> are pointwise for each <span class="mathjax-tex">\(\varphi \)</span>, and not uniform for the whole languages sub-CSL and LTL, respectively. Thus, it is not the case that in the limit we will learn a model that simultaneously approximates the probabilities of all properties <span class="mathjax-tex">\(\phi \)</span> to within a fixed error bound <span class="mathjax-tex">\(\delta \)</span>. In other words, the sample size <i>N</i> required to obtain a good approximation can be different for different <span class="mathjax-tex">\(\phi \)</span>. This is inevitable, due to the fact that both the languages sub-CSL and LTL contain formulas of unbounded complexity.</p><p>To illustrate this point, consider an LMC model <span class="mathjax-tex">\({\mathcal {M}}\)</span> for a sequence of coin tosses: the model has two states labeled <i>H</i> and <i>T</i>, respectively, and transition probabilities of 1/2 between all the states. Let <span class="mathjax-tex">\({\mathcal {M}}_N\)</span> be a learned approximation of <span class="mathjax-tex">\({\mathcal {M}}\)</span>. The transition probabilities in <span class="mathjax-tex">\({\mathcal {M}}_N\)</span> will deviate slightly from the true values 1/2. For example, assume that the transitions in <span class="mathjax-tex">\({\mathcal {M}}_N\)</span> have value <span class="mathjax-tex">\(1/2+\delta \)</span> for the transitions leading into <i>H</i>, and <span class="mathjax-tex">\(1/2-\delta \)</span> for the transitions leading into <i>T</i>. Then one can construct LTL formulas <span class="mathjax-tex">\(\phi \)</span>, such that <span class="mathjax-tex">\(\mid \! P_{\mathcal {M}}(\phi )-P_{{\mathcal {M}}_N}(\phi ) \!\mid \)</span> is arbitrarily close to 1. To do so, observe that according to <span class="mathjax-tex">\({\mathcal {M}}\)</span> the relative frequency of the symbol <i>H</i> in long execution traces converges to 1/2, whereas according to <span class="mathjax-tex">\({\mathcal {M}}_N\)</span> it converges to <span class="mathjax-tex">\(1/2+\delta \)</span>. For any <span class="mathjax-tex">\(k&gt;0\)</span> we can express with an LTL formula <span class="mathjax-tex">\(\phi _k\)</span> that the frequency of <i>H</i> in the first <i>k</i> steps is at least <span class="mathjax-tex">\(1/2+\delta /2\)</span> by just enumerating all sequences of length <i>k</i> that satisfy this condition. Then, as <span class="mathjax-tex">\(k\rightarrow \infty \)</span>, <span class="mathjax-tex">\(P_{\mathcal {M}}(\phi _k)\rightarrow 0\)</span> and <span class="mathjax-tex">\(P_{{\mathcal {M}}_N}(\phi _k)\rightarrow 1\)</span>.</p></div></div></section><section aria-labelledby="Sec16" data-title="Experiments"><div class="c-article-section" id="Sec16-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec16">Experiments</h2><div class="c-article-section__content" id="Sec16-content"><p>In order to validate the proposed algorithm we have conducted two case studies on learning stochastic system models. Since a DMC can be seen as a DMDP having only a single input action, we only report results for DMDPs and DCTMCs. For each case study, we generated observation sequences (I/O strings and timed strings) from known system models, and compared the generating models and the learned models based on relevant system properties expressed by PLTL formulas. All experiments were performed on a standard laptop with a 2.4GHz CPU.</p><h3 class="c-article__sub-heading" id="Sec17">Experiments with MDPs</h3><p>For analyzing the behavior of the learning algorithm with respect to MDPs we consider a modified version of the slot machine model given by Jansen (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Jansen, D. N. (2002). Probabilistic UML statecharts for specification and verification a case study. In Proceedings of the workshop on critical systems development with UML, pp. 121–132." href="/article/10.1007/s10994-016-5565-9#ref-CR32" id="ref-link-section-d52740e24170">2002</a>). Our model represents a slot machine with three reels that are marked with two different symbols “bar” and “apple”, as well as a separate initial symbol “blank”. Starting with an initial configuration in which all reels show the “blank” symbol, the player can for a given number <i>r</i> of rounds select and spin one of the reels. A wheel that has been spun will randomly display either “bar” or “apple”, where the probability of obtaining a “bar” is 0.7 in the first round, and gradually decreases as <span class="mathjax-tex">\(0.7(r-k+1)/r\)</span> for the <i>k</i>th round. The player receives a reward of 10 if the final configuration of the reels shows 3 bars, and a reward of 2 if the final configuration shows 2 bars. Instead of spinning a reel, the player can also choose to push a ’stop’ button. In that case, with probability 0.5 the game will end, and the player receives the prize corresponding to the current configuration of the reels. With probability 0.5, the player will earn 2 extra rounds. Thus, choosing the ’stop’ option can be beneficial when the current configuration already gives a reward (but at the risk that it will change into something less favorable when instead of terminating the game is extended by 2 rounds), or when with the remaining available rounds the current configuration is unlikely to change into a reward configuration (then at the risk that the game ends immediately with the current poor configuration).</p><p>This model is formalized as a DMDP whose states are defined by the configuration of the reels, the number of spins already performed <i>sp</i> (up to the maximum of <i>r</i>), and a Boolean <i>end</i> variable indicating whether the game is terminated. The granting of 2 extra spins is (approximately) implemented by decreasing by 2 the <i>sp</i> counter, down to a minimum of 0 (otherwise this would lead to an infinite state space). Input actions are <span class="mathjax-tex">\(spin _i\)</span> (<span class="mathjax-tex">\(i=1,2,3\)</span>) and <i>stop</i>. The output alphabet is <span class="mathjax-tex">\(\varSigma ^{out }= \{blank ,bar ,apple \}^3 \cup \{Pr0,Pr2,Pr10,end \}\)</span>. States with <span class="mathjax-tex">\(sp &lt;r\)</span> are labeled with the symbol from <span class="mathjax-tex">\(\{blank ,bar ,apple \}^3\)</span> representing the current reel configuration. When the number of available spins has been exhausted, then the next input (regardless of which input is chosen) leads to a state displaying the prize won as one of <span class="mathjax-tex">\(\{Pr0,Pr2,Pr10 \}\)</span>. Finally, one additional input leads to a terminal state labeled with <i>end</i>. States labeled with <span class="mathjax-tex">\(\{Pr0,Pr2,Pr10 \}\)</span> have an associated reward of 0, 2, and 10, respectively. We have implemented this DMDP in PRISM (Kwiatkowska et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Kwiatkowska, M.Z., Norman, G., &amp; Parker, D. (2011). Prism 4.0: Verification of probabilistic real-time systems. In Proceedings of the international conference on computer aided verification (CAV’11), pp. 585–591." href="/article/10.1007/s10994-016-5565-9#ref-CR34" id="ref-link-section-d52740e24631">2011</a>), and experimented with two versions of the model given by <span class="mathjax-tex">\(r=3\)</span>, and <span class="mathjax-tex">\(r=5\)</span>. These models have 103 (<span class="mathjax-tex">\(r=3\)</span>) and 161 (<span class="mathjax-tex">\(r=5\)</span>) reachable states, respectively.</p><p>The model generates traces that with probability 1 are finite, in the sense that after finitely many steps the trace ends in an infinite sequence of <i>end</i> symbols. However, there is no fixed bound on the number of initial non-<i>end</i> symbols. We sample observation sequences from the models using a uniform random selection of input actions at each point. Sampling of one sequence is terminated when the <i>end</i> symbol appears. The length distribution of strings sampled in this manner is dominated by a geometric distribution with parameter <span class="mathjax-tex">\(\lambda =0.25\cdot 0.5\)</span> (the probability that the random scheduler chooses the <i>stop</i> input, and the game terminates on that input). The convergence in probability (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10994-016-5565-9#Equ2">2</a>) of Theorem <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar16">1</a> then also is ensured under this sampling regime (the consistency properties of the Hoeffding test in relation to the expected sample string lengths as described by Definitions <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar32">20</a> and <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar33">21</a> (iii) are unaffected when the length distribution of sampled strings is reduced; the data support condition of Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar33">21</a> (ii) still is true for all ’relevant’ states of the IOFPTA, i.e., all states that are not just copies of the unique <i>end</i> state).</p><p>In the following, we characterize the size of data sets in terms of the total number <i>N</i> of observation symbols, rather than the number of sequences (as a better measure of the ’raw size’ of the data). For sufficiently large samples, the ratio between the number of sequences and the number of symbols is very nearly constant, so that letting <span class="mathjax-tex">\(\epsilon _N=c/N\)</span> also satisfies the conditions to obtain (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10994-016-5565-9#Equ4">4</a>) in Theorem <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar19">3</a> when <i>N</i> is the number of symbols. In our experiments we set <span class="mathjax-tex">\(c=10.000\)</span>, because that leads to <span class="mathjax-tex">\(\epsilon _{20.000}=0.5\)</span> for our smallest datasize <span class="mathjax-tex">\(N=20.000\)</span>. Since the use of this <span class="mathjax-tex">\(\epsilon _N\)</span> sequence only is motivated by the theoretical convergence in the limit guarantees, and these guarantees do not provide any optimality guarantees for the limited sample sizes we consider, we also consider the alternative sequence where <span class="mathjax-tex">\(\epsilon _N=0.5\)</span>, for all <i>N</i>. This also serves the purpose of investigating the robustness of the learning results with respect to the choice of the <span class="mathjax-tex">\(\epsilon _N\)</span>.</p><p>We evaluate the learned models based on how well they approximate properties of the generating model. We consider properties of the form <span class="mathjax-tex">\(P^{\mathrm {max}}(\phi )\)</span> for different LTL formulas <span class="mathjax-tex">\(\phi \)</span>, and use the following accuracy measure for the evaluation: when <i>p</i> and <span class="mathjax-tex">\(\bar{p}\)</span> are the probabilities in the true and learned models, respectively, then we use the Kullback-Leibler distance</p><div id="Equ5" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} KL(p,\bar{p}) = p\log \frac{p}{\bar{p}} + (1-p)\log \frac{1-p}{1-\bar{p}} \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (5)
                </div></div><p>to measure the error of <span class="mathjax-tex">\(\bar{p}\)</span>. The error, then, depends on the ratio <span class="mathjax-tex">\({p}/{\bar{p}}\)</span> rather than the difference <span class="mathjax-tex">\(p-\bar{p}\)</span>. The inclusion of the term <span class="mathjax-tex">\((1-p)\log \frac{1-p}{1-\bar{p}}\)</span> evaluates the estimate of <span class="mathjax-tex">\(P^{\mathrm {max}}(\phi )\)</span> also as an estimate for the dual <span class="mathjax-tex">\(P^{\mathrm {min}}(\lnot \phi )=1-P^{\mathrm {max}}(\phi )\)</span>. <span class="mathjax-tex">\( KL(p,\bar{p})\)</span> is infinite when <span class="mathjax-tex">\(p\ne \bar{p}\in \{0,1\}\)</span>, i.e. when the learned value <span class="mathjax-tex">\(\bar{p}\)</span> represents an incorrect assumption of deterministic behavior. On the other hand <span class="mathjax-tex">\(\bar{p}\ne p\in \{0,1\}\)</span>, i.e., incorrectly modeling deterministic behavior as probabilistic, incurs only a finite <i>KL</i> error. This asymmetric view is reasonable in many situations, because estimating 0,1-values by non-extreme probabilities usually means erring on the safe side, whereas incorrectly inferring 0,1-values can lead to incorrect assumptions of critical safety properties, for example.</p><p>We compare the models learned by <span class="u-small-caps">IOalergia</span> with the models given by the initially constructed I/O frequency prefix tree acceptors (with the frequencies normalized to probabilities, so that the IOFPTA is itself a valid DMDP). These initial tree-models are just a somewhat compact representation of the original data, and model checking performed on the trees can be seen as <i>statistical model checking</i> for DMDPs. Based on the tree-model representation of the data, we can use the model checking functionality of the PRISM tool to also perform statistical model checking. However, it turned out that the PRISM model checking algorithms, which are optimized for models specified in a modular, structured way, do not perform so well on the tree models, which are given by an unstructured state-level representation. Thus, even though PRISM is known to be able to operate on models of tens of millions of states, we were only able to run PRISM on tree models of up to around 60,000 states.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6" data-title="Fig. 6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig6_HTML.gif?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig6_HTML.gif" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Growth of tree and model size. <i>Top</i> 
                                       <span class="mathjax-tex">\(r=3\)</span>, <i>bottom</i> 
                                       <span class="mathjax-tex">\(r=5\)</span>
                                    </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig6">6</a> shows how for the <span class="mathjax-tex">\(r=3\)</span> and <span class="mathjax-tex">\(r=5\)</span> models the number of states in the constructed IOFPTAs and learned models develops as a function of the data size. The plots are in log-log scale, with the number of data symbols (divided by 1000) on the x-axis, and the number of states of the trees and learned models on the left, respectively right, y-axes. The red lines (box symbols) show a linear growth of the IOFPTA in log-log space. These lines have a near-perfect fit with the functions <span class="mathjax-tex">\(550 N^{0.65}\)</span> (<span class="mathjax-tex">\(r=3\)</span>), and <span class="mathjax-tex">\(550 N^{0.8}\)</span> (<span class="mathjax-tex">\(r=5\)</span>). These fits experimentally verify the sub-linear growth of IOFPTAs, which is theoretically obtained from Lemma <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar36">2</a> (Appendix).</p><p>When learning with fixed <span class="mathjax-tex">\(\epsilon =0.5\)</span>, the learned model sizes also show an approximately linear behavior in log-log space, which translates to a growth of (approximately) the orders <span class="mathjax-tex">\(N^{0.27}\)</span> (<span class="mathjax-tex">\(r=3\)</span>), and <span class="mathjax-tex">\(N^{0.4}\)</span> (<span class="mathjax-tex">\(r=5\)</span>). Learning with <span class="mathjax-tex">\(\epsilon _N=10,000/N\)</span> at first under-estimates the true model size. The models learned for the largest <i>N</i> values are very close in size to the generating model. However, the experimental range for <i>N</i> would need to be extended considerably further in order to ascertain that here we already see the asymptotic convergence to the true model.</p><p>We evaluate the accuracy of the learned model based on a test suite of 61 LTL properties. The complete list of properties is given in “MDP Test Properties” of Appendix. As mentioned above, using PRISM model checking on the IOFPTAs as a surrogate for statistical model checking does not scale to very large tree models. Therefore, the results here are limited to a maximum of <span class="mathjax-tex">\(N=1m\)</span> for <span class="mathjax-tex">\(r=3\)</span>, and <span class="mathjax-tex">\(N=320k\)</span> for <span class="mathjax-tex">\(r=5\)</span> (at these tree sizes, a model-checking run for all 61 properties took several hours, vs. a few seconds for model checking the model learned from the IOFPTA).</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Number of test properties with <span class="mathjax-tex">\(KL(p,\bar{p})=\infty \)</span>
                                    </b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10994-016-5565-9/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>We first consider for how many of the test properties an error <span class="mathjax-tex">\(KL(p,\bar{p})=\infty \)</span> is obtained, i.e., the learned value <span class="mathjax-tex">\(\bar{p}\)</span> is an erroneous deterministic 0/1-value. These numbers are given in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10994-016-5565-9#Tab1">1</a>. An entry <i>k</i>; <i>l</i> in this table means that for <i>k</i> test properties the IOFPTA gave an infinite <i>KL</i>-value, and for <i>l</i> properties this was the case for the learned model. It emerges a clear picture that the learned model is much less likely to return erroneous deterministic values. This is a natural consequence of a model-smoothing effect resulting from the state-merging process, and illustrates that model learning can alleviate overfitting problems occurring in statistical model-checking. The most problematic queries for IOFPTA-model checking were the low-probability queries 56–61, where the true probabilities are in the range 0.03–0.002, and IOFPTA-model checking returned the value 0. The values obtained from the learned models, on the other hand, approximated the true values rather well, and had <i>KL</i>-errors in the range 0.001–0.01.</p><p>The smoothing effect in the learned models can also have the less desirable consequence of leading to non-extreme estimates for probabilities that in the generating model are actually 0/1-valued. This was observed for property 16, which for <span class="mathjax-tex">\(r=5\)</span> has max-probability 1 in the generating model. Here IOFPTA model checking returned the correct result, wheras the probabilities in the learned models were in the range 0.95–0.99 even for large data sizes. Similarly, some of the properties that have zero probability in the <span class="mathjax-tex">\(r=3\)</span> model, had probabilities in the range 0.01–0.001 in the learned models.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7" data-title="Fig. 7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig7_HTML.gif?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig7_HTML.gif" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>KL errors</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig7">7</a> illustrates the <i>KL</i>-errors for all 61 properties for small datasets (<span class="mathjax-tex">\(N=40k\)</span>), and the largest datasets for which model checking the IOFPTA tree was feasible (<span class="mathjax-tex">\(N=1m\)</span> for <span class="mathjax-tex">\(r=3\)</span>, and <span class="mathjax-tex">\(N=320k\)</span> for <span class="mathjax-tex">\(r=5\)</span>). In these plots the <i>x</i>-axes index the test properties. The properties are here sorted according to increasing values of the <i>KL</i>-errors obtained from the trees. Thus, the indexing differs from the numbering given in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10994-016-5565-9#Tab5">5</a>, and also the ordering of the properties differs in the four plots of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig7">7</a>. The <i>y</i>-axes show the <i>KL</i>-errors in log-scale. Infinite <i>KL</i>-values are represented by the value 10.0, and zero values by <span class="mathjax-tex">\(10^{-6}\)</span>.</p><p>At the right end of each plot appear the properties that gave <span class="mathjax-tex">\(KL=\infty \)</span> from IOFPTA model-checking. The errors obtained for the same properties from the learned models are in the same range as the errors for other properties. On the left ends of the plots appear properties with actual probability zero, which give zero error from the tree, but nonzero estimates, and hence nonzero errors from the learned models.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8" data-title="Fig. 8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig8_HTML.gif?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig8_HTML.gif" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Probabilities for <span class="mathjax-tex">\(P^{\mathrm {max}}(\lnot \lozenge ^{&lt;9}{} end )\)</span> queries</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9" data-title="Fig. 9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig9_HTML.gif?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig9_HTML.gif" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>Probabilities for <span class="mathjax-tex">\(P^{\mathrm {max}}\lozenge Pr10 \)</span> and <span class="mathjax-tex">\(P^{\mathrm {max}}\lozenge Pr2 \)</span> queries. <i>Plots</i> with the larger probability values are for <span class="mathjax-tex">\(P^{\mathrm {max}}\lozenge Pr2 \)</span>
                                    </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>For the <span class="mathjax-tex">\(r=5\)</span> model the properties appearing at indices 42–49 (<span class="mathjax-tex">\(N=40k\)</span>), respectively 52–59 (<span class="mathjax-tex">\(N=320k\)</span>) are properties 17–24 of Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10994-016-5565-9#Tab5">5</a>, which are all of the form <span class="mathjax-tex">\(P^{\mathrm {max}}(\lnot \lozenge ^{&lt;k}{} end )\)</span> for different values of <i>k</i>, i.e., they represent the maximum probability of the game lasting at least <i>k</i> steps, for various values of <i>k</i>. For both the tree and the learned models the estimates for these probabilities were quite inaccurate. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig8">8</a> on the right shows the actual probability values obtained for the <span class="mathjax-tex">\(P^{\mathrm {max}}(\lnot \lozenge ^{&lt;9}{} end )\)</span> query for <span class="mathjax-tex">\(r=5\)</span>. For the datasizes <span class="mathjax-tex">\(N=40k\)</span> and <span class="mathjax-tex">\(N=320k\)</span> depicted in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig7">7</a>, the estimates are above 0.9 for all trees and models, whereas the true value is 0.5. The left plot in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig8">8</a> shows the results for the same query in the <span class="mathjax-tex">\(r=3\)</span> case.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig9">9</a> shows the probabilities returned for the queries <span class="mathjax-tex">\(P^{\mathrm {max}}\lozenge Pr10 \)</span> and <span class="mathjax-tex">\(P^{\mathrm {max}}\lozenge Pr2 \)</span>. These are queries for which the corresponding <i>KL</i>-errors lie in the middle ranges of the <i>KL</i>-errors seen in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig7">7</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10" data-title="Fig. 10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig10_HTML.gif?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig10_HTML.gif" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Average KL errors</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig10">10</a> shows the average <i>KL</i>-errors obtained as a function of the data size. The average here is taken over all test properties excluding the properties <span class="mathjax-tex">\(P^{\mathrm {max}}(\lnot \lozenge ^{&lt;k}{} end )\)</span> (whose high values would otherwise mask the development of <i>KL</i>-errors for the remaining properties). Furthermore, for each data size, only properties are included for which all models return non-infinite errors.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11" data-title="Fig. 11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig11_HTML.gif?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig11_HTML.gif" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>Average KL error at <span class="mathjax-tex">\(N=10^6\)</span> as function of <span class="mathjax-tex">\(\epsilon \)</span>
                                    </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>To obtain a more complete picture on the influence of the <span class="mathjax-tex">\(\epsilon \)</span> parameter, we also vary <span class="mathjax-tex">\(\epsilon \)</span> over the whole feasible range from 0 to 2 for the fixed data size <span class="mathjax-tex">\(N=10^6\)</span>. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig11">11</a> shows the sizes and average KL-errors for the learned models. The different <span class="mathjax-tex">\(\epsilon \)</span>-values we used are listed on the <i>x</i>-axis simply on equi-distant marks. The <span class="mathjax-tex">\(\epsilon \)</span>-values we otherwise used for <span class="mathjax-tex">\(N=10^6\)</span> are 0.5 and 0.01, which both are in the middle of the range of values considered here. Even at the extreme end <span class="mathjax-tex">\(\epsilon =2\)</span> the learned models are significantly smaller than the original IOFPTA’s (which have sizes 47,564 and 134,693 for <span class="mathjax-tex">\(r=3\)</span> and <span class="mathjax-tex">\(r=5\)</span>, respectively). This is because even though the Hoeffding test proper will always reject when <span class="mathjax-tex">\(\epsilon =2\)</span>, we still obtain positive compatibility results, and hence merges of nodes, due to the base test in line 1 of our Hoeffding compatibility test (Algorithm 3). The minimal model size is 31 nodes, corresponding to exactly one node for each output symbol. This minimal size is reached at <span class="mathjax-tex">\(\epsilon =10^{-60}\)</span> and <span class="mathjax-tex">\(\epsilon =10^{-10}\)</span> for <span class="mathjax-tex">\(r=3\)</span> and <span class="mathjax-tex">\(r=5\)</span>, respectively. The average KL errors are shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig11">11</a> separately for the “hard” test properties <span class="mathjax-tex">\(P^{\mathrm {max}}(\lnot \lozenge ^{&lt;k}{} end )\)</span>, and the remaining “easy” properties. Furthermore, to obtain readable plots, the KL-errors for the hard properties have been scaled by a factor of 0.1.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig11">11</a> indicates that better results are obtained when <span class="mathjax-tex">\(\epsilon \)</span> is chosen so large that the size of the learned model is somewhat larger than the size of the true model. This would also have to be expected, since a model that over-estimates the true number of states can be trace-equivalent to the true model, whereas a model with fewer states than the true model usually can not. For the ’easy’ test properties we obtain a fairly clear picture of optimal <span class="mathjax-tex">\(\epsilon \)</span>-values in the range 0.5–1.5, corresponding to models that are in the range of <span class="mathjax-tex">\(1\times \)</span> to <span class="mathjax-tex">\(10\times \)</span> the size of the true model. The picture for the ’hard’ properties is less clear and rather different for <span class="mathjax-tex">\(r=3\)</span>, where the most accurate models are learned for a range of small <span class="mathjax-tex">\(\epsilon \)</span>-values, and <span class="mathjax-tex">\(r=5\)</span>, where the error decreases nearly monotonically as <span class="mathjax-tex">\(\epsilon \)</span> increases. Overall, the results show that <span class="u-small-caps">IOalergia</span> learning is quite robust with respect to the precise choice of the <span class="mathjax-tex">\(\epsilon \)</span> value.</p><p>Summarizing our observations, we can reach a number of conclusions: the differences in the accuracy of estimated probabilities are quite significant for different models of similar size (<span class="mathjax-tex">\(r=3\)</span> with 103 states; <span class="mathjax-tex">\(r=5\)</span> with 161 states), and for different queries <span class="mathjax-tex">\(P^{\mathrm {max}}(\lnot \lozenge ^{&lt;k}{} end )\)</span> and <span class="mathjax-tex">\(P^{\mathrm {max}}\lozenge PrX \)</span> of similar syntactic form and complexity. Thus, neither the size of the true model, nor the complexity of the query alone will be good predictors for the accuracy of max-probability estimates obtained either by statistical model checking, or by model learning. In spite of very different convergence speeds, we observed convergence of the estimated max-probabilities to the true values for all test properties.</p><p>When comparing statistical model checking against model learning, no clear winner emerges in terms of the accuracy of estimated probabilities. The main difference lies in a smoothing effect of the learning process that eliminates extreme 0/1 empirical probabilities. This can allow the learned model to successfully generalize from the data, and return accurate estimates for low-probability properties that are not seen in the data, and for which statistical model checking returns zero probabilities. On the other hand, it can also lead to over-generalization, where true probability zero properties are given non-zero values in the learned model. Here it should be emphasized that in our experiments we have not tried to exploit another generalization capability of model learning, which is the ability to generalize from observations of finite initial trace segments to infinite behaviors. Traces in our slot machine model are finite with probability 1, and our data only contained traces of completed runs. This gives ideal conditions for statistical model checking, since empirical probabilities in the data correspond to actual model probabilities.</p><p>Comparing the results obtained from models learned with fixed <span class="mathjax-tex">\(\epsilon =0.5\)</span>, and decreasing <span class="mathjax-tex">\(\epsilon =10,000/N\)</span> we observe in Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig8">8</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig9">9</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig10">10</a> for smaller data sizes a slight advantage for <span class="mathjax-tex">\(\epsilon =0.5\)</span>. This is explained by Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig6">6</a>, which shows that under the <span class="mathjax-tex">\(\epsilon =10,000/N\)</span> regime the learned model stays smaller than the true model for the whole range of data sizes, approaching the true size only at the very end. The <span class="mathjax-tex">\(\epsilon =0.5\)</span> models, on the other hand, soon become somewhat larger than the true model. As also indicated by Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig11">11</a>, moderate over-approximations of the true model tend to lead to smaller KL errors.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12" data-title="Fig. 12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig12_HTML.gif?as=webp"></source><img aria-describedby="figure-12-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig12_HTML.gif" alt="figure12" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>Time for model learning (<span class="mathjax-tex">\(r=3\)</span>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/12" data-track-dest="link:Figure12 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>In terms of space, model learning obviously leads to very significant savings (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig6">6</a>). As mentioned above, we cannot make a meaningful comparison for the time complexity of statistical model checking versus model learning, since we are using a very inefficient approach for performing the former. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig12">12</a> shows the computation time for <span class="u-small-caps">IOalergia</span>learning for the case <span class="mathjax-tex">\(r=3\)</span> and <span class="mathjax-tex">\(\epsilon =0.5\)</span>. The overall time is divided into the construction time for the IOFPTA, and the time for the <span class="u-small-caps">IOalergia</span>node-merging process. We observe that both times are linear in the datasize. For <span class="u-small-caps">Alergia</span>, the theoretical worst-case complexity is cubic in the size of the IOFPTA, but the linear behavior we here observe is consistent with what is reported as the typical behavior of <span class="u-small-caps">Alergia</span> in practice. Moreover, we see that the times for the tree construction and the node merging phases of the learning procedure are of the same order of magnitude. Since even a highly optimized statistical model checking procedure will not be much faster than the IOFPTA construction, we can conclude that the time for model learning is of the same order of magnitude as a single run of statistical model checking, with significant savings for the amortized cost of checking multiple properties.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Accuracies of pure versus count-aggregating <span class="u-small-caps">IOalergia</span>(<span class="mathjax-tex">\(r=3\)</span>)</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10994-016-5565-9/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>As discussed in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec10">3.2</a>, in our <span class="u-small-caps">IOalergia</span> implementation we do not aggregate frequency counts when merging nodes, and we perform the compatibility tests always based on the counts in the original IOFPTA. For comparison we also tested a version of the algorithm in which counts are aggregated. The main observation we made was that for a given <span class="mathjax-tex">\(\epsilon \)</span>-value, models learned using aggregated counts were larger than models learned without count aggregation. Thus, aggregating counts leads to more rejections in the compatibility tests. This can be explained by the fact that the Hoeffding test will always accept compatibility when the two counts <span class="mathjax-tex">\(n_1,n_2\)</span> are very small (cf. Algorithm 3), e.g. both are at most 2, or one is equal to 1, and the other less than 10. Since counts at the leaves of the IOFPTA (or nodes very close to the leaves) will usually have very low counts, this means that in the original IOFPTA most pairs of leaves will be tested as compatible. However, after merging the counts of two or three leaves, this will more often no longer be the case. The accuracy of models learned with count-aggregation was not higher than the accuracy of models learned without aggregation, but with <span class="mathjax-tex">\(\epsilon \)</span>-settings that lead to models of approximately equal size. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10994-016-5565-9#Tab2">2</a> shows some detailed results for the <span class="mathjax-tex">\(r=3\)</span> model learned from data of size <span class="mathjax-tex">\(N=1m\)</span>. For the two <span class="mathjax-tex">\(\epsilon \)</span>-values that also have been used in the previous experiments for <span class="mathjax-tex">\(N=1m\)</span>, the table shows the sizes of the learned models, with and without count aggregation. For comparison also the IOFPTA is included in the table. The average <i>KL</i>-error shown in the last column of the table is the average error over all 61 test properties (for <span class="mathjax-tex">\(r=3, N=1m\)</span> the errors for the difficult properties 17–24 are not such clear outliers that their inclusion in the average dominates the results). For the IOFPTA the <i>KL</i>-error is averaged over all properties except two for which the error is infinite. The table indicates that the accuracy depends more on the size of the learned model (best results being obtained when slightly over-estimating the true size) than on whether learning is with or without count aggregation.</p><h3 class="c-article__sub-heading" id="Sec18">Experiments for CTMCs</h3><p>For CMTCs, we consider a case study adapted from Haverkort et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Haverkort, B. R., Hermanns, H., &amp; Katoen, J. P. (2000). On the use of model checking techniques for dependability evaluation. In Proceedings of the IEEE symposium on reliable distributed systems (SRDS 2000), pp. 228–237." href="/article/10.1007/s10994-016-5565-9#ref-CR28" id="ref-link-section-d52740e29393">2000</a>), where two sub-clusters of workstations are connected through a backbone. Each sub-cluster has <i>N</i> workstations, and the data from a workstation is sent to the backbone by a switch connected to the workstation’s sub-cluster. The topology of the system is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig13">13</a>. Each component in the system can break down and any broken component can be repaired. The average failure-free running time of the workstations, switches, and backbone is 2, 5, and 10 h, respectively; the average time required for repairing one of these components is 1, 2, and 4 h. There are two types of Quality of Service (QoS) associated with the system:</p><ul class="u-list-style-dash">
                    <li>
                      <p>
                                    <span class="u-sans-serif">minimum</span>: at least 3<i>N</i> / 4 workstations are operational and connected via switches and the backbone,</p>
                    </li>
                    <li>
                      <p>
                                    <span class="u-sans-serif">premium</span>: at least <i>N</i> workstations are operational and connected via switches and the backbone.</p>
                    </li>
                  </ul><p>Note that if the <span class="u-sans-serif">premium</span> requirement is met, then so is the <span class="u-sans-serif">minimum</span> requirement. We specify CTMCs for this system with a varying number of workstations. The summary statistics for the models in terms of the number of states and transitions are listed in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10994-016-5565-9#Tab3">3</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-13" data-title="Fig. 13"><figure><figcaption><b id="Fig13" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 13</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/13" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig13_HTML.gif?as=webp"></source><img aria-describedby="figure-13-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig13_HTML.gif" alt="figure13" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-13-desc"><p>The topology of a workstation cluster (Haverkort et al. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Haverkort, B. R., Hermanns, H., &amp; Katoen, J. P. (2000). On the use of model checking techniques for dependability evaluation. In Proceedings of the IEEE symposium on reliable distributed systems (SRDS 2000), pp. 228–237." href="/article/10.1007/s10994-016-5565-9#ref-CR28" id="ref-link-section-d52740e29449">2000</a>)</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/13" data-track-dest="link:Figure13 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Summary statistics of the CTMC models for the workstation cluster case study</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10994-016-5565-9/tables/3"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>When generating data from the specified models, the observation sequences correspond to timed strings that alternate between observable symbols and time values. Following the sampling procedure outlined in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec15">4</a>, we generated observation sequences from different system configurations with 4, 8, and 10 workstations in each sub-cluster. The average length of these observation sequences is 50. We also assume that each component is operational initially. For the present case study, the most important property is the amount of time for which the minimum and premium QoS requirements are satisfied. These two properties are expressed by the sub-CSL formulas</p><div id="Equ32" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P=? [\lozenge _{\le t}\; !\mathsf {``minimum''}]\qquad P=? [\lozenge _{\le t}\; !\mathsf {``premium''}], \end{aligned}$$</span></div></div><p>where <i>t</i> is a real number.</p><p>For the experimental results reported below, we used <span class="mathjax-tex">\(\alpha =0.5\)</span> for the compatibility tests employed in the learning algorithms. The choice of having a fixed <span class="mathjax-tex">\(\alpha \)</span>-value is based on the experimental results for the slot machine model (see Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec17">5.1</a>), which showed that the learning algorithms are fairly robust wrt. the particular choice of <span class="mathjax-tex">\(\alpha \)</span>-value.</p><p>As shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig14">14</a>, the two QoS properties above are generally well approximated by the learned models although (as expected) the quality of the approximations decreases as the complexity of the generating models increases. All models are learned using 40000 symbols, and all probabilities have been computed using PRISM. For comparison, we have also included the results obtained by directly using the timed frequency prefix tree acceptors (TFPTAs) for performing model checking. As can be seen from the figure, when the prediction horizon starts to increase the properties are no longer well-approximated by the TFPTA-models. Summary information about the models learned for various data sizes and system configurations are given in the first five columns in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10994-016-5565-9#Tab4">4</a>; <span class="mathjax-tex">\(|S|\)</span> is the number of symbols in the dataset (<span class="mathjax-tex">\(\times 10^3\)</span>); <span class="mathjax-tex">\(|\mathrm {Seq}|\)</span> is the number of sequences in the dataset; <span class="mathjax-tex">\(|\text {TFPTA}|\)</span> is the number of nodes in the TFPTA; <i>‘Time’</i> is the learning time (in seconds), including the time for constructing the TFPTA, and |<i>Q</i>| is the number of states in the learned model.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-14" data-title="Fig. 14"><figure><figcaption><b id="Fig14" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 14</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/14" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig14_HTML.gif?as=webp"></source><img aria-describedby="figure-14-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig14_HTML.gif" alt="figure14" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-14-desc"><p>The results of checking the properties <span class="mathjax-tex">\(P=? [\lozenge _{\le t}\; !\mathsf {``minimum''}]\)</span> and <span class="mathjax-tex">\(P=? [\lozenge _{\le t}\; !\mathsf {``premium''}]\)</span> in the learned models, timed frequency prefix tree acceptor, and the generating models with <span class="mathjax-tex">\(t \in [0.5,6]\)</span>
                                    </p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/14" data-track-dest="link:Figure14 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4 Experimental results for the workstation cluster</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10994-016-5565-9/tables/4"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        
                  <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-15" data-title="Fig. 15"><figure><figcaption><b id="Fig15" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 15</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/15" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig15_HTML.gif?as=webp"></source><img aria-describedby="figure-15-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10994-016-5565-9/MediaObjects/10994_2016_5565_Fig15_HTML.gif" alt="figure15" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-15-desc"><p>The quality of learned models measured in terms of randomly generated formulas</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10994-016-5565-9/figures/15" data-track-dest="link:Figure15 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>In addition to the two properties above, we have measured the quality of the learned models by randomly generating sets of sub-CSL formulas <span class="mathjax-tex">\(\varPhi \)</span> using a stochastic context-free grammar. Each formula is restricted to a maximum length of 20. For the temporal operators we uniformly sample a time value <i>t</i> from [0, 20] and defined the time intervals as [0, <i>t</i>]. In order to avoid testing on tautologies or other formulas with little discriminative value, we constructed a baseline model <i>B</i> with one state for each symbol in the alphabet and with uniform transitions probabilities. For each generated formula <span class="mathjax-tex">\(\varphi \in \varPhi \)</span> we then tested whether the formula was able to discriminate between the learned model <i>A</i>, the generating model <i>M</i>, and the baseline model <i>B</i>. If <span class="mathjax-tex">\(\varphi \)</span> was not able to discriminate between these three models (i.e., <span class="mathjax-tex">\(P_{A}(\varphi )=P_{M}(\varphi )=P_{B}(\varphi )\)</span>), then <span class="mathjax-tex">\(\varphi \)</span> was removed from <span class="mathjax-tex">\(\varPhi \)</span>.</p><p>We finally evaluated the learned models by comparing the mean absolute difference in probability (calculated using PRISM) over the generated formulas for the models <i>M</i> and <i>A</i>:</p><div id="Equ6" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} D_A= &amp; {} \frac{1}{|\varPhi |}\sum \nolimits _{\varphi \in \varPhi } {|P_{M } (\varphi ) - P_{A } (\varphi )|}. \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (6)
                </div></div><p>The mean absolute difference between <i>M</i> and <i>B</i> is calculated analogously.</p><p>The results of the experiments are listed in columns <span class="mathjax-tex">\(D_A\)</span> and <span class="mathjax-tex">\(D_A^T\)</span> in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10994-016-5565-9#Tab4">4</a>, where column <span class="mathjax-tex">\(D_A^T\)</span> lists the results obtained by performing model checking using the TFPTA-model. For models with 4, 8, and 10 workstations in each sub-cluster we ended up with 677, 637, and 635 random formulas, respectively, after the elimination of non-discriminative formulas. The results are further illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10994-016-5565-9#Fig15">15</a>, where we also see that the difference (measured using the randomly generated formulas) between the learned model and the generating model decreases as the amount of data increases. Each data point is the mean value based on eight experiments with different randomly generated data sets. For comparison, the absolute mean difference between the baseline models and the generating models are 0.424, 0.350, and 0.293, for <span class="mathjax-tex">\(N=4\)</span>, <span class="mathjax-tex">\(N=8\)</span>, and <span class="mathjax-tex">\(N=10\)</span>, respectively.</p></div></div></section><section aria-labelledby="Sec19" data-title="Conclusion"><div class="c-article-section" id="Sec19-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec19">Conclusion</h2><div class="c-article-section__content" id="Sec19-content"><p>In this paper we have proposed a framework for learning probabilistic system models based on observed system behaviors. Specifically, we have considered system models in the form of deterministic Markov decision processes and continuous time Markov chains, where the former model class includes standard deterministic Markov chains as a special case. The learning framework is presented within a model checking context and is based on an adapted version of the <span class="u-small-caps">Alergia</span> algorithm (Carrasco and Oncina <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Carrasco, R., &amp; Oncina, J. (1994). Learning stochastic regular grammars by means of a state merging method. In Proceedings of the international colloquium on grammatical inference and applications (ICGIA 1994), pp. 139–152." href="/article/10.1007/s10994-016-5565-9#ref-CR10" id="ref-link-section-d52740e31561">1994</a>) for learning finite probabilistic automata models.</p><p>We have shown that in the large sample limit the learning algorithm will correctly identify the model structure as well as the probability parameters of the model. We position the learning results within a model checking context by showing that for the learned models the probabilities of model properties expressed in the formal specification languages LTL and sub-CSL will converge to the probabilities given by the true models.</p><p>The learning framework is empirically analyzed based on two use-cases covering Markov decision process and continuous time Markov chains. The use cases are analyzed wrt. the structure of the learned system models as well as relevant LTL and sub-CSL definable properties. The results show that for both model classes the learning algorithm is able to produce models that provide accurate estimates of the probabilities of the specified LTL and sub-CSL properties. The results have also been compared to the estimates obtained by statistical model checking, but with the analysis limited to properties testable by statistical model checking. Thus, we do not exploit the generalization capabilities of model learning for reasoning about unbounded system properties. The comparison shows that in terms of LTL-accuracy, there is no clear winner between the two approaches; the main differences in the results are caused by the smoothing effect of model learning. On the other hand, in terms of space and time complexity we see a significant difference in favor of model learning. For the sub-CSL properties, both the accuracy and complexity results are significantly better than those obtained by statistical model checking, in particular for sub-CSL properties defined over longer time horizons. These results are further complemented by accuracy estimates for randomly generated sub-CSL formulas, demonstrating that the learned models also provide accurate probability estimates of more general model properties.</p><p>The theoretical learning results presented in the paper focus on learning in the limit rather than on probably approximately correct (PAC) learning results. Extending the results to PAC learning would require an error measure for the model classes in question, which, in turn, would entail defining a suitable measure for probability distributions over <span class="mathjax-tex">\(\varSigma ^{\omega }\)</span>. Candidate error measures have been investigated by Jaeger et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Jaeger, M., Mao, H., Larsen, K. G., &amp; Mardare, R. (2014). Continuity properties of distances for Markov processes. In Proceedings of QEST 2014, LNCS, Vol. 8657, pp. 297–312." href="/article/10.1007/s10994-016-5565-9#ref-CR31" id="ref-link-section-d52740e31599">2014</a>) who show that there are fundamental difficulties in defining measures that on the one hand support PAC learnability results and on the other hand satisfy natural continuity properties.</p><p>In addition to the results reported in the paper, we have conducted preliminary experiments on learning deterministic MDP approximations based on observations generated by non-deterministic system models. The results showed that the learned (deterministic) models are not sufficiently expressive to capture all relevant non-deterministic system properties. Based on these results, we wish as part of future work to consider learning methods for non-deterministic model classes. We expect, however, that the learning methods will be significantly different from the methods proposed in the current paper as, e.g., the assumption about a deterministic system behavior is key for the FPTA-based data representation.</p><p>The current paper is a significantly extended version of Mao et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Mao, H., Chen, Y., Jaeger, M., Nielsen, T. D., Larsen, K. G., &amp; Nielsen, B. (2011). Learning probabilistic automata for model checking. In Proceedings of the international conference on quantitative evaluation of system (QEST 2011), pp. 111–120." href="/article/10.1007/s10994-016-5565-9#ref-CR39" id="ref-link-section-d52740e31609">2011</a>) and Mao et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Mao, H., Chen, Y., Jaeger, M., Nielsen, T. D., Larsen, K. G., &amp; Nielsen, B. (2012). Learning Markov decision processes for model checking. In Proceedings of the first workshop on quantities in formal methods (QFM), pp. 49–63." href="/article/10.1007/s10994-016-5565-9#ref-CR40" id="ref-link-section-d52740e31612">2012</a>). We have subsequently adapted the results in Mao et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Mao, H., Chen, Y., Jaeger, M., Nielsen, T. D., Larsen, K. G., &amp; Nielsen, B. (2012). Learning Markov decision processes for model checking. In Proceedings of the first workshop on quantities in formal methods (QFM), pp. 49–63." href="/article/10.1007/s10994-016-5565-9#ref-CR40" id="ref-link-section-d52740e31615">2012</a>) to support active learning scenarios, where one guides the interaction with the system under analysis in order to reduce the amount of data required for establishing an accurate system model (Chen and Nielsen <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Chen, Y., &amp; Nielsen, T. D. (2012). Active learning of Markov decision processes for system verification. In Proceedings of the international conference on machine learning and applications (ICMLA 2012), pp. 289–294." href="/article/10.1007/s10994-016-5565-9#ref-CR14" id="ref-link-section-d52740e31618">2012</a>). Furthermore, the learning algorithm has also been extended for learning and verifying properties of systems endowed with a relational structure (Mao and Jaeger <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Mao, H., &amp; Jaeger, M. (2012). Learning and model checking networks of I/O automata. In Proceedings of the fourth Asian conference on machine learning (ACML), pp. 285–300." href="/article/10.1007/s10994-016-5565-9#ref-CR38" id="ref-link-section-d52740e31621">2012</a>). Generally, these learning results assume access to multiple observation sequences of the system in question. For systems that are hard (or even impossible) to restart, this requirement will rarely hold. In Chen et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Chen, Y., Mao, H., Jaeger, M., Nielsen, T. D., Larsen, K.G., &amp; Nielsen, B. (2012). Learning Markov models for stationary system behaviors. In NASA formal methods symposium (NFM), pp. 216–230." href="/article/10.1007/s10994-016-5565-9#ref-CR15" id="ref-link-section-d52740e31625">2012</a>) we have therefore considered methods for investigating system properties by learning system models based on a single observation sequence.</p></div></div></section>
                        
                    

                    <section aria-labelledby="notes" data-title="Notes"><div class="c-article-section" id="notes-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="notes">Notes</h2><div class="c-article-section__content" id="notes-content"><ol class="c-article-footnote c-article-footnote--listed"><li class="c-article-footnote--listed__item" id="Fn1"><span class="c-article-footnote--listed__index">1.</span><div class="c-article-footnote--listed__content"><p>Note that the <span class="mathjax-tex">\(\bar{\varvec{o}}^{(N)}\)</span> can not be assumed to be identically distributed, since the input sequences will be different in different samples.</p></div></li></ol></div></div></section><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Aarts, F., &amp; Vaandrager, F. W. (2010). Learning I/O automata. In Proceedings of the international conference o" /><p class="c-article-references__text" id="ref-CR1">Aarts, F., &amp; Vaandrager, F. W. (2010). Learning I/O automata. In <i>Proceedings of the international conference on concurrency theory</i> (CONCUR 2010), pp. 71–85.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Ammons, G., Bodík, R., &amp; Larus, J. R. (2002). Mining specifications. In Proceedings of the SIGPLAN-SIGACT symp" /><p class="c-article-references__text" id="ref-CR2">Ammons, G., Bodík, R., &amp; Larus, J. R. (2002). Mining specifications. In <i>Proceedings of the SIGPLAN-SIGACT symposium on principles of programming language</i> (POPL 2002), pp. 4–16.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Angluin, " /><meta itemprop="datePublished" content="1987" /><meta itemprop="headline" content="Angluin, D. (1987). Learning regular sets from queries and counterexamples. Journal of Information and Computa" /><p class="c-article-references__text" id="ref-CR3">Angluin, D. (1987). Learning regular sets from queries and counterexamples. <i>Journal of Information and Computation</i>, <i>75</i>, 87–106.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=916360" aria-label="View reference 3 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2F0890-5401%2887%2990052-6" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0636.68112" aria-label="View reference 3 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20regular%20sets%20from%20queries%20and%20counterexamples&amp;journal=Journal%20of%20Information%20and%20Computation&amp;volume=75&amp;pages=87-106&amp;publication_year=1987&amp;author=Angluin%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="C. Baier, JP. Katoen, " /><meta itemprop="datePublished" content="2008" /><meta itemprop="headline" content="Baier, C., &amp; Katoen, J. P. (2008). Principles of model checking. Cambridge, MA: The MIT Press." /><p class="c-article-references__text" id="ref-CR4">Baier, C., &amp; Katoen, J. P. (2008). <i>Principles of model checking</i>. Cambridge, MA: The MIT Press.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Principles%20of%20model%20checking&amp;publication_year=2008&amp;author=Baier%2CC&amp;author=Katoen%2CJP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Baier, B. Haverkort, H. Hermanns, JP. Katoen, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Baier, C., Haverkort, B., Hermanns, H., &amp; Katoen, J. P. (2003). Model-checking algorithms for continuous-time " /><p class="c-article-references__text" id="ref-CR5">Baier, C., Haverkort, B., Hermanns, H., &amp; Katoen, J. P. (2003). Model-checking algorithms for continuous-time Markov chains. <i>Journal of IEEE Transaction on Software Engineering</i>, <i>29</i>(6), 524–541.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTSE.2003.1205180" aria-label="View reference 5">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0974.68017" aria-label="View reference 5 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Model-checking%20algorithms%20for%20continuous-time%20Markov%20chains&amp;journal=Journal%20of%20IEEE%20Transaction%20on%20Software%20Engineering&amp;volume=29&amp;issue=6&amp;pages=524-541&amp;publication_year=2003&amp;author=Baier%2CC&amp;author=Haverkort%2CB&amp;author=Hermanns%2CH&amp;author=Katoen%2CJP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Behrmann, A. David, KG. Larsen, P. Pettersson, W. Yi, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Behrmann, G., David, A., Larsen, K. G., Pettersson, P., &amp; Yi, W. (2011). Developing uppaal over 15 years. Jour" /><p class="c-article-references__text" id="ref-CR6">Behrmann, G., David, A., Larsen, K. G., Pettersson, P., &amp; Yi, W. (2011). Developing uppaal over 15 years. <i>Journal of Software: Practice and Experience</i>, <i>41</i>(2), 133–142.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Developing%20uppaal%20over%2015%20years&amp;journal=Journal%20of%20Software%3A%20Practice%20and%20Experience&amp;volume=41&amp;issue=2&amp;pages=133-142&amp;publication_year=2011&amp;author=Behrmann%2CG&amp;author=David%2CA&amp;author=Larsen%2CKG&amp;author=Pettersson%2CP&amp;author=Yi%2CW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="B. Bollig, JP. Katoen, C. Kern, M. Leucker, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Bollig, B., Katoen, J. P., Kern, C., &amp; Leucker, M. (2010). Learning communicating automata from MSCs. IEEE Tra" /><p class="c-article-references__text" id="ref-CR7">Bollig, B., Katoen, J. P., Kern, C., &amp; Leucker, M. (2010). Learning communicating automata from MSCs. <i>IEEE Transactions on Software Engineering</i>, <i>36</i>(3), 390–408.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2FTSE.2009.89" aria-label="View reference 7">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20communicating%20automata%20from%20MSCs&amp;journal=IEEE%20Transactions%20on%20Software%20Engineering&amp;volume=36&amp;issue=3&amp;pages=390-408&amp;publication_year=2010&amp;author=Bollig%2CB&amp;author=Katoen%2CJP&amp;author=Kern%2CC&amp;author=Leucker%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bouyer, P., Larsen, K. G., &amp; Markey, N. (2008). Model checking one-clock priced timed automata. Journal of Log" /><p class="c-article-references__text" id="ref-CR8">Bouyer, P., Larsen, K. G., &amp; Markey, N. (2008). Model checking one-clock priced timed automata. <i>Journal of Logical Methods in Computer Science</i>, <i>4</i>(2), 1–28.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Bouyer, U. Fahrenberg, KG. Larsen, N. Markey, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Bouyer, P., Fahrenberg, U., Larsen, K. G., &amp; Markey, N. (2011). Quantitative analysis of real-time systems usi" /><p class="c-article-references__text" id="ref-CR9">Bouyer, P., Fahrenberg, U., Larsen, K. G., &amp; Markey, N. (2011). Quantitative analysis of real-time systems using priced timed automata. <i>Communications of the ACM</i>, <i>54</i>(9), 78–87.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F1995376.1995396" aria-label="View reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Quantitative%20analysis%20of%20real-time%20systems%20using%20priced%20timed%20automata&amp;journal=Communications%20of%20the%20ACM&amp;volume=54&amp;issue=9&amp;pages=78-87&amp;publication_year=2011&amp;author=Bouyer%2CP&amp;author=Fahrenberg%2CU&amp;author=Larsen%2CKG&amp;author=Markey%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Carrasco, R., &amp; Oncina, J. (1994). Learning stochastic regular grammars by means of a state merging method. In" /><p class="c-article-references__text" id="ref-CR10">Carrasco, R., &amp; Oncina, J. (1994). Learning stochastic regular grammars by means of a state merging method. In <i>Proceedings of the international colloquium on grammatical inference and applications</i> (ICGIA 1994), pp. 139–152.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RC. Carrasco, J. Oncina, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Carrasco, R. C., &amp; Oncina, J. (1999). Learning deterministic regular grammars from stochastic samples in polyn" /><p class="c-article-references__text" id="ref-CR11">Carrasco, R. C., &amp; Oncina, J. (1999). Learning deterministic regular grammars from stochastic samples in polynomial time. <i>Journal of Theoretial Informatics and Applications</i>, <i>33</i>(1), 1–20.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1705851" aria-label="View reference 11 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1051%2Fita%3A1999102" aria-label="View reference 11">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0940.68071" aria-label="View reference 11 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20deterministic%20regular%20grammars%20from%20stochastic%20samples%20in%20polynomial%20time&amp;journal=Journal%20of%20Theoretial%20Informatics%20and%20Applications&amp;volume=33&amp;issue=1&amp;pages=1-20&amp;publication_year=1999&amp;author=Carrasco%2CRC&amp;author=Oncina%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Castro, J., &amp; Gavaldà, R. (2008). Towards feasible PAC-learning of probabilistic deterministic finite automata" /><p class="c-article-references__text" id="ref-CR12">Castro, J., &amp; Gavaldà, R. (2008). Towards feasible PAC-learning of probabilistic deterministic finite automata. In <i>Grammatical inference: Algorithms and applications</i>, pp. 163–174.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Chen, T., Han, T., Katoen, J. P., &amp; Mereacre, A. (2009). Quantitative model checking of continuous-time Markov" /><p class="c-article-references__text" id="ref-CR13">Chen, T., Han, T., Katoen, J. P., &amp; Mereacre, A. (2009). Quantitative model checking of continuous-time Markov chains against timed automata specifications. In <i>24th annual IEEE symposium on logic in computer science</i> pp. 309–318.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Chen, Y., &amp; Nielsen, T. D. (2012). Active learning of Markov decision processes for system verification. In Pr" /><p class="c-article-references__text" id="ref-CR14">Chen, Y., &amp; Nielsen, T. D. (2012). Active learning of Markov decision processes for system verification. In <i>Proceedings of the international conference on machine learning and applications</i> (ICMLA 2012), pp. 289–294.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Chen, Y., Mao, H., Jaeger, M., Nielsen, T. D., Larsen, K.G., &amp; Nielsen, B. (2012). Learning Markov models for " /><p class="c-article-references__text" id="ref-CR15">Chen, Y., Mao, H., Jaeger, M., Nielsen, T. D., Larsen, K.G., &amp; Nielsen, B. (2012). Learning Markov models for stationary system behaviors. In <i>NASA formal methods symposium</i> (NFM), pp. 216–230.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Clark, F. Thollard, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Clark, A., &amp; Thollard, F. (2004). PAC-learnability of probabilistic deterministic finite state automata. Journ" /><p class="c-article-references__text" id="ref-CR16">Clark, A., &amp; Thollard, F. (2004). PAC-learnability of probabilistic deterministic finite state automata. <i>Journal of Machine Learning Research</i>, <i>5</i>, 473–497.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2247988" aria-label="View reference 16 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1222.68094" aria-label="View reference 16 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=PAC-learnability%20of%20probabilistic%20deterministic%20finite%20state%20automata&amp;journal=Journal%20of%20Machine%20Learning%20Research&amp;volume=5&amp;pages=473-497&amp;publication_year=2004&amp;author=Clark%2CA&amp;author=Thollard%2CF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cobleigh, J. M., Giannakopoulou, D., &amp; Pasareanu, C. S. (2003). Learning assumptions for compositional verific" /><p class="c-article-references__text" id="ref-CR17">Cobleigh, J. M., Giannakopoulou, D., &amp; Pasareanu, C. S. (2003). Learning assumptions for compositional verification. In <i>Proceedings of the 9th international conference on tools and algorithms for the construction and analysis of systems</i> (TACAS), pp. 331–346.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="C. Courcoubetis, M. Yannakakis, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Courcoubetis, C., &amp; Yannakakis, M. (1995). The complexity of probabilistic verification. Journal of the ACM, 4" /><p class="c-article-references__text" id="ref-CR18">Courcoubetis, C., &amp; Yannakakis, M. (1995). The complexity of probabilistic verification. <i>Journal of the ACM</i>, <i>42</i>(4), 857–907.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1411788" aria-label="View reference 18 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1145%2F210332.210339" aria-label="View reference 18">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0885.68109" aria-label="View reference 18 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20complexity%20of%20probabilistic%20verification&amp;journal=Journal%20of%20the%20ACM&amp;volume=42&amp;issue=4&amp;pages=857-907&amp;publication_year=1995&amp;author=Courcoubetis%2CC&amp;author=Yannakakis%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DR. Cox, " /><meta itemprop="datePublished" content="1953" /><meta itemprop="headline" content="Cox, D. R. (1953). Some simple approximate tests for Poisson variates. Biometrika, 40(3/4), 354–360." /><p class="c-article-references__text" id="ref-CR19">Cox, D. R. (1953). Some simple approximate tests for Poisson variates. <i>Biometrika</i>, <i>40</i>(3/4), 354–360.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=58177" aria-label="View reference 19 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.2307%2F2333353" aria-label="View reference 19">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0051.10808" aria-label="View reference 19 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Some%20simple%20approximate%20tests%20for%20Poisson%20variates&amp;journal=Biometrika&amp;volume=40&amp;issue=3%2F4&amp;pages=354-360&amp;publication_year=1953&amp;author=Cox%2CDR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="de Higuera, C., &amp; Oncina, J. (2004). Learning stochastic finite automata. In Proceedings of the international " /><p class="c-article-references__text" id="ref-CR20">de Higuera, C., &amp; Oncina, J. (2004). Learning stochastic finite automata. In <i>Proceedings of the international conference on grammatical inference</i>, pp. 175–186.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="de la Higuera, C., &amp; Thollard, F. (2000). Identification in the limit with probability one of stochastic deter" /><p class="c-article-references__text" id="ref-CR21">de la Higuera, C., &amp; Thollard, F. (2000). Identification in the limit with probability one of stochastic deterministic finite automata. In <i>Proceedings of the international colloquium on grammatical inference: Algorithms and application</i> (ICGI 2000), pp. 141–156.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Desharnais, J., Gupta, V., Jagadeesan, R., &amp; Panangaden, P. (1999). Metrics for labeled Markov systems. In Pro" /><p class="c-article-references__text" id="ref-CR22">Desharnais, J., Gupta, V., Jagadeesan, R., &amp; Panangaden, P. (1999). Metrics for labeled Markov systems. In <i>Proceedings of international conference on concurrency theory</i> (CONCUR), pp. 258–273.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Feng, L., Han, T., Kwiatkowska, M. Z., &amp; Parker, D. (2011). Learning-based compositional verification for sync" /><p class="c-article-references__text" id="ref-CR23">Feng, L., Han, T., Kwiatkowska, M. Z., &amp; Parker, D. (2011). Learning-based compositional verification for synchronous probabilistic systems. In <i>9th international symposium on automated technology for verification and analysis</i> (ATVA), pp. 511–521.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="EA. Gehan, DG. Thomas, " /><meta itemprop="datePublished" content="1969" /><meta itemprop="headline" content="Gehan, E. A., &amp; Thomas, D. G. (1969). The performance of some two-sample tests in small samples with and witho" /><p class="c-article-references__text" id="ref-CR24">Gehan, E. A., &amp; Thomas, D. G. (1969). The performance of some two-sample tests in small samples with and without censoring. <i>Biometrika</i>, <i>56</i>(1), 127–132.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1093%2Fbiomet%2F56.1.127" aria-label="View reference 24">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20performance%20of%20some%20two-sample%20tests%20in%20small%20samples%20with%20and%20without%20censoring&amp;journal=Biometrika&amp;volume=56&amp;issue=1&amp;pages=127-132&amp;publication_year=1969&amp;author=Gehan%2CEA&amp;author=Thomas%2CDG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Giannakopoulou, D., &amp; Păsăreanu, C. S. (2005). Learning-based assume-guarantee verification (Tool Paper). In P" /><p class="c-article-references__text" id="ref-CR25">Giannakopoulou, D., &amp; Păsăreanu, C. S. (2005). Learning-based assume-guarantee verification (Tool Paper). In P. Godefroid (Ed.), <i>Model Checking Software: 12th International SPIN Workshop</i> (pp. 282–287). Berlin, Heidelberg: Springer.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="O. Grinchtein, B. Jonsson, M. Leucker, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Grinchtein, O., Jonsson, B., &amp; Leucker, M. (2005). Inference of timed transition systems. Journal of Electroni" /><p class="c-article-references__text" id="ref-CR26">Grinchtein, O., Jonsson, B., &amp; Leucker, M. (2005). Inference of timed transition systems. <i>Journal of Electronic Notes in Theoretical Compututer Science</i>, <i>138</i>(3), 87–99.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2208468" aria-label="View reference 26 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.entcs.2005.02.062" aria-label="View reference 26">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1272.68165" aria-label="View reference 26 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Inference%20of%20timed%20transition%20systems&amp;journal=Journal%20of%20Electronic%20Notes%20in%20Theoretical%20Compututer%20Science&amp;volume=138&amp;issue=3&amp;pages=87-99&amp;publication_year=2005&amp;author=Grinchtein%2CO&amp;author=Jonsson%2CB&amp;author=Leucker%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Grinchtein, O., Jonsson, B., &amp; Pettersson, P. (2006). Inference of event-recording automata using timed decisi" /><p class="c-article-references__text" id="ref-CR27">Grinchtein, O., Jonsson, B., &amp; Pettersson, P. (2006). Inference of event-recording automata using timed decision trees. In <i>Proceedings of the international conference on concurrency theory</i> (CONCUR), pp. 435–449.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Haverkort, B. R., Hermanns, H., &amp; Katoen, J. P. (2000). On the use of model checking techniques for dependabil" /><p class="c-article-references__text" id="ref-CR28">Haverkort, B. R., Hermanns, H., &amp; Katoen, J. P. (2000). On the use of model checking techniques for dependability evaluation. In <i>Proceedings of the IEEE symposium on reliable distributed systems</i> (SRDS 2000), pp. 228–237.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hérault, T., Lassaigne, R., Magniette, F., &amp; Peyronnet, S. (2004). Approximate probabilistic model checking. I" /><p class="c-article-references__text" id="ref-CR29">Hérault, T., Lassaigne, R., Magniette, F., &amp; Peyronnet, S. (2004). Approximate probabilistic model checking. In Steffen, B., Levi, G. (Eds.), <i>Verification, model checking, and abstract interpretation</i>. Lecture Notes in Computer Science, Vol. 2937, Springer, Berlin, pp. 307–329.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="Cd. Higuera, " /><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="Higuera, Cd. (2010). Grammatical inference: Learning automata and grammars. Cambridge: Cambridge University Pr" /><p class="c-article-references__text" id="ref-CR30">Higuera, Cd. (2010). <i>Grammatical inference: Learning automata and grammars</i>. Cambridge: Cambridge University Press.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Grammatical%20inference%3A%20Learning%20automata%20and%20grammars&amp;publication_year=2010&amp;author=Higuera%2CCd">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Jaeger, M., Mao, H., Larsen, K. G., &amp; Mardare, R. (2014). Continuity properties of distances for Markov proces" /><p class="c-article-references__text" id="ref-CR31">Jaeger, M., Mao, H., Larsen, K. G., &amp; Mardare, R. (2014). Continuity properties of distances for Markov processes. In <i>Proceedings of QEST 2014</i>, LNCS, Vol. 8657, pp. 297–312.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Jansen, D. N. (2002). Probabilistic UML statecharts for specification and verification a case study. In Procee" /><p class="c-article-references__text" id="ref-CR32">Jansen, D. N. (2002). Probabilistic UML statecharts for specification and verification a case study. In <i>Proceedings of the workshop on critical systems development with UML</i>, pp. 121–132.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Komuravelli, A., Pasareanu, C. S., &amp; Clarke, E. M. (2012). Learning probabilistic systems from tree samples. I" /><p class="c-article-references__text" id="ref-CR33">Komuravelli, A., Pasareanu, C. S., &amp; Clarke, E. M. (2012). Learning probabilistic systems from tree samples. In <i>Proceedings of the 27th annual IEEE/ACM symposium on logic in computer science</i>, pp. 441–450.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Kwiatkowska, M.Z., Norman, G., &amp; Parker, D. (2011). Prism 4.0: Verification of probabilistic real-time systems" /><p class="c-article-references__text" id="ref-CR34">Kwiatkowska, M.Z., Norman, G., &amp; Parker, D. (2011). Prism 4.0: Verification of probabilistic real-time systems. In <i>Proceedings of the international conference on computer aided verification</i> (CAV’11), pp. 585–591.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Laroussinie, F., Larsen, K. G., &amp; Weise, C. (1995). From timed automata to logic- and back. In Proceedings of " /><p class="c-article-references__text" id="ref-CR35">Laroussinie, F., Larsen, K. G., &amp; Weise, C. (1995). From timed automata to logic- and back. In <i>Proceedings of international symposim on mathematical foundations of computer science</i> (MFCS 1995), pp. 529–539.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Legay, A., Delahaye, B., &amp; Bensalem, S. (2010). Statistical model checking: An overview. In Proceedings of the" /><p class="c-article-references__text" id="ref-CR36">Legay, A., Delahaye, B., &amp; Bensalem, S. (2010). Statistical model checking: An overview. In <i>Proceedings of the first international conference on runtime verification</i>, Springer, Berlin, RV’10, pp. 122–135.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Leucker, M. (2007). Learning meets verification. In Proceedings of the international conference on formal meth" /><p class="c-article-references__text" id="ref-CR37">Leucker, M. (2007). Learning meets verification. In <i>Proceedings of the international conference on formal methods for components and objects</i> (FMCO 2007), pp. 127–151.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mao, H., &amp; Jaeger, M. (2012). Learning and model checking networks of I/O automata. In Proceedings of the four" /><p class="c-article-references__text" id="ref-CR38">Mao, H., &amp; Jaeger, M. (2012). Learning and model checking networks of I/O automata. In <i>Proceedings of the fourth Asian conference on machine learning</i> (ACML), pp. 285–300.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mao, H., Chen, Y., Jaeger, M., Nielsen, T. D., Larsen, K. G., &amp; Nielsen, B. (2011). Learning probabilistic aut" /><p class="c-article-references__text" id="ref-CR39">Mao, H., Chen, Y., Jaeger, M., Nielsen, T. D., Larsen, K. G., &amp; Nielsen, B. (2011). Learning probabilistic automata for model checking. In <i>Proceedings of the international conference on quantitative evaluation of system</i> (QEST 2011), pp. 111–120.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Mao, H., Chen, Y., Jaeger, M., Nielsen, T. D., Larsen, K. G., &amp; Nielsen, B. (2012). Learning Markov decision p" /><p class="c-article-references__text" id="ref-CR40">Mao, H., Chen, Y., Jaeger, M., Nielsen, T. D., Larsen, K. G., &amp; Nielsen, B. (2012). Learning Markov decision processes for model checking. In <i>Proceedings of the first workshop on quantities in formal methods</i> (QFM), pp. 49–63.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Niese, O. (2003). An integrated approach to testing complex systems. PhD thesis, Universität Dortmund." /><p class="c-article-references__text" id="ref-CR41">Niese, O. (2003). An integrated approach to testing complex systems. PhD thesis, Universität Dortmund.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Oncina, P. Garcia, E. Vidal, " /><meta itemprop="datePublished" content="1993" /><meta itemprop="headline" content="Oncina, J., Garcia, P., &amp; Vidal, E. (1993). Learning subsequential transducers for pattern recognition interpr" /><p class="c-article-references__text" id="ref-CR42">Oncina, J., Garcia, P., &amp; Vidal, E. (1993). Learning subsequential transducers for pattern recognition interpretation tasks. <i>IEEE Transactions on Pattern Analysis Machine Intelligence</i>, <i>15</i>(5), 448–458.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1109%2F34.211465" aria-label="View reference 42">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 42 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20subsequential%20transducers%20for%20pattern%20recognition%20interpretation%20tasks&amp;journal=IEEE%20Transactions%20on%20Pattern%20Analysis%20Machine%20Intelligence&amp;volume=15&amp;issue=5&amp;pages=448-458&amp;publication_year=1993&amp;author=Oncina%2CJ&amp;author=Garcia%2CP&amp;author=Vidal%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Pnueli, A. (1977). The temporal logic of programs. In Proceedings of the annual symposium on foundations of co" /><p class="c-article-references__text" id="ref-CR43">Pnueli, A. (1977). The temporal logic of programs. In <i>Proceedings of the annual symposium on foundations of computer science</i> (FOCS) pp. 46–57.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Rabin, M. O. (1963). Probabilistic automata. Information and Control, 6(3), 230–245. doi:10.1016/S0019-9958(63" /><p class="c-article-references__text" id="ref-CR44">Rabin, M. O. (1963). Probabilistic automata. <i>Information and Control, 6</i>(3), 230–245. doi:<a href="https://doi.org/10.1016/S0019-9958(63)90290-0">10.1016/S0019-9958(63)90290-0</a>. <a href="http://www.sciencedirect.com/science/article/pii/S0019995863902900">http://www.sciencedirect.com/science/article/pii/S0019995863902900</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Raffelt, H., &amp; Steffen, B. (2006). Learnlib: A library for automata learning and experimentation. In Proceedin" /><p class="c-article-references__text" id="ref-CR45">Raffelt, H., &amp; Steffen, B. (2006). Learnlib: A library for automata learning and experimentation. In <i>Proceedings of the international conference on fundamental approaches to software engineering</i> (FASE), pp. 377–380.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Ron, Y. Singer, N. Tishby, " /><meta itemprop="datePublished" content="1996" /><meta itemprop="headline" content="Ron, D., Singer, Y., &amp; Tishby, N. (1996). The power of amnesia: Learning probabilistic automata with variable " /><p class="c-article-references__text" id="ref-CR46">Ron, D., Singer, Y., &amp; Tishby, N. (1996). The power of amnesia: Learning probabilistic automata with variable memory length. <i>Machine Learning</i>, <i>25</i>(2–3), 117–149.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1023%2FA%3A1026490906255" aria-label="View reference 46">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0869.68066" aria-label="View reference 46 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 46 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20power%20of%20amnesia%3A%20Learning%20probabilistic%20automata%20with%20variable%20memory%20length&amp;journal=Machine%20Learning&amp;volume=25&amp;issue=2%E2%80%933&amp;pages=117-149&amp;publication_year=1996&amp;author=Ron%2CD&amp;author=Singer%2CY&amp;author=Tishby%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Ron, Y. Singer, N. Tishby, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Ron, D., Singer, Y., &amp; Tishby, N. (1998). On the learnability and usage of acyclic probabilistic finite automa" /><p class="c-article-references__text" id="ref-CR47">Ron, D., Singer, Y., &amp; Tishby, N. (1998). On the learnability and usage of acyclic probabilistic finite automata. <i>Journal of Computer and System Sciences</i>, <i>56</i>(2), 133–152.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1629686" aria-label="View reference 47 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1006%2Fjcss.1997.1555" aria-label="View reference 47">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0915.68124" aria-label="View reference 47 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 47 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20the%20learnability%20and%20usage%20of%20acyclic%20probabilistic%20finite%20automata&amp;journal=Journal%20of%20Computer%20and%20System%20Sciences&amp;volume=56&amp;issue=2&amp;pages=133-152&amp;publication_year=1998&amp;author=Ron%2CD&amp;author=Singer%2CY&amp;author=Tishby%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Segala, R. (1996). Modeling and verification of randomized distributed real-time systems. Technical report. Ca" /><p class="c-article-references__text" id="ref-CR48">Segala, R. (1996). <i>Modeling and verification of randomized distributed real-time systems</i>. Technical report. Cambridge, MA.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Sen, K., Viswanathan, M., &amp; Agha, G. (2004a). Learning continuous time Markov chains from sample executions. I" /><p class="c-article-references__text" id="ref-CR49">Sen, K., Viswanathan, M., &amp; Agha, G. (2004a). Learning continuous time Markov chains from sample executions. In <i>Proceedings of international conference on quantitative evaluation of systems</i> (QEST), pp. 146–155.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Sen, K., Viswanathan, M., &amp; Agha, G. (2004b). Statistical model checking of black-box probabilistic systems. I" /><p class="c-article-references__text" id="ref-CR50">Sen, K., Viswanathan, M., &amp; Agha, G. (2004b). Statistical model checking of black-box probabilistic systems. In Alur, R., Peled, D. (Eds.), <i>Computer aided verification</i>. Lecture Notes in Computer Science, Vol. 3114, pp. 202–215.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Singh, R., Giannakopoulou, D., &amp; Pasareanu, C. S. (2010). Learningcomponent interfaces with may and must abstr" /><p class="c-article-references__text" id="ref-CR51">Singh, R., Giannakopoulou, D., &amp; Pasareanu, C. S. (2010). Learningcomponent interfaces with may and must abstractions. In <i>Computer aided verification</i>. Lecture Notes in Computer Science, Vol. 3576, pp. 527–542.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Thollard, F., Dupont, P., &amp; de la Higuera, C. (2000). Probabilistic DFA inference using kullback-leibler diver" /><p class="c-article-references__text" id="ref-CR52">Thollard, F., Dupont, P., &amp; de la Higuera, C. (2000). Probabilistic DFA inference using kullback-leibler divergence and minimality. In <i>Proceedings of the international conference on machine learning</i> (ICML), pp. 975–982.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="WG. Tzeng, " /><meta itemprop="datePublished" content="1992" /><meta itemprop="headline" content="Tzeng, W. G. (1992). Learning probabilistic automata and markov chains via queries. Machine Learning, 8, 151–1" /><p class="c-article-references__text" id="ref-CR53">Tzeng, W. G. (1992). Learning probabilistic automata and markov chains via queries. <i>Machine Learning</i>, <i>8</i>, 151–166.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0749.68076" aria-label="View reference 53 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 53 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20probabilistic%20automata%20and%20markov%20chains%20via%20queries&amp;journal=Machine%20Learning&amp;volume=8&amp;pages=151-166&amp;publication_year=1992&amp;author=Tzeng%2CWG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="F. Breugel, J. Worrell, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="van Breugel, F., &amp; Worrell, J. (2005). A behavioural pseudometric for probabilistic transition system. Theoret" /><p class="c-article-references__text" id="ref-CR54">van Breugel, F., &amp; Worrell, J. (2005). A behavioural pseudometric for probabilistic transition system. <i>Theoretical Computer Science</i>, <i>331</i>, 115–142.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2120054" aria-label="View reference 54 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.tcs.2004.09.035" aria-label="View reference 54">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1070.68109" aria-label="View reference 54 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 54 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20behavioural%20pseudometric%20for%20probabilistic%20transition%20system&amp;journal=Theoretical%20Computer%20Science&amp;volume=331&amp;pages=115-142&amp;publication_year=2005&amp;author=Breugel%2CF&amp;author=Worrell%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Vardi, M. Y. (1985). Automatic verification of probabilistic concurrent finite-state programs. In Proceedings " /><p class="c-article-references__text" id="ref-CR55">Vardi, M. Y. (1985). Automatic verification of probabilistic concurrent finite-state programs. In <i>Proceedings of the IEEE symposium on foundations of computer science</i> (FOCS), pp. 327–338.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Vardi, M. Y. (1999). Probabilistic linear-time model checking: An overview of the automata-theoretic approach." /><p class="c-article-references__text" id="ref-CR56">Vardi, M. Y. (1999). Probabilistic linear-time model checking: An overview of the automata-theoretic approach. In <i>Proceedings of the international AMAST workshop on formal methods for real-time and probabilstic systems</i> (ARTS 1999), pp. 265–276.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Verwer, S. (2010). Efficient identification of timed automata—Theory and practice. PhD thesis, Technical Unive" /><p class="c-article-references__text" id="ref-CR57">Verwer, S. (2010). Efficient identification of timed automata—Theory and practice. PhD thesis, Technical University Delft.</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10994-016-5565-9-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">College of Computer Science, Sichuan University, Chengdu, 610065, China</p><p class="c-article-author-affiliation__authors-list">Hua Mao &amp; Yingke Chen</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Department of Computer Science, Aalborg University, 9220, Aalborg East, Denmark</p><p class="c-article-author-affiliation__authors-list">Manfred Jaeger, Thomas D. Nielsen, Kim G. Larsen &amp; Brian Nielsen</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Hua-Mao"><span class="c-article-authors-search__title u-h3 js-search-name">Hua Mao</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Hua+Mao&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Hua+Mao" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Hua+Mao%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Yingke-Chen"><span class="c-article-authors-search__title u-h3 js-search-name">Yingke Chen</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Yingke+Chen&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Yingke+Chen" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Yingke+Chen%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Manfred-Jaeger"><span class="c-article-authors-search__title u-h3 js-search-name">Manfred Jaeger</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Manfred+Jaeger&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Manfred+Jaeger" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Manfred+Jaeger%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Thomas_D_-Nielsen"><span class="c-article-authors-search__title u-h3 js-search-name">Thomas D. Nielsen</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Thomas D.+Nielsen&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Thomas D.+Nielsen" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Thomas D.+Nielsen%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Kim_G_-Larsen"><span class="c-article-authors-search__title u-h3 js-search-name">Kim G. Larsen</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Kim G.+Larsen&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Kim G.+Larsen" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Kim G.+Larsen%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Brian-Nielsen"><span class="c-article-authors-search__title u-h3 js-search-name">Brian Nielsen</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Brian+Nielsen&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Brian+Nielsen" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Brian+Nielsen%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10994-016-5565-9/email/correspondent/c1/new">Manfred Jaeger</a>.</p></div></div></section><section aria-labelledby="additional-information" data-title="Additional information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><p>Editors: Jeffrey Heinz, C. de la Higuera and Tim Oates.</p></div></div></section><section aria-labelledby="appendices"><div class="c-article-section" id="appendices-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="appendices">Appendices</h2><div class="c-article-section__content" id="appendices-content"><h3 class="c-article__sub-heading" id="App1">Appendix: Consistency of Alergia-style learning</h3><h3 class="c-article__sub-heading" id="Sec21">Overview</h3><p>In this appendix we give a detailed and general proof on the consistency of Alergia-like algorithms for learning finite stochastic automata. Our proof follows the same main lines of arguments as previous proofs presented in Carrasco and Oncina (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Carrasco, R. C., &amp; Oncina, J. (1999). Learning deterministic regular grammars from stochastic samples in polynomial time. Journal of Theoretial Informatics and Applications, 33(1), 1–20." href="/article/10.1007/s10994-016-5565-9#ref-CR11" id="ref-link-section-d52740e31650">1999</a>), de la Higuera and Thollard (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="de la Higuera, C., &amp; Thollard, F. (2000). Identification in the limit with probability one of stochastic deterministic finite automata. In Proceedings of the international colloquium on grammatical inference: Algorithms and application (ICGI 2000), pp. 141–156." href="/article/10.1007/s10994-016-5565-9#ref-CR21" id="ref-link-section-d52740e31653">2000</a>), Sen et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004a" title="Sen, K., Viswanathan, M., &amp; Agha, G. (2004a). Learning continuous time Markov chains from sample executions. In Proceedings of international conference on quantitative evaluation of systems (QEST), pp. 146–155." href="/article/10.1007/s10994-016-5565-9#ref-CR49" id="ref-link-section-d52740e31656">2004a</a>). However, we extend and improve on these existing works in several ways.</p><p>First, we provide results that are formulated on the basis of a very general automaton model, and thereby provide a uniform treatment of consistency for the basic Alergia algorithm, as well as for extensions such as DLMDPs ad DCTMCs as introduced in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec4">2</a>. Also, the general <i>stochastic reactive automaton model</i> introduced below easily accommodates models both with non-zero termination probabilities, i.e., defining probability distributions on <span class="mathjax-tex">\(\varSigma ^*\)</span>, and models without termination probabilities, i.e., defining probability distributions on <span class="mathjax-tex">\(\varSigma ^{\omega }\)</span>.</p><p>Second, in our proof we aim to make the statistical part of the argument more rigorous and self-contained: all previous consistency proofs – and also the one we propose in the following – depend on arguments about the error probabilities of the compatibility tests performed by the algorithm. The problem here is that the concrete tests performed depend on the structure of the specific FPTA, and thereby are dependent on the data. However, a test that would have a certain significance level if it was fixed prior to the observation of the data, may not have the same correctness guarantees if the fact that it is performed depends on the sampled data itself. A trivial example may illustrate the point: suppose we want to test the hypothesis that a coin is fair based on the empirical frequency <span class="mathjax-tex">\(\bar{h}\)</span> of heads in a sample of 100 tosses. For this we can find <span class="mathjax-tex">\(p,q&gt;0\)</span> with <span class="mathjax-tex">\(p&lt;q\)</span> such that <span class="mathjax-tex">\(P_{fair }(\bar{h}\not \in [1/2-p,1/2+q]) = P_{fair }(\bar{h}\not \in [1/2-q,1/2+p])=0.05\)</span>. Thus, reject if <span class="mathjax-tex">\(\bar{h}\not \in [1/2-p,1/2+q]\)</span> and reject if <span class="mathjax-tex">\(\bar{h}\not \in [1/2-p,1/2+q]\)</span> are both tests for the hypothesis <span class="mathjax-tex">\(P(h)=1/2\)</span> at significance level 0.05. However, if we perform the first test whenever <span class="mathjax-tex">\(\bar{h}\le 1/2\)</span>, and the second if <span class="mathjax-tex">\(\bar{h}&gt; 1/2\)</span>, then the resulting test no longer has a 0.05 significance level. Of course, in Alergia, the execution of tests and the data sample are not connected in such an inadmissible way as in this example. In order to correctly account for this fact in the consistency proof, we largely separate the statistical argument from the concrete execution runs of the algorithm, and, in effect, always consider all the statistical tests that could be performed given some possible data sample.</p><p>The separation of the statistical from the algorithmic aspect also is part of the third goal of our consistency proof, which is to obtain a modular argument that clearly identifies three main components that lead to consistency:</p><ul class="u-list-style-dash">
                      <li>
                        <p>algorithmic component: conditions on the procedure by which nodes in the initial FPTA are tested for compatibility and merged. This will lead only to a very simple and loose constraint on the algorithmic procedure.</p>
                      </li>
                      <li>
                        <p>data component: conditions on the sampling process for the data from which the automaton is learned.</p>
                      </li>
                      <li>
                        <p>statistical component: conditions on the statistical tests used to decide node compatibility</p>
                      </li>
                    </ul><p>This modular structure of the results facilitates their application to new or modified versions of existing algorithms.</p><h3 class="c-article__sub-heading" id="Sec22">Stochastic reactive automata model</h3><p>We define a general stochastic automaton model of which LMDPs and CTMCs are special cases. We then also provide a general concept for deterministic stochastic automata, of which DLMDPs and DCTMCs are special cases. Our model is reactive, in the sense that it takes inputs, and its stochastic behavior is conditioned on those inputs. All probabilistic aspects of the automaton are encoded by random variables associated with each state.</p>
                    <h3 class="c-article__sub-heading" id="FPar21">Definition 12</h3>
                    <p>A stochastic reactive finite automaton (SRFA)</p><div id="Equ33" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} {\mathcal {A}}=(Q,q^s,\varvec{X},\varSigma ^{in },succ ,obs ) \end{aligned}$$</span></div></div><p>is given by</p><ul class="u-list-style-dash">
                        <li>
                          <p>A finite set of states <i>Q</i> containing a designated start state <span class="mathjax-tex">\(q^s\)</span>.</p>
                        </li>
                        <li>
                          <p>Each state <span class="mathjax-tex">\(q\in Q\)</span> is labeled with random variables <span class="mathjax-tex">\(X^{(q)}_1,\ldots ,X^{(q)}_n\)</span>, where each <span class="mathjax-tex">\(X^{(q)}_i\)</span> takes values in some sample space <span class="mathjax-tex">\(\varOmega _i\)</span> (the same for all <i>q</i>), according to some parametric model <span class="mathjax-tex">\(\varTheta _i\)</span> (the same for all <i>q</i>).</p>
                        </li>
                        <li>
                          <p>A finite input alphabet <span class="mathjax-tex">\(\varSigma ^{in }\)</span>.</p>
                        </li>
                        <li>
                          <p>A successor function <span class="mathjax-tex">\(succ : Q\times \varSigma ^{in }\times \prod _{i=1}^n \varOmega _i \rightarrow Q\)</span>
                                       </p>
                        </li>
                        <li>
                          <p>An observation function <span class="mathjax-tex">\(obs : \varSigma ^{in }\times \prod _{i=1}^n \varOmega _i \rightarrow {\mathcal {P}}\{1,\ldots ,n\}\)</span>.</p>
                        </li>
                      </ul>
                              
                  <p>We denote <span class="mathjax-tex">\(\prod _{i=1}^n \varOmega _i\)</span> with <span class="mathjax-tex">\(\varvec{\varOmega }\)</span>, and <span class="mathjax-tex">\((\omega _1,\ldots ,\omega _n)\)</span> with <span class="mathjax-tex">\(\varvec{\omega }\)</span>. <span class="mathjax-tex">\(obs (\sigma ,\varvec{\omega })\)</span> contains the indices of the random variables that are observed when the input is <span class="mathjax-tex">\(\sigma \)</span>, and the <span class="mathjax-tex">\(\varvec{\omega }\)</span> are the sampled values of <span class="mathjax-tex">\((X^{(q)}_1,\ldots ,X^{(q)}_n)\)</span>. We can then define the <i>observation space</i>
                              </p><div id="Equ34" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} Obs := \{ (\sigma , (\omega _i)_{i\in obs (\sigma ,\varvec{\omega })}) \mid \sigma \in \varSigma ^{in }, \varvec{\omega }\in \varvec{\varOmega }) \} \end{aligned}$$</span></div></div><p>Given an input string <span class="mathjax-tex">\(\pi \in (\varSigma ^{in })^{\omega }\)</span>, a SRFA defines a probability distribution over the space of state-observation sequences <span class="mathjax-tex">\((Q \times Obs )^{\omega }\)</span> by assuming that the random variables <span class="mathjax-tex">\(\varvec{X}^{(q)}\)</span> are independent at each state <i>q</i>, so that their joint distribution defines distributions for the successor state and the next observation.</p><p>By a slight abuse of notation, we also use <span class="mathjax-tex">\(obs (\sigma ,\varvec{\omega })\)</span> to denote <span class="mathjax-tex">\((\sigma , (\omega _i)_{i\in obs (\sigma ,\varvec{\omega })})\)</span>. We use <span class="mathjax-tex">\(\varvec{o}\)</span> to denote elements of <i>Obs</i>.</p>
                    <h3 class="c-article__sub-heading" id="FPar22">Definition 13</h3>
                    <p>A stochastic automaton is <i>finite-branching deterministic</i> (called DSRFA), if there exists an equivalence relation <span class="mathjax-tex">\(\equiv \)</span> on <i>Obs</i>, so that</p><ul class="u-list-style-dash">
                        <li>
                          <p>
                                          <span class="mathjax-tex">\(\equiv \)</span> partitions <i>Obs</i> into finitely many equivalence classes</p>
                        </li>
                        <li>
                          <p>
                            <span class="mathjax-tex">\(obs (\sigma ,\varvec{\omega }) \equiv obs (\sigma ',\varvec{\omega }') \Rightarrow \forall q: succ (q,\sigma ,\varvec{\omega }) = succ (q,\sigma ',\varvec{\omega }')\)</span>
                          </p>
                        </li>
                      </ul><p>The equivalence class of <span class="mathjax-tex">\(\varvec{o}\in Obs \)</span>, is denoted <span class="mathjax-tex">\([\varvec{o}]\)</span>, and <span class="mathjax-tex">\([Obs ]\)</span> is the set of all equivalence classes. In finite-branching deterministic automata we can also denote <span class="mathjax-tex">\(succ (q,\sigma ,\varvec{\omega })\)</span> as <span class="mathjax-tex">\(succ (q,\varvec{o})\)</span>, or <span class="mathjax-tex">\(succ (q,[\varvec{o}])\)</span>.</p>
                  
                    <h3 class="c-article__sub-heading" id="FPar23">Example 5</h3>
                    <p>We show how DLMDPs as described in Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar3">3</a> can be represented as a DSRFA. We assume there also is an alphabet <span class="mathjax-tex">\(\varSigma ^{out }\)</span> of observable output symbols. On a given input <span class="mathjax-tex">\(\sigma ^i\in \varSigma ^{in }\)</span> the automaton makes a random transition to a state labeled with <span class="mathjax-tex">\(\sigma ^o\in \varSigma ^{out }\)</span>, so that the successor state is uniquely determined by the <span class="mathjax-tex">\((\sigma ^i,\sigma ^o)\)</span> pair.</p>
                    <p>To represent this as a DSRFA, we assume that each state is labeled by random variables <span class="mathjax-tex">\(X_{\sigma ^i}\)</span> 
                                 <span class="mathjax-tex">\((\sigma ^i\in \varSigma ^{in })\)</span> with values in <span class="mathjax-tex">\(\varSigma ^{out }\)</span>. <span class="mathjax-tex">\(X_{\sigma ^i}\)</span> represents the conditional distribution over the next output symbol, given input <span class="mathjax-tex">\(\sigma ^i\)</span>. Given input <span class="mathjax-tex">\(\sigma ^i\in \varSigma ^{in }\)</span> one observes the value of the relevant variable <span class="mathjax-tex">\(X_{\sigma ^i}\)</span>, i.e., <span class="mathjax-tex">\(obs (\sigma ^i, (X^{(q)}_{\sigma })_{\sigma \in \varSigma ^{in }})=(\sigma ^i,X^{(q)}_{\sigma ^i})\)</span>. Then <span class="mathjax-tex">\(succ (q,\sigma ^i, (X^{(q)}_{\sigma })_{\sigma \in \varSigma ^{in }})\)</span> is the unique <span class="mathjax-tex">\(q'\in Q\)</span> defined by <span class="mathjax-tex">\(q,\ \sigma ^i,\ X^{(q)}_{\sigma ^i}\)</span>. In this case, the equivalence class <span class="mathjax-tex">\([\varvec{o}]\)</span> is just the singleton <span class="mathjax-tex">\(\varvec{o}\)</span>.</p>
                    <p>To expand this to DCTMCs, one may add a real-valued delay variable <span class="mathjax-tex">\(X_T\)</span>, e.g. with an exponential distribution. Assuming that the delay time is always observed, then <span class="mathjax-tex">\(obs (\sigma ^i, X_T, (X^{(q)}_{\sigma })_{\sigma \in \varSigma ^{in }})= (\sigma ^i, X_T, X^{(q)}_{\sigma ^i})\)</span>. Furthermore <span class="mathjax-tex">\((\sigma ^i, X_T, X^{(q)}_{\sigma ^i}) \equiv \)</span> 
                                 <span class="mathjax-tex">\( ({\sigma ^i}', X'_T, {X^{(q)}_{\sigma ^i}}')\)</span> iff <span class="mathjax-tex">\(\sigma ^i={\sigma ^i}'\)</span>, and <span class="mathjax-tex">\(X^{(q)}_{\sigma ^i}={X^{(q)}_{\sigma ^i}}'\)</span>.</p>
                  <p>For random variables <i>X</i>, <i>Y</i> we write <span class="mathjax-tex">\(X\approx Y\)</span> if <i>X</i> and <i>Y</i> have the same distribution.</p>
                    <h3 class="c-article__sub-heading" id="FPar24">Definition 14</h3>
                    <p>Two states <span class="mathjax-tex">\(q,q'\in Q\)</span> are said to be <i>locally compatible</i>, written <span class="mathjax-tex">\(q\sim _lq'\)</span>, if <span class="mathjax-tex">\(X^{(q)}_i\approx X^{(q')}_i\)</span> for <span class="mathjax-tex">\(i=1,\ldots ,n\)</span>. They are said to be <i>globally compatible</i>, written <span class="mathjax-tex">\(q\sim q'\)</span>, if <span class="mathjax-tex">\(q\sim _lq'\)</span>, and <span class="mathjax-tex">\(succ (q,\bar{\varvec{o}})\sim _lsucc (q',\bar{\varvec{o}})\)</span> for all <span class="mathjax-tex">\(\bar{\varvec{o}}\in Obs ^*\)</span>.</p>
                  <p>The relation <span class="mathjax-tex">\(q\sim q'\)</span> is an equivalence relation on <i>Q</i>. The automaton obtained by factoring <span class="mathjax-tex">\({\mathcal {A}}\)</span> over this equivalence relation is denoted <span class="mathjax-tex">\({\mathcal {A}}/\sim \)</span>.</p><h3 class="c-article__sub-heading" id="Sec23">Computation prefix tree</h3><p>For a finite-branching deterministic automaton <span class="mathjax-tex">\({\mathcal {A}}\)</span>, we can define the computation prefix tree:</p>
                    <h3 class="c-article__sub-heading" id="FPar25">Definition 15</h3>
                    <p>The computation prefix tree (CPT) for <span class="mathjax-tex">\({\mathcal {A}}\)</span> is the infinite rooted tree in which every node <i>v</i> has one successor <span class="mathjax-tex">\(succ (v,[\varvec{o}])\)</span> for each equivalence class <span class="mathjax-tex">\([\varvec{o}]\in [Obs ]\)</span>.</p>
                  <p>Each node <i>v</i> in the CPT can be labeled with a state <span class="mathjax-tex">\(q(v)\in Q\)</span>: the root is labeled with <span class="mathjax-tex">\(q^s\)</span>, and the <span class="mathjax-tex">\([\varvec{o}]\)</span>-successor of a node labeled with <i>q</i> is labeled with <span class="mathjax-tex">\(succ (q,\varvec{o})\)</span>. For a finite computation (sequence of observations) <span class="mathjax-tex">\(\bar{\varvec{o}}=\varvec{o}_1,\ldots ,\varvec{o}_k\)</span> one inductively defines the node <span class="mathjax-tex">\(v\in T\)</span> 
                              <i>reached by</i> 
                              <span class="mathjax-tex">\(\bar{\varvec{o}}\)</span>: For <span class="mathjax-tex">\(k=0\)</span> the node reached by <span class="mathjax-tex">\(\bar{\varvec{o}}\)</span> is the root. For <span class="mathjax-tex">\(k\ge 1\)</span> the node reached by <span class="mathjax-tex">\(\varvec{o}_1,\ldots ,\varvec{o}_k\)</span> is the <span class="mathjax-tex">\([\varvec{o}_k]\)</span>-successor of the node reached by <span class="mathjax-tex">\(\varvec{o}_1,\ldots ,\varvec{o}_{k-1}\)</span>. Each node <i>v</i> is reached by a unique observation sequence, denoted <span class="mathjax-tex">\(\bar{\varvec{o}}(v)\)</span>.</p><p>Without loss of generality, we from now on assume that all states in <span class="mathjax-tex">\({\mathcal {A}}\)</span> are reachable by some computation, so that every state <span class="mathjax-tex">\(q\in Q\)</span> also appears as a node label in the CPT.</p>
                    <h3 class="c-article__sub-heading" id="FPar26">Definition 16</h3>
                    <p>Let <span class="mathjax-tex">\({\mathcal {A}}\)</span> be a DSFA with <span class="mathjax-tex">\(|Q|=m\)</span> and <i>T</i> its CPT. A <i>kernel</i> of <i>T</i> is any initial part <i>K</i> of <i>T</i> that contains for each state <span class="mathjax-tex">\(q\in Q\)</span> a node <i>v</i>(<i>q</i>) labeled with <i>q</i>. If <i>K</i> is a kernel, then <span class="mathjax-tex">\(K^{+1}\)</span> is the union of <i>K</i> with all <span class="mathjax-tex">\([\varvec{o}]\)</span>-successors (<span class="mathjax-tex">\([\varvec{o}]\in [Obs ]\)</span>) of nodes in <i>K</i>. The <i>critical region</i> of <i>K</i> is the extension of <i>K</i> by the set of all nodes <span class="mathjax-tex">\(v\in T\)</span> reachable from <i>K</i> by a path of length at most <span class="mathjax-tex">\(m^2\)</span>.</p>
                  <p>In most accounts of Alergia-like learning algorithms, it is assumed that an initial part of the CPT is constructed from the data. We take an essentially equivalent, but conceptually slightly different view, and let the data only increment empirical count variables at the nodes of the full, infinite tree. This, in particular, serves the purpose to consider sets of tests independently from particular data samples, i.e., our analysis will be based on always considering all possible compatibility tests between nodes of the full CPT that would be performed given any sample.</p><p>Let <i>v</i> be a node in <i>T</i>. For each <span class="mathjax-tex">\(i=1,\ldots ,n\)</span> we associate with <i>v</i> an <i>empirical distribution variable</i> 
                              <span class="mathjax-tex">\(\hat{X}_i^{(v)}\)</span> whose values are multisets of values from <span class="mathjax-tex">\(\varOmega _i\)</span> (for finite <span class="mathjax-tex">\(\varOmega _i\)</span> such a multiset is just given by an integer count for each value in <span class="mathjax-tex">\(\varOmega _i\)</span>).</p><p>For <span class="mathjax-tex">\(j=1,\ldots ,N\)</span> let <span class="mathjax-tex">\(\bar{\varvec{o}}^{(j)}=\varvec{o}^{(j)}_1,\ldots ,\varvec{o}^{(j)}_{k(j)}\)</span> be an observed computation of length <i>k</i>(<i>j</i>). The sample <span class="mathjax-tex">\((\bar{\varvec{o}}^{(j)})_j\)</span> defines the empirical distributions at a node <span class="mathjax-tex">\(v\in T\)</span> that is reached by observation sequence <span class="mathjax-tex">\(\bar{\varvec{o}}(v)\)</span> of length <i>k</i> as follows: the multiset <span class="mathjax-tex">\(\hat{X}_i^{(v)}\)</span> is the union of all <span class="mathjax-tex">\(\omega _i\)</span> that are observed in those <span class="mathjax-tex">\(\varvec{o}^{(j)}_{k+1}\)</span> for <i>j</i> such that <span class="mathjax-tex">\(k(j)\ge k+1\)</span>, and <span class="mathjax-tex">\(\varvec{o}^{(j)}_1,\ldots ,\varvec{o}^{(j)}_k=\bar{\varvec{o}}(v)\)</span>.</p><h3 class="c-article__sub-heading" id="Sec24">State merging in the CPT</h3><p>Alergia-like algorithms merge nodes of the CPT based on compatibility tests between pairs of nodes. The following definition introduces a binary relation representing the outcome of such tests.</p>
                    <h3 class="c-article__sub-heading" id="FPar27">Definition 17</h3>
                    <p>A <i>compatibility test relation</i> on <i>T</i> is a binary symmetric and reflexive relation <span class="mathjax-tex">\(\sim _t\)</span> between the nodes of <i>T</i>. Furthermore, we define <span class="mathjax-tex">\(v \sim _t^*v'\)</span> iff <span class="mathjax-tex">\(v\sim _tv'\)</span>, and for all <span class="mathjax-tex">\(\bar{\varvec{o}}\in Obs ^*\)</span>: <span class="mathjax-tex">\(succ (v,\bar{\varvec{o}})\sim _tsucc (v',\bar{\varvec{o}})\)</span>.</p>
                  <p>Based on recursively applied compatibility tests, Alergia-like algorithms actually compute the <span class="mathjax-tex">\(\sim _t^*\)</span> relation, and merge pairs of nodes <span class="mathjax-tex">\(v,v'\)</span> (and their successors) for which <span class="mathjax-tex">\(v\sim _t^*v'\)</span>. At each stage in the algorithm, an equivalence relation on <i>T</i> describes the equivalence classes of merged nodes. In the following, we define equivalence relations <span class="mathjax-tex">\(\sim _i^{\textit{tc}}\)</span> that describe the equivalence classes of merged nodes after <i>i</i> iterations of the algorithm. For this we assume a fixed (but arbitrary) enumeration of the nodes of <i>T</i>:</p><div id="Equ35" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} T=v_1,v_2,v_3,\ldots \end{aligned}$$</span></div></div>
                           
                    <h3 class="c-article__sub-heading" id="FPar28">Definition 18</h3>
                    <p>For <span class="mathjax-tex">\(i=1,2,\ldots \)</span> we define for <span class="mathjax-tex">\(v,v'\in T\)</span>: <span class="mathjax-tex">\(v\sim _iv'\)</span> iff there exist <span class="mathjax-tex">\(j,h \le i\)</span> and <span class="mathjax-tex">\(\bar{\varvec{o}}\in Obs ^*\)</span>, such that <span class="mathjax-tex">\(v_j \sim _t^*v_h\)</span>, <span class="mathjax-tex">\(v=succ (v_j,\bar{\varvec{o}})\)</span>, and <span class="mathjax-tex">\(v'=succ (v_h,\bar{\varvec{o}})\)</span>. Let <span class="mathjax-tex">\(\sim _i^{\textit{tc}}\)</span> be the transitive closure of <span class="mathjax-tex">\(\sim _i\)</span>.</p>
                  <p>The following lemma stipulates sufficient conditions on <span class="mathjax-tex">\(\sim _t\)</span> for the algorithm to terminate with the correctly identified equivalence classes of <span class="mathjax-tex">\({\mathcal {A}}/\sim \)</span>.</p>
                    <h3 class="c-article__sub-heading" id="FPar29">Lemma 1</h3>
                    <p>Let <span class="mathjax-tex">\(k\ge 1\)</span> be such that <span class="mathjax-tex">\(K^{+1}= \{v_1,\ldots ,v_k\}\)</span> for some kernel <i>K</i> of <i>T</i>. Let <i>C</i> be the critical region for <i>K</i>. Assume that <span class="mathjax-tex">\(\sim _t\)</span> satisfies the following two conditions:</p><ol class="u-list-style-none">
                        <li>
                          <span class="u-custom-list-number">(i)</span>
                          
                            <p>for all <span class="mathjax-tex">\(v,v'\)</span> in <i>C</i>: <span class="mathjax-tex">\(v\sim _tv'\)</span> iff <span class="mathjax-tex">\(q(v)\sim _lq(v')\)</span> (correct test results on <i>C</i>)</p>
                          
                        </li>
                        <li>
                          <span class="u-custom-list-number">(ii)</span>
                          
                            <p>for all <span class="mathjax-tex">\(j,h\le k\)</span>, and all <span class="mathjax-tex">\(\bar{\varvec{o}}\in Obs ^*\)</span>: if <span class="mathjax-tex">\(q(succ (v_j,\bar{\varvec{o}}))\sim _lq(succ (v_h,\bar{\varvec{o}}))\)</span>, then <span class="mathjax-tex">\(succ (v_j,\bar{\varvec{o}})\sim _tsucc (v_h,\bar{\varvec{o}})\)</span> (no false rejections in relevant tests)</p>
                          
                        </li>
                      </ol><p>Then for all <span class="mathjax-tex">\(v,v'\in T\)</span>: <span class="mathjax-tex">\(v\sim _k^{\textit{tc}}v'\ \Leftrightarrow q(v)\sim q(v')\)</span>.</p>
                  
                    <h3 class="c-article__sub-heading" id="FPar30">Proof</h3>
                    <p>First assume that <span class="mathjax-tex">\(v\sim _k^{\textit{tc}}v'\)</span>. It is sufficient to consider the case where <span class="mathjax-tex">\(v\sim _kv'\)</span>: if in that case <span class="mathjax-tex">\(q(v)\sim q(v')\)</span>, this will also be true in the general case <span class="mathjax-tex">\(v\sim _k^{\textit{tc}}v'\)</span>, since <span class="mathjax-tex">\(\sim \)</span> itself is a transitive relation.</p>
                    <p>Assume, then, that <span class="mathjax-tex">\(v\sim _kv'\)</span>, and let <span class="mathjax-tex">\(v_j,v_h\in K\)</span> for <span class="mathjax-tex">\(v,v'\)</span> as given by Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar28">18</a>. It is sufficient to show that <span class="mathjax-tex">\(q(v_j)\sim q(v_h)\)</span>. Assume <span class="mathjax-tex">\(q(v_j)\not \sim q(v_h)\)</span>. Then <span class="mathjax-tex">\(q(v_j)\not \sim _lq(v_h)\)</span>, or for some computation sequence <span class="mathjax-tex">\(\bar{\varvec{o}}\)</span>: <span class="mathjax-tex">\(succ (q(v_j),\bar{\varvec{o}})\not \sim _lsucc (q(v_h),\bar{\varvec{o}})\)</span>. The length of <span class="mathjax-tex">\(\bar{\varvec{o}}\)</span> can be bounded by <span class="mathjax-tex">\(m^2\)</span>, since any pair of states reachable from <span class="mathjax-tex">\(q(v_j),q(v_h)\)</span> is reachable within at most <span class="mathjax-tex">\(m^2\)</span> steps. Thus, <span class="mathjax-tex">\(succ (v_j,\bar{\varvec{o}})\)</span>, <span class="mathjax-tex">\(succ (v_h,\bar{\varvec{o}})\in C\)</span>, and by (i), <span class="mathjax-tex">\(succ (v_j,\bar{\varvec{o}})\not \sim _tsucc (v_h,\bar{\varvec{o}})\)</span>, so that <span class="mathjax-tex">\(v_j \not \sim _t^*v_h\)</span>, a contradiction.</p>
                    <p>For the converse direction, we first note that the statement is true for <span class="mathjax-tex">\(v,v'\in K^{+1}\)</span>, because then <span class="mathjax-tex">\(q(v)\sim q(v')\)</span> implies <span class="mathjax-tex">\(v\sim _t^*v'\)</span> by (i) and (ii), and therefore also <span class="mathjax-tex">\(v\sim _kv'\)</span>.</p>
                    <p>For the general case we proceed as follows: we show that for every <span class="mathjax-tex">\(v\in T\)</span> there exists <span class="mathjax-tex">\(v_K\in K\)</span> with <span class="mathjax-tex">\(v\sim _k^{\textit{tc}}v_K\)</span>. Then, for <span class="mathjax-tex">\(v,v'\in T\)</span> with <span class="mathjax-tex">\(q(v)\sim q(v')\)</span> we obtain <span class="mathjax-tex">\(v\sim _k^{\textit{tc}}v_K\)</span>, <span class="mathjax-tex">\(v'\sim _k^{\textit{tc}}v'_K\)</span>. By the first part of the proof, then <span class="mathjax-tex">\(q(v)\sim q(v_K)\)</span>, and <span class="mathjax-tex">\(q(v')\sim q(v'_K)\)</span>, and hence also <span class="mathjax-tex">\(q(v_K)\sim q(v'_K)\)</span>, and <span class="mathjax-tex">\(v\sim _k^{\textit{tc}}v'\)</span>.</p>
                    <p>Assume that there exists <span class="mathjax-tex">\(v\in T\setminus K^{+1}\)</span> for which no <span class="mathjax-tex">\(v_K\)</span> exists. Let <i>v</i> be such a counterexample that is minimal in the sense that <span class="mathjax-tex">\(v=succ (v_0,\varvec{o})\)</span>, <span class="mathjax-tex">\(v_0\in K^{+1}\setminus K\)</span>, and <span class="mathjax-tex">\(\mid \! \varvec{o} \!\mid \)</span> (i.e., the distance of <i>v</i> to <span class="mathjax-tex">\(K^{+1}\)</span>) is minimal. For <span class="mathjax-tex">\(v_0\)</span> there exists <span class="mathjax-tex">\(v_1\in K\)</span> with <span class="mathjax-tex">\(q(v_0)\sim q(v_1)\)</span>, and therefore <span class="mathjax-tex">\(v_0\sim _t^*v_1\)</span>. Let <span class="mathjax-tex">\(v'=succ (v_1,\varvec{o})\)</span>. Then <span class="mathjax-tex">\(v\sim _kv'\)</span>. The distance of <span class="mathjax-tex">\(v'\)</span> to <span class="mathjax-tex">\(K^{+1}\)</span> is less than <span class="mathjax-tex">\(\mid \! \varvec{o} \!\mid \)</span>, and therefore <span class="mathjax-tex">\(v'\sim _k^{\textit{tc}}v_K\)</span> for some <span class="mathjax-tex">\(v_K\in K\)</span>. Thus, also <span class="mathjax-tex">\(v\sim _k^{\textit{tc}}v_K\)</span>, a contradiction. <span class="mathjax-tex">\(\square \)</span>
                              </p>
                  <p>Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar28">18</a> reflects a quite high-level description of an iterative state-merging procedure that abstracts from several implementation details present in our version of the Alergia algorithm as described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec8">3</a>. For instance, the definition of <span class="mathjax-tex">\(\sim _i\)</span> does not take into account that in our algorithm we test the compatibility of a node <span class="mathjax-tex">\(q_b\)</span> (corresponding to the next node <span class="mathjax-tex">\(v_i\)</span> considered in the enumeration of <i>T</i> according to Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar28">18</a>) with candidate nodes <span class="mathjax-tex">\(q_r\)</span> (corresponding to the nodes <span class="mathjax-tex">\(v_1,\ldots ,v_{i-1}\)</span> in our enumeration) in lexicographic order of <span class="mathjax-tex">\(q_r\)</span>, and that once one such compatibility is found, no further compatibilities of <span class="mathjax-tex">\(q_b\)</span> with other nodes <span class="mathjax-tex">\(q_r\)</span> are tested. Due to these differences between the procedural merge strategies in concrete implementations, and the abstract merge relations <span class="mathjax-tex">\(\sim _i\)</span>, it is not the case that in all cases the final equivalence classes over states computed by the algorithm coincide with the limit of <span class="mathjax-tex">\(\sim _i^{\textit{tc}}\)</span> as <span class="mathjax-tex">\(i\rightarrow \infty \)</span>. However, these two equivalence relations will be the same if condition (i) of Lemma <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar29">1</a> holds: in that case, the test relation <span class="mathjax-tex">\(\sim _t\)</span> is guaranteed to be an equivalence relation on <i>C</i>, and implementation details that influence which representatives of an equivalence class are used for compatibility testing do not affect the outcome.</p><p>The only necessary procedural aspect we have to require of an implementation in order to guarantee that under the conditions of Lemma <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar29">1</a> the computed equivalence relation coincides with <span class="mathjax-tex">\(\sim _k^{\textit{tc}}\)</span> is that nodes of the CPT are processed in a fixed order, which is not influenced by the data sample.</p><p>We will now investigate conditions under which it is ensured that <span class="mathjax-tex">\(\sim _t\)</span> will satisfy the conditions of Lemma <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar29">1</a> if <span class="mathjax-tex">\(\sim _t\)</span> is defined by statistical tests of the relation <span class="mathjax-tex">\(\sim _l\)</span>. This will be a purely statistical question without any reference to algorithmic procedures.</p><h3 class="c-article__sub-heading" id="Sec25">Statistical tests</h3><p>We assume that the relation <span class="mathjax-tex">\(\sim _t\)</span> is defined by statistical tests <span class="mathjax-tex">\(\sim _{t,i}\)</span> for the local equivalences <span class="mathjax-tex">\(X^{(q(v))}_i\approx X^{(q(v'))}_i\)</span> as <span class="mathjax-tex">\(\sim _t=\cap _{i=1}^n \sim _{t,i}\)</span>.</p><p>According to the terminology and notation introduced in Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar21">12</a>, a random variable <i>X</i> has a distribution on a state space <span class="mathjax-tex">\(\varOmega \)</span> characterized by a parameter <span class="mathjax-tex">\(\theta \in \varTheta \)</span>. In the following, we denote this distribution by <span class="mathjax-tex">\(P_{\theta }\)</span>. By a slight abuse of notation, we also use <span class="mathjax-tex">\(P_{\theta }\)</span> to denote the distributions induced on <span class="mathjax-tex">\(\varOmega ^N\)</span> (<span class="mathjax-tex">\(N\ge 1\)</span>) and <span class="mathjax-tex">\(\varOmega ^{\infty }\)</span> by independent random sampling from <span class="mathjax-tex">\(P_{\theta }\)</span>. Furthermore, <span class="mathjax-tex">\(P_{\theta _1\times \theta _2}\)</span> denotes the sampling distribution for two independent samples according to <span class="mathjax-tex">\(P_{\theta _1}\)</span> and <span class="mathjax-tex">\(P_{\theta _2}\)</span>, respectively. For an infinite sample sequence <span class="mathjax-tex">\(\varvec{\omega }\in \varOmega ^{\infty }\)</span> we denote by <span class="mathjax-tex">\(\varvec{\omega }(N)\)</span> the initial sequence of <i>N</i> samples.</p>
                    <h3 class="c-article__sub-heading" id="FPar31">Definition 19</h3>
                    <p>A <i>two-sample test</i> for equivalence for the parametric family <span class="mathjax-tex">\(\{P_{\theta }\mid \theta \in \varTheta \}\)</span> is a mapping</p><div id="Equ36" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \mathbb R^{&gt;0}\times \bigcup _{N\in \mathbb N}\varOmega ^N \times \bigcup _{N\in \mathbb N}\varOmega ^N \rightarrow \{ {accept},{reject}\} \end{aligned}$$</span></div></div><p>such that for all <span class="mathjax-tex">\(\theta \in \varTheta \)</span>:</p><div id="Equ7" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P_{\theta \times \theta }( \{ (\varvec{\omega }_1,\varvec{\omega }_2) \in \varOmega ^{N_1}\times \varOmega ^{N_2} \mid T(\epsilon ,\varvec{\omega }_1,\varvec{\omega }_2)=reject \})&lt;\epsilon . \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (7)
                </div></div><p>Furthermore, we require that for all <span class="mathjax-tex">\(\epsilon &gt;0\)</span>
                                 </p><div id="Equ8" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} T(\epsilon ,\varvec{\omega }_1,\varvec{\omega }_2)=accept \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (8)
                </div></div><p>if <span class="mathjax-tex">\(\mid \! \varvec{\omega }_1 \!\mid =0\)</span> or <span class="mathjax-tex">\(\mid \! \varvec{\omega }_2 \!\mid =0\)</span>.</p>
                  <p>In the following we use <span class="mathjax-tex">\(\varOmega (f(N))\)</span> and <i>O</i>(<i>f</i>(<i>N</i>)) in the usual complexity-theoretic sense to denote the classes of functions that grow at least, respectively at most, as fast as <i>f</i>(<i>N</i>). Note, in particular, that <span class="mathjax-tex">\(\varOmega \)</span> now appears with two distinct meanings: as a function class, and as a sample space.</p>
                    <h3 class="c-article__sub-heading" id="FPar32">Definition 20</h3>
                    <p>Let <span class="mathjax-tex">\(h:\mathbb N\rightarrow \mathbb R\)</span> be non-decreasing. A two-sample test <i>T</i> is <i>strongly h-consistent</i>, if there exists a sequence <span class="mathjax-tex">\((\epsilon _N)_N\)</span> with</p><ol class="u-list-style-none">
                        <li>
                          <span class="u-custom-list-number">(i-a)</span>
                          
                            <p>
                              <span class="mathjax-tex">\(\sum _N h(N)\epsilon _N &lt; \infty \)</span>
                            </p>
                          
                        </li>
                        <li>
                          <span class="u-custom-list-number">(ii-a)</span>
                          
                            <p>for all <span class="mathjax-tex">\(\theta _1,\theta _2\in \varTheta \)</span>, <span class="mathjax-tex">\(\theta _1\ne \theta _2\)</span>, and for all <span class="mathjax-tex">\(g_1,g_2\in \varOmega (N)\)</span>: </p><div id="Equ9" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned}&amp;P_{\theta _1\times \theta _2} ( \{ (\varvec{\omega }_1,\varvec{\omega }_2)\in \varOmega ^{\infty }\times \varOmega ^{\infty }\mid \nonumber \\&amp;\quad T(\epsilon _N,\varvec{\omega }_1(g_1(N)),\varvec{\omega }_2(g_2(N))) = accept \ \text{ for } \text{ infinitely } \text{ many }\ N \})=0. \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (9)
                </div></div>
                                          
                          
                        </li>
                      </ol><p>
                                 <i>T</i> is called <i>weakly </i>
                                 <i>h</i>-<i>consistent</i>, if instead of (i-a) and (ii-a) only the following holds</p><ol class="u-list-style-none">
                        <li>
                          <span class="u-custom-list-number">(i-b)</span>
                          
                            <p>for all <span class="mathjax-tex">\(\delta &gt;0\)</span>, there exists <span class="mathjax-tex">\(N_0\in \mathbb N\)</span>, such that for all <span class="mathjax-tex">\(N\ge N_0\)</span>: <span class="mathjax-tex">\(h(N)\epsilon _N\le \delta \)</span>.</p>
                          
                        </li>
                        <li>
                          <span class="u-custom-list-number">(ii-b)</span>
                          
                            <p>for all <span class="mathjax-tex">\(\theta _1,\theta _2\in \varTheta \)</span>, <span class="mathjax-tex">\(\theta _1\ne \theta _2\)</span>, for all <span class="mathjax-tex">\(g_1,g_2\in \varOmega (N)\)</span>: </p><div id="Equ37" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \lim _N P_{\theta _1\times \theta _2} ( \{ (\varvec{\omega }_1,\varvec{\omega }_2)\in \varOmega ^{\infty }\times \varOmega ^{\infty }\mid T(\epsilon _N,\varvec{\omega }_1(g_1(N)),\varvec{\omega }_2(g_2(N))) = accept ) = 0. \end{aligned}$$</span></div></div>
                                          
                          
                        </li>
                      </ol>
                              
                  <p>The following definitions introduces the conditions we have to impose on data generation procedures to ensure consistency.</p>
                    <h3 class="c-article__sub-heading" id="FPar33">Definition 21</h3>
                    <p>Let <span class="mathjax-tex">\(\bar{\varvec{o}}^{\infty } = \bar{\varvec{o}}^{(1)},\bar{\varvec{o}}^{(2)},\ldots ,\bar{\varvec{o}}^{(N)},\ldots \)</span> be an infinite sequence of finite observation sequences, where each <span class="mathjax-tex">\(\bar{\varvec{o}}^{(N)}\)</span> is independently sampled from some sampling distribution <span class="mathjax-tex">\(P^s_N\)</span>.<sup><a href="#Fn1"><span class="u-visually-hidden">Footnote </span>1</a></sup> We denote with <span class="mathjax-tex">\(P^s\)</span> the sampling distribution for <span class="mathjax-tex">\(\bar{\varvec{o}}^{\infty }\)</span>, and with <span class="mathjax-tex">\(\hat{X}_{i,N}^{(v)}\)</span> the empirical distribution defined as in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec23">1</a> from the first <i>N</i> elements of <span class="mathjax-tex">\(\bar{\varvec{o}}^{\infty }\)</span>. Let <span class="mathjax-tex">\(h:\mathbb N\rightarrow \mathbb R\)</span> as in Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar32">20</a>. We say that <span class="mathjax-tex">\(P^s\)</span> is <i>h</i>-<i>admissible</i> if</p><ol class="u-list-style-none">
                        <li>
                          <span class="u-custom-list-number">(i)</span>
                          
                            <p>for all <i>v</i>, <i>N</i>, <i>i</i>: the elements of <span class="mathjax-tex">\(\hat{X}_{i,N}^{(v)}\)</span> are an iid sample from <span class="mathjax-tex">\(P(X_i^{ q(v) })\)</span>.</p>
                          
                        </li>
                        <li>
                          <span class="u-custom-list-number">(ii)</span>
                          
                            <p>for all <i>v</i>, <i>i</i>: <span class="mathjax-tex">\(P^s(| \hat{X}_{i,N}^{(v)} | = \varOmega (N))=1\)</span> (at least linear increase of sample sizes for all empirical node distributions)</p>
                          
                        </li>
                        <li>
                          <span class="u-custom-list-number">(iii)</span>
                          
                            <p>
                                            <span class="mathjax-tex">\(E(| \{ v\mid \exists i: | \hat{X}_{i,N}^{(v)} | &gt; 0 \}| ) = O(h(N))\)</span> (in expectation, the increase of the number of nodes with non-empty samples is at most <i>h</i>(<i>N</i>)).</p>
                          
                        </li>
                      </ol>
                              
                  
                    <h3 class="c-article__sub-heading" id="FPar34">Theorem 4</h3>
                    <p>Let <span class="mathjax-tex">\(P^s\)</span> be an <i>h</i>-admissible sample distribution. For <span class="mathjax-tex">\(i=1,\ldots ,n\)</span> let <span class="mathjax-tex">\(T_i\)</span> be an <i>h</i>-consistent two-sample test for equivalence for the parametric family <span class="mathjax-tex">\(\{P_{\theta }\mid \theta \in \varTheta _i\}\)</span> with associated sequence <span class="mathjax-tex">\((\epsilon _{i,N})\)</span>.</p>
                    <p>For <span class="mathjax-tex">\(N&gt;1\)</span>, <span class="mathjax-tex">\(i\in \{1,\ldots ,n\}\)</span> we define</p><div id="Equ10" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} v\sim ^{(N)}_{t,i}v'\ : \Leftrightarrow \ T( \epsilon _{i,N} , \hat{X}_{i,N}^{(v)} , \hat{X}_{i,N}^{(v')} ) = accept \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (10)
                </div></div><p>Furthermore, define</p><div id="Equ38" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} v\sim ^{(N)}_{t}v'\ :\Leftrightarrow \ \forall i:\ v\sim ^{(N)}_{t,i}v'. \end{aligned}$$</span></div></div><p>If <i>T</i> is strongly <i>h</i>-consistent, then</p><div id="Equ11" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P^s( \sim ^{(N)}_{t}\ \text{ almost } \text{ always } \text{ satisfies } \text{(i) } \text{ and } \text{(ii) } \text{ in } \text{ Lemma } \text{1 } )=1. \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (11)
                </div></div><p>If <i>T</i> is weakly <i>h</i>-consistent, then for all <span class="mathjax-tex">\(\delta &gt;0\)</span> exists <span class="mathjax-tex">\(N_0\in \mathbb N\)</span>, such that for all <span class="mathjax-tex">\(N\ge N_0\)</span>:</p><div id="Equ12" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P^s( \sim ^{(N)}_{t}\ \text{ satisfies } \text{(i) } \text{ and } \text{(ii) } \text{ in } \text{ Lemma } \text{1 } ) \ge 1-\delta . \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (12)
                </div></div>
                              
                  
                    <h3 class="c-article__sub-heading" id="FPar35">Proof</h3>
                    <p>We first observe that we may assume that all <span class="mathjax-tex">\(T_i\)</span> satisfy Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar32">20</a> with the same sequence <span class="mathjax-tex">\(\epsilon _N\)</span>, because replacing <span class="mathjax-tex">\(\epsilon _{i,N}\)</span> with <span class="mathjax-tex">\(\epsilon _N:= \max _i \epsilon _{i,N}\)</span> preserves the validity of conditions (i) and (ii) in Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar32">20</a>.</p>
                    <p>We now first show that <span class="mathjax-tex">\(\sim ^{(N)}_{t}\)</span> a.a. satisfies (i). Let <span class="mathjax-tex">\(v,v'\in C\)</span>, and assume, first, that <span class="mathjax-tex">\(q(v)\sim _lq(v')\)</span>. Then <span class="mathjax-tex">\(\theta _i=\theta '_i\)</span> for all <i>i</i>, and thus</p><div id="Equ39" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P^s( T( \epsilon _N, \hat{X}_{i,N}^{(v)}, \hat{X}_{i,N}^{(v')} )=reject ) \le \epsilon _N. \end{aligned}$$</span></div></div><p>If (i-a) holds, then by the Borel-Cantelli lemma (here only using <span class="mathjax-tex">\(\sum _N \epsilon _N &lt;\infty \)</span>)</p><div id="Equ40" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P^s( v \sim ^{(N)}_{t,i}v'\ \text{ a.a. })=1 \end{aligned}$$</span></div></div><p>for all <i>i</i>, and therefore also</p><div id="Equ13" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P^s( v \sim ^{(N)}_{t}v'\ \text{ a.a. })=1. \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (13)
                </div></div><p>If (i-b) holds, then for a given <span class="mathjax-tex">\(\delta \)</span> and sufficiently large <i>N</i>:</p><div id="Equ41" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P^s( v \sim ^{(N)}_{t,i}v')\ge 1- \delta /(4n\mid \! C \!\mid ^2), \end{aligned}$$</span></div></div><p>and therefore</p><div id="Equ14" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P^s( \text{ for } \text{ all }\ v,v'\in C:\ q(v)\sim _lq(v')\Rightarrow v\sim _tv') &gt; 1-\delta /4. \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (14)
                </div></div><p>Conversely, assume <span class="mathjax-tex">\(q(v)\not \sim _lq(v')\)</span>. Let <span class="mathjax-tex">\(i\in \{1,\ldots ,n\}\)</span> be such that <span class="mathjax-tex">\(\theta _i\ne \theta _i'\)</span>. Assume that <i>T</i> is strongly consistent. Then, by Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar32">20</a> (ii-a) and Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar33">21</a> (ii):</p><div id="Equ42" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P^s( T( \epsilon _N, \hat{X}_{i,N}^{(v)}, \hat{X}_{i,N}^{(v')} )=reject \ \text{ a.a. } ) =1, \end{aligned}$$</span></div></div><p>and therefore</p><div id="Equ15" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P^s( v \not \sim ^{(N)}_{t}v'\ a.a.)=1. \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (15)
                </div></div><p>(<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10994-016-5565-9#Equ13">13</a>) and (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10994-016-5565-9#Equ15">15</a>) together imply that <span class="mathjax-tex">\(P^s( \sim ^{(N)}_{t}\ \text{ almost } \text{ always } \text{ satisfies } \text{(i) } \text{ in } \text{ Lemma } \text{1 } )=1\)</span>.</p>
                    <p>If <i>T</i> is only weakly consistent, then by Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar32">20</a> (ii-b) and Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar33">21</a> (ii), for all <span class="mathjax-tex">\(\delta \)</span> and all sufficiently large <i>N</i>:</p><div id="Equ43" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P^s( T( \epsilon _N, \hat{X}_{i,N}^{(v)}, \hat{X}_{i,N}^{(v')} )=reject ) \le \delta / (4n\mid \! C \!\mid ^2), \end{aligned}$$</span></div></div><p>and therefore</p><div id="Equ16" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P^s( \text{ for } \text{ all }\ v,v'\in C:\ q(v)\sim _lq(v')\Leftarrow v\sim _tv') &gt; 1-\delta /4. \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (16)
                </div></div><p>(<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10994-016-5565-9#Equ14">14</a>) and (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10994-016-5565-9#Equ16">16</a>) together imply that <span class="mathjax-tex">\(P^s( \sim ^{(N)}_{t}\ \text{ satisfies } \text{(i) } \text{ in } \text{ Lemma } \text{1 } )\ge 1-\delta /2\)</span>.</p>
                    <p>We now turn to showing condition (ii) of Lemma <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar29">1</a>. For this we consider the probability that (ii) does not hold for <span class="mathjax-tex">\(\sim ^{(N)}_{t}\)</span>. In the following, when we write a union or summation over pairs <span class="mathjax-tex">\(v,v'\)</span> this is always shorthand for union or summation over the set</p><div id="Equ44" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \{ v,v'\mid q(v)\sim _lq(v'), \exists v_j,v_h\in K, \bar{\varvec{o}}\in Obs ^*: v=succ (v_j,\bar{\varvec{o}}), v'=succ (v_h,\bar{\varvec{o}}) \} \end{aligned}$$</span></div></div><p>Using (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10994-016-5565-9#Equ7">7</a>) and (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10994-016-5565-9#Equ8">8</a>) we can write:</p><div id="Equ17" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned}&amp;P^s( \cup _{v,v'} \{ v\not \sim ^{(N)}_{t}v' \} ) \le \sum _{v,v'} \sum _{i=1}^n P^s( v\not \sim ^{(N)}_{t,i}v')\nonumber \\&amp;\quad = \sum _{v,v'} \sum _{i=1}^n P^s( v\not \sim ^{(N)}_{t,i}v', |\hat{X}_{i,N}^{(v)}|&gt;0) \nonumber \\&amp;\quad = \sum _{v,v'} \sum _{i=1}^n P^s( v\not \sim ^{(N)}_{t,i}v' \mid |\hat{X}_{i,N}^{(v)}|&gt;0) P^s( |\hat{X}_{i,N}^{(v)}|&gt;0) \nonumber \\&amp;\quad \le \epsilon _N \sum _{v,v'} \sum _{i=1}^n P^s( |\hat{X}_{i,N}^{(v)}|&gt;0) \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (17)
                </div></div><p>For any given <i>v</i> there exist at most |<i>K</i>| different <span class="mathjax-tex">\(v'\)</span> for which the pair <span class="mathjax-tex">\(v,v'\)</span> is included in the sum. Also writing <span class="mathjax-tex">\(P^s(|\hat{X}_{i,N}^{(v)}|&gt;0\}) \)</span> as <span class="mathjax-tex">\(E( {\varvec{1}}_{|\hat{X}_{i,N}^{(v)}|&gt;0 } )\)</span> with <span class="mathjax-tex">\({\varvec{1}}_e\)</span> the indicator function of event <i>e</i>, we can therefore further bound (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10994-016-5565-9#Equ17">17</a>):</p><div id="Equ18" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned}&amp;\le \epsilon _N |K| \sum _{v\in T}\sum _{i=1}^n P^s( |\hat{X}_{i,N}^{(v)}|&gt;0) \nonumber \\&amp;\quad = \epsilon _N |K| \sum _{v\in T}\sum _{i=1}^n E( {\varvec{1}}_{|\hat{X}_{i,N}^{(v)}|&gt;0 } ) = \epsilon _N |K| E\left( \sum _{v\in T}\sum _{i=1}^n {\varvec{1}}_{|\hat{X}_{i,N}^{(v)}|&gt;0 } \right) \nonumber \\&amp;\quad \le \epsilon _N |K| n E\left( \sum _{v\in T} {\varvec{1}}_{ \exists i: |\hat{X}_{i,N}^{(v)}|&gt;0 } \right) = O(h(N)\epsilon _N), \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (18)
                </div></div><p>where the last equality is due to Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar33">21</a> (iii).</p>
                    <p>If Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar32">20</a> (i-a) holds, it follows with the Borel-Cantelli Lemma that</p><div id="Equ45" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P^s( \sim ^{(N)}_{t}\ \text{ infinitely } \text{ often } \text{ violates } \text{ Lemma } \text{1 } \text{(ii) } )=0. \end{aligned}$$</span></div></div><p>
                                 <span class="mathjax-tex">\(\square \)</span>
                              </p>
                  <p>If Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar32">20</a> (i-b) holds, then for sufficiently large <i>N</i>
                              </p><div id="Equ19" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} P^s( \sim ^{(N)}_{t}\ \text{ violates } \text{ Lemma } \text{1 } \text{(ii) } )\le \delta /2. \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (19)
                </div></div><p>We conclude this section by showing that the Hoeffding test for the equivalence of binomial distributions, and the <i>F</i>-test for the equivalence for exponential distributions are strongly and weakly <i>h</i>-consistent, respectively, for</p><div id="Equ46" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} h^{\textit{geo}}_{\lambda } (N):= E(| \{ v\mid \exists i: | \hat{X}_{i,N}^{(v)} | &gt; 0 \}|), \end{aligned}$$</span></div></div><p>where the expectation is with respect to the sampling procedure described in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec15">4</a>, i.e. with a geometric distribution with parameter <span class="mathjax-tex">\(\lambda \)</span> for the length of the sample sequences <span class="mathjax-tex">\(\bar{\varvec{o}}^{(j)}\)</span>.</p>
                    <h3 class="c-article__sub-heading" id="FPar36">Lemma 2</h3>
                    <p>
                      <span class="mathjax-tex">\(\lim _N h^{\textit{geo}}_{\lambda } (N)/N =0\)</span>
                    </p>
                  
                    <h3 class="c-article__sub-heading" id="FPar37">Proof</h3>
                    <p>Let <span class="mathjax-tex">\(V_N:=| \{ v\mid \exists i: | \hat{X}_{i,N}^{(v)} | &gt; 0 \}|\)</span> and <span class="mathjax-tex">\(V^+_N:=V_N - V_{N-1}\)</span>, i.e., <span class="mathjax-tex">\(V^+_N\)</span> is the number of nodes <span class="mathjax-tex">\(v\in T\)</span> that are reached for the first time in the <i>N</i>th sample. Then <span class="mathjax-tex">\(E(V_N)=\sum _{k=1}^N E(V^+_k) \)</span>, and the lemma can be proven by showing that <span class="mathjax-tex">\(E(V^+_k) \rightarrow 0 \)</span> as <span class="mathjax-tex">\(k\rightarrow \infty \)</span>. We can write</p><div id="Equ47" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} E(V^+_k) = E(V^+_k\mid V^+_k&gt; 0) P^s(V^+_k &gt; 0). \end{aligned}$$</span></div></div><p>For all <i>k</i>: <span class="mathjax-tex">\(E(V^+_k\mid V^+_k &gt; 0)=(1-\lambda )/\lambda \)</span>. This is because the geometric distribution represents a memoryless sampling procedure for the length of an observation sequence <span class="mathjax-tex">\(\bar{\varvec{o}}\)</span>, so that conditional on <span class="mathjax-tex">\(\bar{\varvec{o}}\)</span> having reached a first new node <i>v</i>, the expected length of the remaining string is still the prior expectation <span class="mathjax-tex">\((1-\lambda )/\lambda \)</span>. It is thus sufficient to show that <span class="mathjax-tex">\(P^s(V^+_k &gt; 0)\rightarrow 0\)</span> for <span class="mathjax-tex">\(k\rightarrow \infty \)</span>. For this let <span class="mathjax-tex">\(A_{l,k}\)</span> be the event that all nodes <span class="mathjax-tex">\(v\in T\)</span> at depth <span class="mathjax-tex">\(\le l\)</span> are included in <span class="mathjax-tex">\(V_k\)</span>. Then, because of Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar33">21</a> (ii), we have that for all fixed <i>l</i>: <span class="mathjax-tex">\(P^s(A_{l,k})\rightarrow 1\)</span> for <span class="mathjax-tex">\(k\rightarrow \infty \)</span>. Thus, for all <i>l</i> and all <span class="mathjax-tex">\(\delta &gt;0\)</span> there exists <span class="mathjax-tex">\(k_0\)</span> such that for all <span class="mathjax-tex">\(k\ge k_0\)</span>: <span class="mathjax-tex">\(P^s(V^+_k&gt; 0)\le P^s(V^+_k &gt; 0\mid A_{l,k}) + \delta \)</span>. With <span class="mathjax-tex">\(P^s(V^+_k &gt; 0\mid A_{l,k})\le (1-\lambda )^l\)</span> then <span class="mathjax-tex">\(P^s(V^+_k &gt; 0)\rightarrow 0\)</span> follows. <span class="mathjax-tex">\(\square \)</span>
                              </p>
                  
                    <h3 class="c-article__sub-heading" id="FPar38">Lemma 3</h3>
                    <p>The Hoeffding test defined by Algorithm 3 is strongly <span class="mathjax-tex">\( h^{\textit{geo}}_{\lambda } \)</span>-consistent.</p>
                  
                    <h3 class="c-article__sub-heading" id="FPar39">Proof</h3>
                    <p>We first note that the Hoeffding test is indeed a two-sample test in the sense of Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar31">19</a> (Carrasco and Oncina <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1999" title="Carrasco, R. C., &amp; Oncina, J. (1999). Learning deterministic regular grammars from stochastic samples in polynomial time. Journal of Theoretial Informatics and Applications, 33(1), 1–20." href="/article/10.1007/s10994-016-5565-9#ref-CR11" id="ref-link-section-d52740e52321">1999</a>). To show strong consistency, let <span class="mathjax-tex">\(\epsilon _N:=1/N^r\)</span> for some <span class="mathjax-tex">\(r&gt;2\)</span>. Then (i-a) of Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar32">20</a> is satisfied, because according to Lemma <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar36">2</a> 
                                 <span class="mathjax-tex">\( h^{\textit{geo}}_{\lambda } (N)\epsilon _N &lt; 1/N^{r-1}\)</span> in the limit <span class="mathjax-tex">\(N\rightarrow \infty \)</span>.</p>
                    <p>To show (ii-a), let <span class="mathjax-tex">\(\theta _1 &gt; \theta _2\)</span> be parameters of the binomial distribution, and <span class="mathjax-tex">\(g_1, g_2\in \varOmega (N)\)</span>. In this case, <span class="mathjax-tex">\(\varvec{\omega }_i(g_i(N))\)</span> are samples from <span class="mathjax-tex">\(\varOmega =\{0,1\}\)</span> of size <span class="mathjax-tex">\(g_i(N)\)</span>. Let <span class="mathjax-tex">\(f_i\)</span> denote the number of occurrences of 1 in <span class="mathjax-tex">\(\varvec{\omega }_i(g_i(N))\)</span>, and <span class="mathjax-tex">\(T(\epsilon _N,\varvec{\omega }_1(g_1(N)),\varvec{\omega }_2(g_2(N))) = accept \)</span> iff</p><div id="Equ20" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \mid \! f_1/g_1(N) - f_2/g_2(N) \!\mid &lt; ( \sqrt{1/g_1(N)} + \sqrt{1/g_2(N)} )\sqrt{1/2\ln ( 2/\epsilon _N)} . \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (20)
                </div></div><p>By the strong law of large numbers, <span class="mathjax-tex">\(P_{\theta _1\times \theta _2}( \lim _{N\rightarrow \infty }\mid \! f_1/g_1(N) - f_2/g_2(N) \!\mid \rightarrow \theta _1-\theta _2 )=1\)</span>. The right-hand side of (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10994-016-5565-9#Equ20">20</a>) is of the order <span class="mathjax-tex">\(O(\sqrt{ \ln N/N })\)</span>, and, thus, goes to zero as <span class="mathjax-tex">\(N\rightarrow \infty \)</span>. It follows that with probability 1, (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10994-016-5565-9#Equ20">20</a>) only holds for finitely many <i>N</i>.</p>
                    <p>We note that similarly we obtain that the Hoeffding test is weakly <span class="mathjax-tex">\( h^{\textit{geo}}_{\lambda } \)</span>-consistent for sequences <span class="mathjax-tex">\(\epsilon _N:=1/N^r\)</span> with <span class="mathjax-tex">\(r&gt;1\)</span>. <span class="mathjax-tex">\(\square \)</span>
                              </p>
                  
                    <h3 class="c-article__sub-heading" id="FPar40">Lemma 4</h3>
                    <p>The <i>F</i>-test defined by Algorithm 4 is weakly <span class="mathjax-tex">\( h^{\textit{geo}}_{\lambda } \)</span>-consistent.</p>
                  
                    <h3 class="c-article__sub-heading" id="FPar41">Proof</h3>
                    <p>For the <i>F</i>-test, the data <span class="mathjax-tex">\(\varvec{\omega }_i(g_i(N))\)</span> consists of samples from <span class="mathjax-tex">\(\varOmega =\mathbb R\)</span> following exponential distributions with parameters <span class="mathjax-tex">\(\theta _i\)</span>. Let <span class="mathjax-tex">\(g_1, g_2\in \varOmega (N)\)</span>. In the following, we denote <span class="mathjax-tex">\(N_i:= g_i(N)\)</span> (<span class="mathjax-tex">\(i=1,2\)</span>).</p>
                    <p>Let <span class="mathjax-tex">\(\hat{\theta _i}:= \sum _{l=1}^{N_i}\omega _l/N_i\)</span>. Then <span class="mathjax-tex">\((\hat{\theta _1}/\hat{\theta _2})(\theta _2 / \theta _1)\)</span> (approximately) follows an <span class="mathjax-tex">\(F(2N_1,2N_2)\)</span>-distribution with mean <span class="mathjax-tex">\(\mu =\frac{N_2}{N_2-1}\)</span> and standard deviation</p><div id="Equ21" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \sigma = \sqrt{\frac{ N_2^2(N_1+N_2-1) }{N_1(N_2-1)^2(N_2-2) }} \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (21)
                </div></div><p> (Cox <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1953" title="Cox, D. R. (1953). Some simple approximate tests for Poisson variates. Biometrika, 40(3/4), 354–360." href="/article/10.1007/s10994-016-5565-9#ref-CR19" id="ref-link-section-d52740e54224">1953</a>; Gehan and Thomas <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1969" title="Gehan, E. A., &amp; Thomas, D. G. (1969). The performance of some two-sample tests in small samples with and without censoring. Biometrika, 56(1), 127–132." href="/article/10.1007/s10994-016-5565-9#ref-CR24" id="ref-link-section-d52740e54227">1969</a>), and</p><div id="Equ22" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned}&amp;P_{\theta _1\times \theta _2}\left( \hat{\theta _1}/\hat{\theta _2}\in \left[ \mu - \frac{\sigma }{\sqrt{\epsilon _N }}, \mu + \frac{\sigma }{\sqrt{\epsilon _N } } \right] \right) \nonumber \\&amp;\quad =P_{F(2N_1,2N_2 )}\left( \left[ (\mu - \frac{\sigma }{\sqrt{\epsilon _N }})\frac{\theta _1}{\theta _2}, (\mu + \frac{\sigma }{\sqrt{\epsilon _N }})\frac{\theta _1}{\theta _2} \right] \right) . \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (22)
                </div></div><p>The <i>F</i>-test is constructed by an application of Chebyshev’s inequality for the <span class="mathjax-tex">\(F(2N_1,2N_2)\)</span>-distribution, and thereby is seen to be a two-sample test in the sense of Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar31">19</a>.</p>
                    <p>To show weak consistency, let <span class="mathjax-tex">\(\epsilon _N=1/\sqrt{N h^{\textit{geo}}_{\lambda } (N)}\)</span>. With Lemma <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar36">2</a> then <span class="mathjax-tex">\( h^{\textit{geo}}_{\lambda } (N)\epsilon _N=\sqrt{ h^{\textit{geo}}_{\lambda } (N)/N}\rightarrow 0\)</span>, so that Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar32">20</a> (i-b) is satisfied.</p>
                    <p>Now assume <span class="mathjax-tex">\(\theta _1\ne \theta _2\)</span>. With Lemma <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10994-016-5565-9#FPar36">2</a> we obtain <span class="mathjax-tex">\(\sigma /\sqrt{\epsilon _N}=O(( h^{\textit{geo}}_{\lambda } (N)/N)^{1/4})\rightarrow 0\)</span>. With <span class="mathjax-tex">\(\mu \rightarrow 1\)</span> this means that the interval <span class="mathjax-tex">\([(\mu - \frac{\sigma }{\sqrt{\epsilon _N }})\frac{\theta _2}{\theta _1}, (\mu + \frac{\sigma }{\sqrt{\epsilon _N }})\frac{\theta _2}{\theta _1} ]\)</span> is bounded away from 1 as <span class="mathjax-tex">\(N\rightarrow \infty \)</span>, and that the right-hand side of (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10994-016-5565-9#Equ22">22</a>) goes to zero. <span class="mathjax-tex">\(\square \)</span>
                              </p>
                  <h3 class="c-article__sub-heading" id="App2">Appendix 2: MDP test properties</h3><p>See Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10994-016-5565-9#Tab5">5</a>.</p>
                  <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-5"><figure><figcaption class="c-article-table__figcaption"><b id="Tab5" data-test="table-caption">Table 5 LTL test properties used in the Experiments of Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10994-016-5565-9#Sec17">5.1</a>
                                    </b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10994-016-5565-9/tables/5"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                </div></div></section><section aria-labelledby="rightslink" data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Learning%20deterministic%20probabilistic%20automata%20from%20a%20model%20checking%20perspective&amp;author=Hua%20Mao%20et%20al&amp;contentID=10.1007%2Fs10994-016-5565-9&amp;copyright=The%20Author%28s%29&amp;publication=0885-6125&amp;publicationDate=2016-05-18&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10994-016-5565-9" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10994-016-5565-9" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Mao, H., Chen, Y., Jaeger, M. <i>et al.</i> Learning deterministic probabilistic automata from a model checking perspective.
                    <i>Mach Learn</i> <b>105, </b>255–299 (2016). https://doi.org/10.1007/s10994-016-5565-9</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" href="/article/10.1007/s10994-016-5565-9.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2012-12-01">01 December 2012</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-04-07">07 April 2016</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-05-18">18 May 2016</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-11">November 2016</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10994-016-5565-9" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10994-016-5565-9</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Probabilistic model checking</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Probabilistic automata learning</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Linear time temporal logic</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10994-016-5565-9.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button" data-track-external  download>
            
                <span>Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>

                </div>

                <div data-test="collections">
                    <div id="SpringerLinkArticleCollections">
    
</div>

                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10994/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=5565;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 95.247.224.159</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Not affiliated
        </p>

    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
        <symbol id="icon-info" viewBox="0 0 18 18">
            <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-chevron-down" viewBox="0 0 16 16">
            <path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>
