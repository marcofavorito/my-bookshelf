author: Eck, Adam and Soh, Leen-Kiat and Devlin, Sam and Kudenko, Daniel
author_list:
- affiliation: []
  family: Eck
  given: Adam
- affiliation: []
  family: Soh
  given: Leen-Kiat
- affiliation: []
  family: Devlin
  given: Sam
- affiliation: []
  family: Kudenko
  given: Daniel
citations:
- unstructured: Araya-Lopez, M., Buffet, O., Thomas, V., & Charpillet, F. (2010).
    A POMDP extension with belief-dependent rewards. In Proceedings of the 24th Annual
    Conference on Neural Information Processing Systems (NIPS’10) (pp. 64–72). Vancouver,
    B.C., Canada, December 6–9, 2010.
- unstructured: Asmuth, J., Littman, M. L., & Zinkov, R. (2008). Potential-based shaping
    in model-based reinforcement learning. In Proceedings of the 23rd AAAI Conference
    on Artificial Intelligence (AAAI’08) (pp. 604–609). Chicago, IL, July 13–17, 2008.
- author: DP Bertsekas
  doi: 10.1023/A:1009634810396
  first-page: '89'
  journal-title: Journal of Heuristics
  unstructured: Bertsekas, D. P., & Castanon, D. A. (1999). Rollout algorithms for
    stochastic scheduling problems. Journal of Heuristics, 5, 89–108.
  volume: '5'
  year: '1999'
- unstructured: Boutilier, C. (2002). A POMDP formulation of preference elicitation
    problems. In Proceedings of the 18th National Conference on Artificial Intelligence
    (AAAI’02) (pp. 239–246). Edmonton, Alberta, Canada, July 28–August 1, 2002.
- author: SP Boyd
  doi: 10.1017/CBO9780511804441
  unstructured: 'Boyd, S. P., & Vandenberghe, L. (2004). Convex optimization. Cambridge:
    Cambridge University Press.'
  volume-title: Convex optimization
  year: '2004'
- unstructured: Devlin, S., & Kudenko, D. (2011). Theoretical considerations of potential-based
    reward shaping for multi-agent systems. In K. Tumer, P. Yolum, L. Sonenberg, &
    P. Stone (Eds.), Proceedings of the 10th International Conference on Autonomous
    Agents and Multiagent Sytems (AAMAS’11) (pp. 225–232). Taipei, Taiwan, May 2–6,
    2011.
- unstructured: Devlin, S., & Kudenko, D. (2012). Dynamic potential-based reward shaping.
    In V. Conitzer, M. Winikoff, L. Padgham, & W. van der Hoek (Eds.), Proceedings
    of the 11th International Conference on Autonomous Agents and Multiagent Systems
    (AAMAS’12). Valencia, Spain, June 6–8, 2012.
- unstructured: 'Doshi, F., & Roy, N. (2008). The permutable POMDP: Fast solutions
    to POMDPs for preference elicitation. In L. Padgham, D. C. Parkes, J. Muller &
    S. Parsons (Eds.), Proceedings of the 7th International Conference on Autonomous
    Agents and Multiagent Systems (AAMAS’08) (pp. 493–500). Estoril, Portugal, May
    12–16, 2008.'
- unstructured: Eck, A., Soh, L.-K., Devlin, S., & Kudenko, D. (2013). Potential-based
    reward shaping for POMDPs (Extended Abstract). In T. Ito, C. Jonker, M. Gini,
    & O. Shehory (Eds.), Proceedings of the 12th International Conference on Autonomous
    Agents and Multiagent Systems (AAMAS’13). Saint Paul, Minnesota, May 8–10, 2013.
- author: M Hauskrecht
  doi: 10.1613/jair.678
  first-page: '33'
  journal-title: Journal of Artificial Intelligence Research
  unstructured: Hauskrecht, M. (2000). Value-function approximations for partially
    observable Markov decision proceses. Journal of Artificial Intelligence Research,
    13, 33–94.
  volume: '13'
  year: '2000'
- author: LP Kaelbling
  doi: 10.1016/S0004-3702(98)00023-X
  first-page: '99'
  journal-title: Artificial Intelligence
  unstructured: Kaelbling, L. P., Littman, M. L., & Cassandra, A. R. (1998). Planning
    and acting in partially observable stochastic domains. Artificial Intelligence,
    101, 99–134.
  volume: '101'
  year: '1998'
- doi: 10.15607/RSS.2008.IV.009
  unstructured: 'Kurniawati, H., Hsu, D., & Lee, W. S. (2008). SARSOP: Efficient point-based
    POMDP planning by approximating optimally reachable belief spaces. In Proceedings
    of the 2008 Robotics: Science and Systems Conference (RSS ’08).'
- unstructured: Mihaylova, L. et al. (2002). Active sensing for robotics—A survey.
    In Proceedings of the 5th International Conference on Numerical Methods and Applications
    (NM&A’02). Borovets, Bulgaria, August 20–24, 2002.
- unstructured: 'Ng, A. Y., Harada, D., & Russell, S. (1999). Policy invariance under
    reward transformations: Theory and application to reward shaping, In Proceedings
    of the 16th International Conference on Machine Learning (ICML’99) (pp. 278–287).
    Bled, Slovenia, June 27–30, 1999.'
- author: SCW Ong
  doi: 10.1177/0278364910369861
  first-page: '1053'
  issue: '8'
  journal-title: International Journal of Robotics Research
  unstructured: Ong, S. C. W., Png, S. W., Hsu, D., & Lee, W. S. (2010). Planning
    under uncertainty for robotic tasks with mixed observability. International Journal
    of Robotics Research, 29(8), 1053–1068.
  volume: '29'
  year: '2010'
- unstructured: 'Pineau, J., Gordon, G., & Thrun, S. (2003). Point-based value iteration:
    An anytime algorithm for POMDPs. In Proceedings of the 18th International Joint
    Conference on Artificial Intelligence (IJCAI’03) (pp. 1025–1032). Acapulco, Mexico,
    August 9–15, 2003.'
- unstructured: 'Ross, S., & Chaib-draa, B. (2007). AEMS: An anytime online search
    algorithm for approximate policy refinement in large POMDPs. In Proceedings of
    the 20th International Joint Conference on Artificial Intelligence (IJCAI’07)
    (pp. 2592–2598). Hyderabad, India, January 6–12, 2007.'
- author: S Ross
  doi: 10.1613/jair.2567
  first-page: '663'
  journal-title: Journal of Artificial Intelligence Research
  unstructured: Ross, S., Pineau, J., Paquet, S., & Chaib-draa, B. (2008). Online
    planning algorithms for POMDPs. Journal of Artificial Intelligence Research, 32,
    663–704.
  volume: '32'
  year: '2008'
- unstructured: Silver, D., & Veness, J. (2010). Monte-Carlo planning in large POMDPs.
    In Proceedings of the 24th Annual Conference on Neural Information Processing
    Systems (NIPS’10) (pp. 2164–2172). Vancouver, B.C., Canada, December 6–9, 2010.
- unstructured: Smith, T., & Simmons, R. (2004). Heuristic search value iteration
    for POMDPs. In Proceedings of the 20th Conference on Uncertainty in Artificial
    Intelligence (UAI’04) (pp. 520–527). Banff, Alberta, Canada, July 7–11, 2004.
- unstructured: 'Somani, A., Ye, N., Hsu, D., & Sun Lee, W. (2013). DESPOT: Online
    POMDP planning with regularization. In Advances in Neural Information Processing
    Systems (NIPS) 2013.'
- doi: 10.1609/aaai.v25i1.7931
  unstructured: Sorg, J., Singh, S., & Lewis, R. L. (2011). Optimal rewards versus
    leaf-evaluation heuristics in planning agents. In Proceedings of the 25th AAAI
    Conference on Artificial Intelligence (AAAI’11) (pp. 465–470). San Francisco,
    CA, August 7–11, 2011.
- doi: 10.1109/IROS.2010.5648856
  unstructured: Spaan, M. T. J., Veiga, T. S., & Lima, P. U. (2010). Active cooperative
    perception in networked robotic systems using POMDPs. In Proceedings of the 2010
    IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS’10)
    (pp. 4800–4805). Taipei, Taiwan, October 18–22.
- author: JD Williams
  doi: 10.1016/j.csl.2006.06.008
  first-page: '393'
  journal-title: Computer Speech and Language
  unstructured: Williams, J. D., & Young, S. (2007). Partially observable Markov decision
    processes for spoken dialog systems. Computer Speech and Language, 21, 393–422.
  volume: '21'
  year: '2007'
- unstructured: 'Zhang, Z. & Chen, X. (2012). FHHOP: A factored heuristic online planning
    algorithm for POMDPs. In Proceedings of the 28th Conference on Uncertainty in
    Artificial Intelligence (UAI’12) (pp. 934–943). Catalina Island, USA, August 15–17,
    2012.'
doc_url: http://link.springer.com/article/10.1007/s10458-015-9292-6/fulltext.html
doi: 10.1007/s10458-015-9292-6
files:
- eck-adam-and-soh-leen-kiat-and-devlin-sam-and-kudenko-danielpotential-based-reward-shaping-for-finite-horizon-online-pomdp-planning2016.pdf
issue: '3'
journal: Autonomous Agents and Multi-Agent Systems
language: en
month: 5
pages: 403--445
publisher: Springer Science and Business Media LLC
ref: PotentialBasedEckA2016
time-added: 2023-09-24-22:53:22
title: Potential-based reward shaping for finite horizon online POMDP planning
type: article
url: http://dx.doi.org/10.1007/s10458-015-9292-6
volume: '30'
year: 2016
